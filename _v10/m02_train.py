"""
í•™ìŠµ íŒŒì´í”„ë¼ì¸ - ë°ì´í„° ë¡œë“œë¶€í„° ëª¨ë¸ í•™ìŠµê¹Œì§€
"""
import pandas as pd
import numpy as np
import os
import glob
from datetime import datetime
from sklearn.model_selection import train_test_split
from s02_rename import rename_file
from s03_preprocessing import StockPreprocessor
from m01_model import StockPredictionModel, ModelEvaluator


class TrainingPipeline:
    """ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, data_dir="D:/stock/_v10/_data/stock", output_dir="D:/stock/_v10"):
        self.data_dir = data_dir
        self.output_dir = output_dir
        self.preprocessed_dir = os.path.join(output_dir, "_preprocessed")
        os.makedirs(self.preprocessed_dir, exist_ok=True)
        
    def preprocess_all_stocks(self):
        """ëª¨ë“  ì£¼ì‹ ë°ì´í„° ì „ì²˜ë¦¬"""
        print("=" * 60)
        print("ğŸ“ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        stock_files = glob.glob(os.path.join(self.data_dir, "*.csv"))
        processed_files = []
        
        for i, file_path in enumerate(stock_files):
            filename = os.path.basename(file_path)
            stock_code = filename.split("_")[0]
            
            print(f"\n[{i+1}/{len(stock_files)}] {stock_code} ì²˜ë¦¬ ì¤‘...")
            
            # 1. ì»¬ëŸ¼ëª… ë³€í™˜
            renamed_file = os.path.join(self.preprocessed_dir, f"{stock_code}_renamed.csv")
            if not os.path.exists(renamed_file):
                if not rename_file(file_path, renamed_file):
                    print(f"  âš ï¸ {stock_code} ë¦¬ë„¤ì„ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                    continue
            
            # 2. ì „ì²˜ë¦¬
            final_file = os.path.join(self.preprocessed_dir, f"{stock_code}_final.csv")
            if not os.path.exists(final_file):
                try:
                    preprocessor = StockPreprocessor(stock_code=stock_code)
                    preprocessor.run_pipeline(renamed_file, final_file, is_train=True)
                except Exception as e:
                    print(f"  âš ï¸ {stock_code} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            processed_files.append(final_file)
            print(f"  âœ… {stock_code} ì™„ë£Œ")
        
        print(f"\nâœ… ì´ {len(processed_files)}ê°œ ì¢…ëª© ì „ì²˜ë¦¬ ì™„ë£Œ")
        return processed_files
    
    def load_and_merge_data(self, file_list=None, min_rows=100):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ë° ë³‘í•©"""
        if file_list is None:
            file_list = glob.glob(os.path.join(self.preprocessed_dir, "*_final.csv"))
        
        print(f"\nğŸ“Š {len(file_list)}ê°œ íŒŒì¼ ë¡œë“œ ì¤‘...")
        
        all_data = []
        for file_path in file_list:
            try:
                df = pd.read_csv(file_path)
                if len(df) < min_rows:
                    print(f"  âš ï¸ {os.path.basename(file_path)}: ë°ì´í„° ë¶€ì¡± ({len(df)}í–‰), ê±´ë„ˆëœ€")
                    continue
                
                # ì¢…ëª© ì½”ë“œ ì¶”ê°€
                stock_code = os.path.basename(file_path).split("_")[0]
                df['stock_code'] = stock_code
                all_data.append(df)
                
            except Exception as e:
                print(f"  âš ï¸ {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if not all_data:
            raise ValueError("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        # ë³‘í•©
        merged_df = pd.concat(all_data, ignore_index=True)
        print(f"âœ… ì´ {len(merged_df)}í–‰ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        
        return merged_df
    
    def prepare_features(self, df):
        """í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬"""
        # ì œì™¸í•  ì»¬ëŸ¼
        exclude_cols = ['ë‚ ì§œ', 'target', 'next_rtn', 'stock_code']
        
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        X = df[feature_cols].copy()
        y = df['target'].copy()
        
        # NaN ì²˜ë¦¬
        X = X.fillna(0)
        
        print(f"ğŸ“‹ í”¼ì²˜ ìˆ˜: {len(feature_cols)}")
        print(f"ğŸ“‹ ìƒ˜í”Œ ìˆ˜: {len(X)}")
        print(f"ğŸ“‹ í´ë˜ìŠ¤ ë¶„í¬: ìƒìŠ¹ {y.sum()} ({y.mean()*100:.1f}%), í•˜ë½ {len(y)-y.sum()} ({(1-y.mean())*100:.1f}%)")
        
        return X, y, feature_cols
    
    def train_model(self, X, y, test_size=0.2):
        """ëª¨ë¸ í•™ìŠµ"""
        # ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ shuffle=False
        split_idx = int(len(X) * (1 - test_size))
        
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
        
        print(f"\nğŸ“Š í•™ìŠµ ë°ì´í„°: {len(X_train)}í–‰")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}í–‰")
        
        # ëª¨ë¸ í•™ìŠµ
        model = StockPredictionModel()
        train_results = model.train(X_train, y_train)
        
        # í…ŒìŠ¤íŠ¸ í‰ê°€
        print("\n" + "=" * 60)
        print("ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€")
        print("=" * 60)
        
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)
        
        test_metrics = ModelEvaluator.evaluate(y_test, y_pred, y_proba)
        
        print(f"   Accuracy:  {test_metrics['accuracy']:.4f}")
        print(f"   Precision: {test_metrics['precision']:.4f}")
        print(f"   Recall:    {test_metrics['recall']:.4f}")
        print(f"   F1 Score:  {test_metrics['f1']:.4f}")
        print(f"   AUC:       {test_metrics['auc']:.4f}")
        
        # í”¼ì²˜ ì¤‘ìš”ë„ ì¶œë ¥
        print("\nğŸ“Š Top 10 ì¤‘ìš” í”¼ì²˜:")
        print(model.feature_importance.head(10).to_string(index=False))
        
        # ëª¨ë¸ ì €ì¥
        model.save()
        
        return model, test_metrics
    
    def run_full_pipeline(self, preprocess=True):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("\n" + "ğŸš€" * 20)
        print("      ì£¼ê°€ ì˜ˆì¸¡ AI í•™ìŠµ íŒŒì´í”„ë¼ì¸")
        print("ğŸš€" * 20 + "\n")
        
        # 1. ì „ì²˜ë¦¬
        if preprocess:
            self.preprocess_all_stocks()
        
        # 2. ë°ì´í„° ë¡œë“œ
        df = self.load_and_merge_data()
        
        # 3. í”¼ì²˜ ì¤€ë¹„
        X, y, feature_cols = self.prepare_features(df)
        
        # 4. ëª¨ë¸ í•™ìŠµ
        model, metrics = self.train_model(X, y)
        
        return model, metrics


def train_single_stock(stock_code, data_dir="D:/stock/_v10/_data/stock"):
    """ë‹¨ì¼ ì¢…ëª© í•™ìŠµ"""
    stock_code = str(stock_code).zfill(6)
    
    # íŒŒì¼ ì°¾ê¸°
    pattern = os.path.join(data_dir, f"{stock_code}_*.csv")
    files = glob.glob(pattern)
    
    if not files:
        print(f"âŒ {stock_code} ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    file_path = files[0]
    print(f"ğŸ“‚ íŒŒì¼: {file_path}")
    
    # ì „ì²˜ë¦¬
    preprocessor = StockPreprocessor(stock_code=stock_code)
    renamed_file = file_path.replace(".csv", "_renamed.csv")
    final_file = file_path.replace(".csv", "_final.csv")
    
    from s02_rename import rename_file
    rename_file(file_path, renamed_file)
    df = preprocessor.run_pipeline(renamed_file, final_file, is_train=True)
    
    # í”¼ì²˜ ì¤€ë¹„
    exclude_cols = ['ë‚ ì§œ', 'target', 'next_rtn']
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    X = df[feature_cols].fillna(0)
    y = df['target']
    
    # ëª¨ë¸ í•™ìŠµ
    model = StockPredictionModel(model_dir=f"D:/stock/_v10/models/{stock_code}")
    model.train(X, y)
    model.save(suffix=f"_{stock_code}")
    
    return model


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ")
    parser.add_argument("--stock", type=str, help="ë‹¨ì¼ ì¢…ëª© ì½”ë“œ (ì˜ˆ: 005930)")
    parser.add_argument("--all", action="store_true", help="ì „ì²´ ì¢…ëª© í•™ìŠµ")
    parser.add_argument("--no-preprocess", action="store_true", help="ì „ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°")
    
    args = parser.parse_args()
    
    if args.stock:
        train_single_stock(args.stock)
    else:
        pipeline = TrainingPipeline()
        pipeline.run_full_pipeline(preprocess=not args.no_preprocess)

