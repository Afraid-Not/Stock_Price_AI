"""
9ê°œ ì¢…ëª© ì „ìš© ì•™ìƒë¸” í•™ìŠµ
- ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, NAVER, ì¹´ì¹´ì˜¤, ì‚¼ì„±SDI, LGì „ì, LGë””ìŠ¤í”Œë ˆì´, ì‚¼ì„±SDS, KT
- íƒ€ê²Ÿ: ì˜¤ëŠ˜ ì¢…ê°€ â†’ ë‚´ì¼ ì¢…ê°€ (1% ì´ìƒ ìƒìŠ¹/í•˜ë½)
"""
import pandas as pd
import numpy as np
import random
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
import joblib
import os
from datetime import datetime


def set_seed(seed: int):
    """ëª¨ë“  ëœë¤ ì‹œë“œ ê³ ì •"""
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

# 9ê°œ ì¢…ëª© ì½”ë“œ
TARGET_STOCKS = [
    '005930',  # ì‚¼ì„±ì „ì
    '000660',  # SKí•˜ì´ë‹‰ìŠ¤
    '035420',  # NAVER
    '035720',  # ì¹´ì¹´ì˜¤
    '006400',  # ì‚¼ì„±SDI
    '066570',  # LGì „ì
    '034220',  # LGë””ìŠ¤í”Œë ˆì´
    '018260',  # ì‚¼ì„±SDS
    '030200',  # KT
]

STOCK_NAMES = {
    '005930': 'ì‚¼ì„±ì „ì',
    '000660': 'SKí•˜ì´ë‹‰ìŠ¤',
    '035420': 'NAVER',
    '035720': 'ì¹´ì¹´ì˜¤',
    '006400': 'ì‚¼ì„±SDI',
    '066570': 'LGì „ì',
    '034220': 'LGë””ìŠ¤í”Œë ˆì´',
    '018260': 'ì‚¼ì„±SDS',
    '030200': 'KT',
}


class Stock9Trainer:
    def __init__(self, data_path, n_splits=5, lag_days=[1, 3, 5], 
                 target_threshold=0.01, seed=42):
        self.data_path = data_path
        self.n_splits = n_splits
        self.lag_days = lag_days
        self.target_threshold = target_threshold
        self.seed = seed
        self.models = {}
        self.label_encoder = LabelEncoder()
        
        # ì‹œë“œ ê³ ì •
        set_seed(seed)
        print(f"ğŸ² ëœë¤ ì‹œë“œ: {seed}")
        
        self.model_dir = 'models_9stocks'
        os.makedirs(self.model_dir, exist_ok=True)
        
    def load_data(self):
        """9ê°œ ì¢…ëª©ë§Œ ë¡œë“œ"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(self.data_path)
        
        # stock_codeë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì•ì— 0 íŒ¨ë”©)
        df['stock_code'] = df['stock_code'].astype(str).str.zfill(6)
        
        # 9ê°œ ì¢…ëª©ë§Œ í•„í„°ë§
        df = df[df['stock_code'].isin(TARGET_STOCKS)].copy()
        
        # ë‚ ì§œ ì •ë ¬ (YYYYMMDD ë¬¸ìì—´ í˜•ì‹ ì²˜ë¦¬)
        # âš ï¸ TimeSeriesSplitì´ ì œëŒ€ë¡œ ì‘ë™í•˜ë ¤ë©´ ë‚ ì§œ ìš°ì„  ì •ë ¬ í•„ìˆ˜!
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'].astype(str), format='%Y%m%d', errors='coerce')
        df = df.dropna(subset=['ë‚ ì§œ'])  # íŒŒì‹± ì‹¤íŒ¨í•œ í–‰ ì œê±°
        df = df.sort_values(['ë‚ ì§œ', 'stock_code']).reset_index(drop=True)
        
        print(f"   ì›ë³¸ ë°ì´í„°: {len(df):,}ê±´")
        print(f"   ê¸°ê°„: {df['ë‚ ì§œ'].min().date()} ~ {df['ë‚ ì§œ'].max().date()}")
        print(f"   ì¢…ëª© ìˆ˜: {df['stock_code'].nunique()}ê°œ")
        
        # ì¢…ëª©ë³„ ë°ì´í„° ìˆ˜ ì¶œë ¥
        for code in TARGET_STOCKS:
            cnt = len(df[df['stock_code'] == code])
            print(f"      {STOCK_NAMES[code]}: {cnt:,}ê±´")
        
        # íƒ€ê²Ÿ ì¬ì •ì˜
        if self.target_threshold is not None:
            df = self.redefine_target(df)
        
        # Lag í”¼ì²˜ ì¶”ê°€
        df = self.add_lag_features(df)
        
        print(f"   Lag í”¼ì²˜ ì¶”ê°€ í›„: {len(df):,}ê±´")
        print(f"   í´ë˜ìŠ¤ ë¶„í¬: 0={len(df[df['target']==0]):,}, 1={len(df[df['target']==1]):,}")
        
        return df
    
    def redefine_target(self, df):
        """íƒ€ê²Ÿ ì¬ì •ì˜: ì˜¤ëŠ˜ ì¢…ê°€ â†’ ë‚´ì¼ ì¢…ê°€"""
        print(f"\nğŸ¯ íƒ€ê²Ÿ ì¬ì •ì˜ (ì˜¤ëŠ˜ ì¢…ê°€ â†’ ë‚´ì¼ ì¢…ê°€, ì„ê³„ê°’: Â±{self.target_threshold*100:.1f}%)")
        
        if 'next_rtn' not in df.columns:
            raise ValueError("next_rtn ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        df = df.dropna(subset=['next_rtn'])
        before_filter = len(df)
        
        # ì„ê³„ê°’ ê¸°ì¤€ ë¶„ë¥˜
        df_up = df[df['next_rtn'] >= self.target_threshold].copy()
        df_up['target'] = 1
        
        df_down = df[df['next_rtn'] <= -self.target_threshold].copy()
        df_down['target'] = 0
        
        df_filtered = pd.concat([df_up, df_down], ignore_index=True)
        df_filtered = df_filtered.sort_values(['ë‚ ì§œ', 'stock_code']).reset_index(drop=True)
        
        # next_rtn ì œê±° (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
        df_filtered = df_filtered.drop(columns=['next_rtn'])
        
        excluded = before_filter - len(df_filtered)
        print(f"   ìƒìŠ¹ (â‰¥+{self.target_threshold*100:.1f}%): {len(df_up):,}ê±´")
        print(f"   í•˜ë½ (â‰¤-{self.target_threshold*100:.1f}%): {len(df_down):,}ê±´")
        print(f"   ì œì™¸ (ë…¸ì´ì¦ˆ): {excluded:,}ê±´ ({excluded/before_filter*100:.1f}%)")
        print(f"   í•„í„°ë§ í›„: {len(df_filtered):,}ê±´")
        
        return df_filtered
    
    def add_lag_features(self, df):
        """Lag í”¼ì²˜ ì¶”ê°€"""
        print(f"\nğŸ“Š Lag í”¼ì²˜ ìƒì„± ì¤‘... (lag_days: {self.lag_days})")
        
        base_features = [
            'open_gap', 'high_ratio', 'low_ratio', 'volatility',
            'ê°œì¸_ì²´ê²°ê°•ë„', 'ì™¸êµ­ì¸_ì²´ê²°ê°•ë„', 'ê¸°ê´€ê³„_ì²´ê²°ê°•ë„',
            'vol_ratio', 'rsi'
        ]
        
        # ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì‚¬ìš©
        base_features = [f for f in base_features if f in df.columns]
        
        lag_dfs = []
        for stock_code in df['stock_code'].unique():
            stock_df = df[df['stock_code'] == stock_code].copy()
            stock_df = stock_df.sort_values('ë‚ ì§œ')
            
            for lag in self.lag_days:
                for feat in base_features:
                    stock_df[f'{feat}_lag{lag}'] = stock_df[feat].shift(lag)
            
            lag_dfs.append(stock_df)
        
        df_with_lag = pd.concat(lag_dfs, ignore_index=True)
        
        # NaN ì œê±°
        before_drop = len(df_with_lag)
        df_with_lag = df_with_lag.dropna()
        after_drop = len(df_with_lag)
        
        # âš ï¸ TimeSeriesSplitì„ ìœ„í•´ ë‚ ì§œ ìš°ì„  ì •ë ¬
        df_with_lag = df_with_lag.sort_values(['ë‚ ì§œ', 'stock_code']).reset_index(drop=True)
        
        new_features = [c for c in df_with_lag.columns if '_lag' in c]
        print(f"   ìƒì„±ëœ Lag í”¼ì²˜ ìˆ˜: {len(new_features)}ê°œ")
        print(f"   NaN ì œê±°: {before_drop - after_drop:,}ê±´ ì œê±°ë¨")
        
        return df_with_lag
    
    def get_features(self, df):
        """í”¼ì²˜ ì»¬ëŸ¼ ì¶”ì¶œ"""
        exclude_cols = ['ë‚ ì§œ', 'target', 'stock_code', 'stock_code_encoded',
                        'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ',
                        'stock_name', 'next_rtn']  # ë¬¸ìì—´/íƒ€ê²Ÿ ê´€ë ¨ ì œì™¸
        
        feature_cols = [c for c in df.columns if c not in exclude_cols]
        return feature_cols
    
    def train_fold(self, X_train, y_train, X_val, y_val):
        """ë‹¨ì¼ Fold í•™ìŠµ (Optuna ìµœì  íŒŒë¼ë¯¸í„° ì ìš©)"""
        models = {}
        
        # XGBoost (Optuna ìµœì í™”)
        xgb_model = xgb.XGBClassifier(
            n_estimators=741,
            max_depth=4,
            learning_rate=0.0156,
            subsample=0.7766,
            colsample_bytree=0.6643,
            reg_alpha=0.000133,
            reg_lambda=0.00135,
            min_child_weight=3,
            random_state=self.seed,
            eval_metric='auc',
            early_stopping_rounds=50
        )
        xgb_model.fit(
            X_train, y_train,
            eval_set=[(X_train, y_train), (X_val, y_val)],
            verbose=False
        )
        models['xgboost'] = xgb_model
        
        # LightGBM (ê¸°ë³¸ íŒŒë¼ë¯¸í„°, Optuna í›„ ì—…ë°ì´íŠ¸)
        lgb_model = lgb.LGBMClassifier(
            n_estimators=500,
            max_depth=6,
            learning_rate=0.05,
            num_leaves=50,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            min_child_samples=20,
            random_state=self.seed,
            verbose=-1
        )
        lgb_model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            callbacks=[lgb.early_stopping(50, verbose=False)]
        )
        models['lightgbm'] = lgb_model
        
        # CatBoost (Optuna ìµœì í™”)
        cat_model = CatBoostClassifier(
            iterations=665,
            depth=10,
            learning_rate=0.0124,
            l2_leaf_reg=1.637,
            bagging_temperature=0.582,
            random_strength=1.44e-07,
            random_state=self.seed,
            eval_metric='AUC',
            early_stopping_rounds=50,
            verbose=False
        )
        cat_model.fit(
            X_train, y_train,
            eval_set=(X_val, y_val)
        )
        models['catboost'] = cat_model
        
        return models
    
    def evaluate(self, y_true, y_pred, y_prob):
        """í‰ê°€"""
        return {
            'accuracy': accuracy_score(y_true, y_pred),
            'precision': precision_score(y_true, y_pred, zero_division=0),
            'recall': recall_score(y_true, y_pred, zero_division=0),
            'f1': f1_score(y_true, y_pred, zero_division=0),
            'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else 0.5
        }
    
    def run(self):
        """í•™ìŠµ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸš€ 9ê°œ ì¢…ëª© ì•™ìƒë¸” í•™ìŠµ ì‹œì‘")
        print("=" * 60)
        
        # ë°ì´í„° ë¡œë“œ
        df = self.load_data()
        
        # í”¼ì²˜ ì¤€ë¹„
        feature_cols = self.get_features(df)
        print(f"\nğŸ“Š í”¼ì²˜ ìˆ˜: {len(feature_cols)}ê°œ")
        
        # stock_code ì¸ì½”ë”©
        df['stock_code_encoded'] = self.label_encoder.fit_transform(df['stock_code'])
        if 'stock_code_encoded' not in feature_cols:
            feature_cols.append('stock_code_encoded')
        
        X = df[feature_cols].values
        y = df['target'].values
        
        # TimeSeriesSplit
        tscv = TimeSeriesSplit(n_splits=self.n_splits)
        
        all_metrics = {'xgboost': [], 'lightgbm': [], 'catboost': [], 'ensemble': []}
        
        print(f"\nğŸ“… {self.n_splits}-Fold TimeSeriesSplit í•™ìŠµ")
        print("=" * 60)
        
        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
            print(f"\n[Fold {fold + 1}/{self.n_splits}]")
            
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            
            print(f"   í•™ìŠµ: {len(train_idx):,}ê±´, ê²€ì¦: {len(val_idx):,}ê±´")
            
            # í•™ìŠµ
            fold_models = self.train_fold(X_train, y_train, X_val, y_val)
            
            # í‰ê°€
            for name, model in fold_models.items():
                y_pred = model.predict(X_val)
                y_prob = model.predict_proba(X_val)[:, 1]
                metrics = self.evaluate(y_val, y_pred, y_prob)
                all_metrics[name].append(metrics)
                print(f"   {name}: AUC={metrics['auc']:.4f}, F1={metrics['f1']:.4f}")
            
            # ê°€ì¤‘ ì•™ìƒë¸” (3ê°œ ëª¨ë¸)
            xgb_prob = fold_models['xgboost'].predict_proba(X_val)[:, 1]
            lgb_prob = fold_models['lightgbm'].predict_proba(X_val)[:, 1]
            cat_prob = fold_models['catboost'].predict_proba(X_val)[:, 1]
            
            # ë‹¤ì–‘í•œ ê°€ì¤‘ì¹˜ í…ŒìŠ¤íŠ¸ (xgb, lgb, cat)
            weights = [
                (0.33, 0.33, 0.34, 'equal'),      # ê· ë“±
                (0.2, 0.3, 0.5, 'cat_heavy'),     # CatBoost ì¤‘ì‹¬
                (0.2, 0.2, 0.6, 'cat_only'),      # CatBoost ê°•ì¡°
                (0.3, 0.4, 0.3, 'lgb_heavy'),     # LightGBM ì¤‘ì‹¬
                (0.0, 0.0, 1.0, 'cat_100'),       # CatBoost ë‹¨ë…
                (0.0, 1.0, 0.0, 'lgb_100'),       # LightGBM ë‹¨ë…
            ]
            
            best_auc = 0
            best_weight = None
            
            for w_xgb, w_lgb, w_cat, name in weights:
                y_prob_w = w_xgb * xgb_prob + w_lgb * lgb_prob + w_cat * cat_prob
                auc = roc_auc_score(y_val, y_prob_w)
                if auc > best_auc:
                    best_auc = auc
                    best_weight = (w_xgb, w_lgb, w_cat, name)
                    best_prob = y_prob_w
            
            # ê¸°ë³¸ ì•™ìƒë¸” (ê· ë“±)
            y_prob_ensemble = (xgb_prob + lgb_prob + cat_prob) / 3
            y_pred_ensemble = (y_prob_ensemble >= 0.5).astype(int)
            metrics_ensemble = self.evaluate(y_val, y_pred_ensemble, y_prob_ensemble)
            all_metrics['ensemble'].append(metrics_ensemble)
            
            # ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸”
            y_pred_best = (best_prob >= 0.5).astype(int)
            metrics_best = self.evaluate(y_val, y_pred_best, best_prob)
            
            if 'best_ensemble' not in all_metrics:
                all_metrics['best_ensemble'] = []
            all_metrics['best_ensemble'].append(metrics_best)
            
            print(f"   ensemble(equal): AUC={metrics_ensemble['auc']:.4f}")
            print(f"   best({best_weight[3]}): AUC={metrics_best['auc']:.4f} â­")
            
            # ë§ˆì§€ë§‰ Fold ëª¨ë¸ ì €ì¥
            if fold == self.n_splits - 1:
                self.models = fold_models
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ“‹ êµì°¨ ê²€ì¦ ê²°ê³¼ (í‰ê·  Â± í‘œì¤€í¸ì°¨)")
        print("=" * 60)
        
        for name in ['xgboost', 'lightgbm', 'catboost', 'ensemble', 'best_ensemble']:
            metrics_list = all_metrics[name]
            print(f"\nğŸ“ˆ {name.upper()}:")
            for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc']:
                values = [m[metric] for m in metrics_list]
                print(f"   {metric:10s}: {np.mean(values):.4f} Â± {np.std(values):.4f}")
        
        # ëª¨ë¸ ì €ì¥
        self.save_models()
        
        return all_metrics
    
    def save_models(self):
        """ëª¨ë¸ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        print("\n" + "=" * 60)
        print("ğŸ’¾ ëª¨ë¸ ì €ì¥")
        print("=" * 60)
        
        for name, model in self.models.items():
            path = f"{self.model_dir}/{name}_{timestamp}.pkl"
            joblib.dump(model, path)
            print(f"   {name}: {path}")
        
        # LabelEncoder ì €ì¥
        le_path = f"{self.model_dir}/label_encoder_{timestamp}.pkl"
        joblib.dump(self.label_encoder, le_path)
        print(f"   label_encoder: {le_path}")
        
        # ì¢…ëª© ëª©ë¡ ì €ì¥
        stocks_path = f"{self.model_dir}/target_stocks_{timestamp}.txt"
        with open(stocks_path, 'w', encoding='utf-8') as f:
            for code in TARGET_STOCKS:
                f.write(f"{code},{STOCK_NAMES[code]}\n")
        print(f"   target_stocks: {stocks_path}")


def main():
    import argparse
    parser = argparse.ArgumentParser(description="9ê°œ ì¢…ëª© ì•™ìƒë¸” í•™ìŠµ")
    parser.add_argument("--data", type=str, default="_data/merged_with_macro.csv",
                        help="ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸: merged_with_macro.csv)")
    parser.add_argument("--no-macro", action="store_true", 
                        help="ë§¤í¬ë¡œ ì—†ì´ ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©")
    parser.add_argument("--seed", type=int, default=42,
                        help="ëœë¤ ì‹œë“œ (ê¸°ë³¸: 42)")
    parser.add_argument("--threshold", type=float, default=0.01,
                        help="íƒ€ê²Ÿ ì„ê³„ê°’ (ê¸°ë³¸: 0.01 = 1%%)")
    parser.add_argument("--n_splits", type=int, default=5,
                        help="êµì°¨ ê²€ì¦ Fold ìˆ˜ (ê¸°ë³¸: 5)")
    args = parser.parse_args()
    
    # ë§¤í¬ë¡œ ì—†ì´ ì‹¤í–‰í•  ê²½ìš°
    if args.no_macro:
        data_path = "_data/merged_all_stocks_20260131.csv"
    else:
        data_path = args.data
    
    print(f"ğŸ“‚ ë°ì´í„°: {data_path}")
    
    trainer = Stock9Trainer(
        data_path=data_path,
        n_splits=args.n_splits,
        lag_days=[1, 3, 5],
        target_threshold=args.threshold,
        seed=args.seed
    )
    
    metrics = trainer.run()
    
    print("\n" + "=" * 60)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()

