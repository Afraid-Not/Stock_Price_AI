import torch
import torch.nn as nn
import argparse
import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.metrics import precision_score, recall_score, f1_score

from s04_dataset import get_dataloaders
from s05_architecture import MultiScaleEnsemble
from focal_loss import FocalLoss

def visualize_predictions(model, data_path, device='cpu', num_samples=30, model_dir=None):
    """ë§ˆì§€ë§‰ Nê°œ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” (ë§ˆì§€ë§‰ {num_samples}ê°œ ë°ì´í„°)")
    print(f"{'='*60}")
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(data_path)
    
    # ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸
    has_date = 'ë‚ ì§œ' in df.columns
    
    # Targetê³¼ Feature ë¶„ë¦¬
    if 'target' in df.columns:
        targets = df['target'].values
        features_df = df.drop(columns=['target'])
    else:
        targets = None
        features_df = df.copy()
    
    if has_date:
        dates = df['ë‚ ì§œ'].copy()
        features_df = features_df.drop(columns=['ë‚ ì§œ'])
    else:
        dates = None
    
    # ë§ˆì§€ë§‰ num_samplesê°œ ë°ì´í„° ì¶”ì¶œ
    window_size = 60  # ëª¨ë¸ì˜ ìœˆë„ìš° í¬ê¸°
    if len(features_df) < window_size + num_samples:
        num_samples = len(features_df) - window_size
        print(f"âš ï¸ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ {num_samples}ê°œë§Œ ì‹œê°í™”í•©ë‹ˆë‹¤.")
    
    model.eval()
    predictions = []
    confidences = []
    actuals = []
    date_list = []
    
    with torch.no_grad():
        for i in range(len(features_df) - window_size - num_samples, len(features_df) - window_size):
            # ìœˆë„ìš° ë°ì´í„° ì¶”ì¶œ
            window_data = features_df.iloc[i:i+window_size].values
            data_tensor = torch.FloatTensor(window_data).unsqueeze(0).to(device)
            
            # ì˜ˆì¸¡
            output = model(data_tensor)
            probs = torch.softmax(output, dim=1)
            pred_class = output.argmax(dim=1).item()
            confidence = probs[0][pred_class].item()
            
            predictions.append(pred_class)
            confidences.append(confidence)
            
            if targets is not None:
                actuals.append(targets[i + window_size])
            
            if dates is not None:
                date_list.append(str(dates.iloc[i + window_size]))
            else:
                date_list.append(f"Day {i + window_size}")
    
    # ê·¸ë˜í”„ ìƒì„±
    fig, axes = plt.subplots(2, 1, figsize=(14, 10))
    
    # 1. Prediction vs Actual
    x = range(len(predictions))
    axes[0].plot(x, predictions, 'o-', label='Prediction', color='blue', linewidth=2, markersize=6)
    if actuals:
        axes[0].plot(x, actuals, 's-', label='Actual', color='red', linewidth=2, markersize=6)
        # Accuracy calculation
        accuracy = (np.array(predictions) == np.array(actuals)).mean() * 100
        axes[0].set_title(f'Prediction vs Actual (Accuracy: {accuracy:.2f}%)', fontsize=14, fontweight='bold')
    else:
        axes[0].set_title('Prediction Results', fontsize=14, fontweight='bold')
    
    axes[0].set_xlabel('Data Index', fontsize=12)
    axes[0].set_ylabel('Class (0: Down, 1: Up)', fontsize=12)
    axes[0].set_ylim([-0.1, 1.1])
    axes[0].set_yticks([0, 1])
    axes[0].set_yticklabels(['Down', 'Up'])
    axes[0].legend(fontsize=11)
    axes[0].grid(True, alpha=0.3)
    
    # 2. Confidence
    colors = ['red' if p == 0 else 'green' for p in predictions]
    axes[1].bar(x, confidences, color=colors, alpha=0.6, edgecolor='black', linewidth=1)
    axes[1].axhline(y=0.5, color='gray', linestyle='--', linewidth=1, label='50% Threshold')
    axes[1].set_title('Prediction Confidence', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Data Index', fontsize=12)
    axes[1].set_ylabel('Confidence', fontsize=12)
    axes[1].set_ylim([0, 1])
    axes[1].legend(fontsize=11)
    axes[1].grid(True, alpha=0.3, axis='y')
    
    # Xì¶• ë ˆì´ë¸” (ë‚ ì§œê°€ ìˆìœ¼ë©´ ë‚ ì§œ í‘œì‹œ)
    if dates is not None and len(date_list) <= 30:
        axes[0].set_xticks(x)
        axes[0].set_xticklabels([d.split()[0] if ' ' in d else d for d in date_list], rotation=45, ha='right')
        axes[1].set_xticks(x)
        axes[1].set_xticklabels([d.split()[0] if ' ' in d else d for d in date_list], rotation=45, ha='right')
    
    plt.tight_layout()
    
    # ê·¸ë˜í”„ ì €ì¥
    if model_dir is None:
        model_dir = Path("D:/stock/_v5/models")
    else:
        model_dir = Path(model_dir)
    
    graph_path = model_dir / f"prediction_graph_{num_samples}samples.png"
    plt.savefig(graph_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ê·¸ë˜í”„ ì €ì¥: {graph_path}")
    
    # Statistics output
    print(f"\nğŸ“Š Prediction Statistics:")
    print(f"   - Mean Confidence: {np.mean(confidences):.4f}")
    print(f"   - Min Confidence: {np.min(confidences):.4f}")
    print(f"   - Max Confidence: {np.max(confidences):.4f}")
    if actuals:
        print(f"   - Accuracy: {accuracy:.2f}%")
        print(f"   - Up Predictions: {sum(predictions)}")
        print(f"   - Actual Up: {sum(actuals)}")
    
    plt.close()

def train_model(data_path, epochs=50, lr=0.001, batch_size=32, save_model=True, model_dir=None, device='cpu', early_stopping_patience=30, use_focal_loss=False, focal_alpha=1.0, focal_gamma=2.0, show_graph=False, save_metric='prec'):
    """ëª¨ë¸ í•™ìŠµ"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print(f"{'='*60}")
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        device = "cpu"
    
    device = torch.device(device)
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if model_dir is None:
        model_dir = Path("D:/stock/_v5/models")
    else:
        model_dir = Path(model_dir)
    model_dir.mkdir(exist_ok=True, parents=True)
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    print("ğŸ“¦ ë°ì´í„°ë¡œë” ìƒì„± ì¤‘...")
    train_loader, val_loader = get_dataloaders(data_path, batch_size=batch_size)
    
    # ë°ì´í„°ì…‹ì˜ í”¼ì²˜ ìˆ˜ í™•ì¸
    sample_x, _ = next(iter(train_loader))
    input_dim = sample_x.shape[2]
    
    print(f"ì…ë ¥ ì°¨ì›: {input_dim}")
    print(f"í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}, ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
    
    # ëª¨ë¸ ì´ˆê¸°í™” ë° ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
    model = MultiScaleEnsemble(input_dim)
    model = model.to(device)
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬)
    # ì „ì²´ ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    print("ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ ì¤‘...")
    all_labels = []
    for _, labels in train_loader:
        all_labels.extend(labels.numpy())
    all_labels = np.array(all_labels)
    class_counts_full = np.bincount(all_labels)
    
    # ì†ì‹¤ í•¨ìˆ˜ ì„ íƒ
    if use_focal_loss:
        criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)
        print(f"ğŸ“Š ì†ì‹¤ í•¨ìˆ˜: Focal Loss (alpha={focal_alpha}, gamma={focal_gamma})")
    else:
        if len(class_counts_full) == 2:
            # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì ì€ í´ë˜ìŠ¤ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            total = class_counts_full.sum()
            class_weights = torch.tensor([
                total / (len(class_counts_full) * class_counts_full[0]),
                total / (len(class_counts_full) * class_counts_full[1])
            ], dtype=torch.float32).to(device)
            print(f"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬: {class_counts_full}")
            print(f"ğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights.cpu().numpy()}")
            criterion = nn.CrossEntropyLoss(weight=class_weights)
        else:
            criterion = nn.CrossEntropyLoss()
            print(f"ğŸ“Š ì†ì‹¤ í•¨ìˆ˜: CrossEntropyLoss")
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)
    
    # Learning Rate Scheduler ì¶”ê°€
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.5, patience=10, min_lr=1e-6
    )
    
    # Early Stopping ì„¤ì •
    early_stopping_counter = 0
    
    print(f"\ní•™ìŠµ ì‹œì‘...")
    print(f"  - ì—í¬í¬: {epochs}")
    print(f"  - í•™ìŠµë¥ : {lr}")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"  - ë””ë°”ì´ìŠ¤: {device}")
    print(f"  - ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_dir}")
    print(f"  - Early Stopping Patience: {early_stopping_patience}")
    print(f"  - Learning Rate Scheduler: ReduceLROnPlateau")
    
    # ì €ì¥ ê¸°ì¤€ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
    best_val_acc = 0.0
    best_val_precision = 0.0
    best_val_recall = 0.0
    best_val_f1 = 0.0
    best_model_path = None
    
    # ë©”íŠ¸ë¦­ ì´ë¦„ ë§¤í•‘
    metric_names = {
        'acc': 'ì •í™•ë„',
        'prec': 'Precision',
        'rec': 'Recall',
        'f1': 'F1 Score'
    }
    
    print(f"  - ëª¨ë¸ ì €ì¥ ê¸°ì¤€: {metric_names.get(save_metric, save_metric)}")
    
    for epoch in range(epochs):
        # í•™ìŠµ
        model.train()
        train_loss = 0
        for batch_x, batch_y in train_loader:
            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            optimizer.zero_grad()
            output = model(batch_x)
            loss = criterion(output, batch_y)
            loss.backward()
            # Gradient Clipping ì¶”ê°€
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            train_loss += loss.item()
        
        # ê²€ì¦
        model.eval()
        all_preds = []
        all_labels = []
        with torch.no_grad():
            for val_x, val_y in val_loader:
                # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                val_x = val_x.to(device)
                val_y = val_y.to(device)
                
                val_output = model(val_x)
                pred = val_output.argmax(dim=1)
                
                # CPUë¡œ ì´ë™í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                all_preds.extend(pred.cpu().numpy())
                all_labels.extend(val_y.cpu().numpy())
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        train_loss_avg = train_loss / len(train_loader)
        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)
        val_acc = (all_preds == all_labels).mean() * 100
        
        # Precision, Recall, F1 Score ê³„ì‚°
        precision = precision_score(all_labels, all_preds, average='binary', zero_division=0)
        recall = recall_score(all_labels, all_preds, average='binary', zero_division=0)
        f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)
        
        # ì„ íƒëœ ë©”íŠ¸ë¦­ì— ë”°ë¼ Learning Rate Scheduler ì—…ë°ì´íŠ¸
        if save_metric == 'acc':
            current_metric = val_acc / 100.0  # ë°±ë¶„ìœ¨ì„ ì†Œìˆ˜ë¡œ ë³€í™˜
            best_metric = best_val_acc / 100.0
        elif save_metric == 'prec':
            current_metric = precision
            best_metric = best_val_precision
        elif save_metric == 'rec':
            current_metric = recall
            best_metric = best_val_recall
        elif save_metric == 'f1':
            current_metric = f1
            best_metric = best_val_f1
        else:
            current_metric = precision
            best_metric = best_val_precision
        
        scheduler.step(current_metric)
        current_lr = optimizer.param_groups[0]['lr']
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (ì„ íƒëœ ë©”íŠ¸ë¦­ ê¸°ì¤€)
        improved = False
        if current_metric > best_metric:
            # ëª¨ë“  ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            best_val_acc = val_acc
            best_val_precision = precision
            best_val_recall = recall
            best_val_f1 = f1
            
            improved = True
            early_stopping_counter = 0
            if save_model:
                # ê¸°ì¡´ ëª¨ë¸ ì‚­ì œ (ì„ íƒì‚¬í•­)
                if best_model_path and os.path.exists(best_model_path):
                    os.remove(best_model_path)
                
                # íŒŒì¼ëª…ì— ì„ íƒëœ ë©”íŠ¸ë¦­ ê°•ì¡°
                metric_value = current_metric
                if save_metric == 'acc':
                    metric_value = val_acc
                    metric_str = f"acc_{val_acc:.2f}"
                elif save_metric == 'prec':
                    metric_str = f"precision_{precision:.4f}"
                elif save_metric == 'rec':
                    metric_str = f"recall_{recall:.4f}"
                elif save_metric == 'f1':
                    metric_str = f"f1_{f1:.4f}"
                else:
                    metric_str = f"precision_{precision:.4f}"
                
                best_model_path = model_dir / f"best_model_epoch_{epoch+1}_acc_{val_acc:.2f}_{metric_str}_f1_{f1:.4f}.pth"
                torch.save({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'val_acc': val_acc,
                    'val_precision': precision,
                    'val_recall': recall,
                    'val_f1': f1,
                    'input_dim': input_dim,
                    'save_metric': save_metric
                }, best_model_path)
        else:
            early_stopping_counter += 1
        
        # Early Stopping ì²´í¬
        if early_stopping_patience > 0 and early_stopping_counter >= early_stopping_patience:
            print(f"\nâš ï¸ Early Stopping: {early_stopping_patience} ì—í¬í¬ ë™ì•ˆ ê°œì„ ì´ ì—†ì–´ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            break
        
        # Best ë©”íŠ¸ë¦­ í‘œì‹œ
        if save_metric == 'acc':
            best_metric_str = f"Best Acc: {best_val_acc:.2f}%"
        elif save_metric == 'prec':
            best_metric_str = f"Best Precision: {best_val_precision:.4f}"
        elif save_metric == 'rec':
            best_metric_str = f"Best Recall: {best_val_recall:.4f}"
        elif save_metric == 'f1':
            best_metric_str = f"Best F1: {best_val_f1:.4f}"
        else:
            best_metric_str = f"Best Precision: {best_val_precision:.4f}"
        
        print(f"Epoch [{epoch+1}/{epochs}] Loss: {train_loss_avg:.4f} | "
              f"Val Acc: {val_acc:.2f}% | Precision: {precision:.4f} | "
              f"Recall: {recall:.4f} | F1: {f1:.4f} | {best_metric_str} | "
              f"LR: {current_lr:.2e} | {'âœ¨' if improved else ''}")
    
    if best_model_path:
        # ìµœì¢… ëª¨ë¸ì˜ ë©”íŠ¸ë¦­ ë¡œë“œ
        checkpoint = torch.load(best_model_path, map_location='cpu', weights_only=False)
        best_precision = checkpoint.get('val_precision', 0)
        best_recall = checkpoint.get('val_recall', 0)
        best_f1 = checkpoint.get('val_f1', 0)
        
        metric_display = metric_names.get(save_metric, save_metric.upper())
        print(f"\nâœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ ({metric_display} ê¸°ì¤€): {best_model_path}")
        print(f"   ê²€ì¦ ì •í™•ë„: {best_val_acc:.2f}%")
        print(f"   Precision: {best_precision:.4f}{' â­' if save_metric == 'prec' else ''}")
        print(f"   Recall: {best_recall:.4f}{' â­' if save_metric == 'rec' else ''}")
        print(f"   F1 Score: {best_f1:.4f}{' â­' if save_metric == 'f1' else ''}")
        if save_metric == 'acc':
            print(f"   ì •í™•ë„: {best_val_acc:.2f}% â­")
        
        # ê·¸ë˜í”„ ì‹œê°í™”
        if show_graph:
            # ìµœê³  ëª¨ë¸ ë¡œë“œ
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()
            visualize_predictions(model, data_path, device=device, model_dir=model_dir)
    else:
        print("\nâš ï¸ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        if show_graph:
            print("âš ï¸ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ë ¤ë©´ ëª¨ë¸ì´ ì €ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    return model, best_model_path

def main():
    parser = argparse.ArgumentParser(
        description="ì£¼ì‹ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ í•™ìŠµ
  python train.py --data preprocessed_005930_20240101_20241231.csv
  
  # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •
  python train.py --data preprocessed_005930_20240101_20241231.csv --epochs 100 --lr 0.0001 --batch-size 64
  
  # ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì§€ì •
  python train.py --data preprocessed_005930_20240101_20241231.csv --model-dir ./my_models
  
  # GPU ì‚¬ìš©
  python train.py --data preprocessed_005930_20240101_20241231.csv --device cuda
  
  # Focal Loss ì‚¬ìš© (ë¶ˆê· í˜• ë°ì´í„°ì— íš¨ê³¼ì )
  python train.py --data preprocessed_005930_20240101_20241231.csv --focal-loss --focal-gamma 2.0
  
  # Focal Loss + ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„°
  python train.py --data preprocessed_005930_20240101_20241231.csv --focal-loss --focal-alpha 0.25 --focal-gamma 2.0
        """
    )
    
    parser.add_argument("--data", type=str, required=True, 
                       help="ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--epochs", type=int, default=300, 
                       help="í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: 50)")
    parser.add_argument("--lr", type=float, default=0.001, 
                       help="í•™ìŠµë¥  (ê¸°ë³¸ê°’: 0.001)")
    parser.add_argument("--batch-size", type=int, default=32, 
                       help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)")
    parser.add_argument("--model-dir", type=str, default=None,
                       help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: D:/stock/_v5/models)")
    parser.add_argument("--no-save", action="store_true",
                       help="ëª¨ë¸ ì €ì¥í•˜ì§€ ì•Šê¸°")
    parser.add_argument("--device", type=str, default="cuda", choices=["cpu", "cuda"],
                       help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: cpu)")
    parser.add_argument("--early-stopping", type=int, default=30,
                       help="Early stopping patience (ê¸°ë³¸ê°’: 30, 0ì´ë©´ ë¹„í™œì„±í™”)")
    parser.add_argument("--focal-loss", action="store_true",
                       help="Focal Loss ì‚¬ìš© (ë¶ˆê· í˜• ë°ì´í„°ì— íš¨ê³¼ì )")
    parser.add_argument("--focal-alpha", type=float, default=1.0,
                       help="Focal Loss alpha íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 1.0)")
    parser.add_argument("--focal-gamma", type=float, default=2.0,
                       help="Focal Loss gamma íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 2.0)")
    parser.add_argument("--graph", action="store_true",
                       help="í•™ìŠµ ì™„ë£Œ í›„ ë§ˆì§€ë§‰ 30ê°œ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ ê·¸ë˜í”„ ìƒì„±")
    parser.add_argument("--save-metric", type=str, default="f1", 
                       choices=["acc", "prec", "rec", "f1"],
                       help="ëª¨ë¸ ì €ì¥ ê¸°ì¤€ ë©”íŠ¸ë¦­ (ê¸°ë³¸ê°’: prec)")
    
    args = parser.parse_args()
    
    # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ (ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° _data í´ë” ê¸°ì¤€)
    data_path = args.data
    if not os.path.isabs(data_path):
        base_dir = Path("D:/stock/_v5/_data")
        data_path = base_dir / data_path
        data_path = str(data_path)
    
    try:
        train_model(
            data_path=data_path,
            epochs=args.epochs,
            lr=args.lr,
            batch_size=args.batch_size,
            save_model=not args.no_save,
            model_dir=args.model_dir,
            device=args.device,
            early_stopping_patience=args.early_stopping,
            use_focal_loss=args.focal_loss,
            focal_alpha=args.focal_alpha,
            focal_gamma=args.focal_gamma,
            show_graph=args.graph,
            save_metric=args.save_metric
        )
        print(f"\n{'='*60}")
        print(f"âœ¨ í•™ìŠµ ì™„ë£Œ!")
        print(f"{'='*60}")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()

