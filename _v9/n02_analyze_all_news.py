"""
9ê°œ ì¢…ëª© ë‰´ìŠ¤ ì „ì²´ LLM ê°ì„± ë¶„ì„
"""
import os
import glob
import pandas as pd
import argparse
from n02_analyze_news import NewsAnalyzer

def main():
    parser = argparse.ArgumentParser(description="ì „ì²´ ë‰´ìŠ¤ ê°ì„± ë¶„ì„")
    parser.add_argument("--input_dir", type=str, default="_data/news", help="ë‰´ìŠ¤ í´ë”")
    parser.add_argument("--output_dir", type=str, default="_data/news_sentiment", help="ê²°ê³¼ í´ë”")
    parser.add_argument("--method", type=str, default="llm", choices=["llm", "finbert"])
    parser.add_argument("--delay", type=float, default=0.3, help="API í˜¸ì¶œ ê°„ê²©")
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ë‰´ìŠ¤ íŒŒì¼ ëª©ë¡
    news_files = sorted(glob.glob(f"{args.input_dir}/news_*.csv"))
    
    print("=" * 60)
    print("ğŸš€ ì „ì²´ ë‰´ìŠ¤ ê°ì„± ë¶„ì„")
    print("=" * 60)
    print(f"ì…ë ¥ í´ë”: {args.input_dir}")
    print(f"ì¶œë ¥ í´ë”: {args.output_dir}")
    print(f"ë¶„ì„ ë°©ë²•: {args.method}")
    print(f"íŒŒì¼ ìˆ˜: {len(news_files)}ê°œ")
    print("=" * 60)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
    print("\nğŸ”§ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
    analyzer = NewsAnalyzer(method=args.method)
    
    # ì „ì²´ í†µê³„
    total_news = 0
    total_processed = 0
    all_daily = []
    
    for idx, news_file in enumerate(news_files):
        filename = os.path.basename(news_file)
        stock_code = filename.split("_")[1]  # news_005930_... -> 005930
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ìŠ¤í‚µ
        output_file = f"{args.output_dir}/sentiment_{stock_code}.csv"
        if os.path.exists(output_file):
            print(f"\n[{idx+1}/{len(news_files)}] {stock_code} - â­ï¸ ì´ë¯¸ ì™„ë£Œ, ìŠ¤í‚µ")
            # ì´ë¯¸ ì™„ë£Œëœ íŒŒì¼ë„ daily ì§‘ê³„ì— í¬í•¨
            daily_file = f"{args.output_dir}/daily_{stock_code}.csv"
            if os.path.exists(daily_file):
                all_daily.append(pd.read_csv(daily_file, encoding='utf-8-sig'))
            continue
        
        print(f"\n[{idx+1}/{len(news_files)}] {stock_code} ë¶„ì„ ì¤‘...")
        
        try:
            # ë‰´ìŠ¤ ë¡œë“œ
            df = pd.read_csv(news_file, encoding='utf-8-sig')
            df['stock_code'] = stock_code
            total_news += len(df)
            print(f"   ë‰´ìŠ¤ ìˆ˜: {len(df)}ê±´")
            
            # ê°ì„± ë¶„ì„
            df_analyzed = analyzer.analyze_dataframe(df, delay=args.delay)
            
            if df_analyzed is not None and len(df_analyzed) > 0:
                total_processed += len(df_analyzed)
                
                # ë¶„ì„ ê²°ê³¼ ì €ì¥
                df_analyzed.to_csv(output_file, index=False, encoding='utf-8-sig')
                print(f"   ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")
                
                # ì¼ë³„ ì§‘ê³„
                df_daily = analyzer.aggregate_daily(df_analyzed)
                daily_output = f"{args.output_dir}/daily_{stock_code}.csv"
                df_daily.to_csv(daily_output, index=False, encoding='utf-8-sig')
                print(f"   ğŸ’¾ ì¼ë³„ ì§‘ê³„ ì €ì¥: {daily_output}")
                
                all_daily.append(df_daily)
            else:
                print(f"   âš ï¸ ë¶„ì„ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    # ì „ì²´ daily ë³‘í•©
    if all_daily:
        df_all_daily = pd.concat(all_daily, ignore_index=True)
        all_daily_path = f"{args.output_dir}/all_daily_sentiment.csv"
        df_all_daily.to_csv(all_daily_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ì „ì²´ ì¼ë³„ ê°ì„± ì €ì¥: {all_daily_path}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
    print(f"ì´ ë‰´ìŠ¤: {total_news}ê±´")
    print(f"ë¶„ì„ ì™„ë£Œ: {total_processed}ê±´")
    print("=" * 60)


if __name__ == "__main__":
    main()

