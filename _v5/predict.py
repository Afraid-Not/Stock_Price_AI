import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import argparse
import os
import sys
from pathlib import Path
from datetime import datetime

from s05_architecture import MultiScaleEnsemble

def load_model(model_path, device='cpu'):
    """ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ"""
    print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # ëª¨ë¸ ì •ë³´ í™•ì¸
    input_dim = checkpoint.get('input_dim')
    if input_dim is None:
        raise ValueError("ëª¨ë¸ íŒŒì¼ì— input_dim ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = MultiScaleEnsemble(input_dim)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì…ë ¥ ì°¨ì›: {input_dim}")
    print(f"   - ê²€ì¦ ì •í™•ë„: {checkpoint.get('val_acc', 'N/A'):.2f}%")
    print(f"   - í•™ìŠµ ì—í¬í¬: {checkpoint.get('epoch', 'N/A')}")
    
    return model, input_dim

def prepare_prediction_data(data_path, window_size=60):
    """ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
    print(f"\nğŸ“Š ë°ì´í„° ì¤€ë¹„ ì¤‘: {data_path}")
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
    
    df = pd.read_csv(data_path)
    
    # Target ì»¬ëŸ¼ ì œê±° (ì˜ˆì¸¡ìš©ì´ë¯€ë¡œ)
    if 'target' in df.columns:
        df = df.drop(columns=['target'])
    
    # ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸ ë° ì €ì¥
    date_col = None
    if 'ë‚ ì§œ' in df.columns:
        date_col = df['ë‚ ì§œ'].copy()
        df = df.drop(columns=['ë‚ ì§œ'])
    
    # ìµœê·¼ window_sizeì¼ ë°ì´í„° ì¶”ì¶œ
    if len(df) < window_size:
        raise ValueError(f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ {window_size}ì¼ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(df)}ì¼)")
    
    # ìµœê·¼ window_sizeì¼ ë°ì´í„°
    recent_data = df.iloc[-window_size:].values
    
    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
    print(f"   - ì „ì²´ ë°ì´í„°: {len(df)}ì¼")
    print(f"   - ì˜ˆì¸¡ìš© ë°ì´í„°: {window_size}ì¼")
    print(f"   - í”¼ì²˜ ìˆ˜: {recent_data.shape[1]}")
    
    return recent_data, date_col, df.columns.tolist()

def predict(model, data, device='cpu'):
    """ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰"""
    model = model.to(device)
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€: (window_size, features) -> (1, window_size, features)
    data_tensor = torch.FloatTensor(data).unsqueeze(0).to(device)
    
    with torch.no_grad():
        output = model(data_tensor)
        # ì†Œí”„íŠ¸ë§¥ìŠ¤ í™•ë¥ 
        probs = torch.softmax(output, dim=1)
        # ì˜ˆì¸¡ í´ë˜ìŠ¤
        pred_class = output.argmax(dim=1).item()
        # í™•ë¥ ê°’
        prob_up = probs[0][1].item()
        prob_down = probs[0][0].item()
    
    return pred_class, prob_up, prob_down

def predict_batch(model, data_path, window_size=60, batch_size=32, device='cpu'):
    """ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ë°°ì¹˜ ì˜ˆì¸¡ ìˆ˜í–‰"""
    print(f"\nğŸ“Š ë°°ì¹˜ ì˜ˆì¸¡ ì‹œì‘...")
    
    df = pd.read_csv(data_path)
    
    # ë‚ ì§œ ì»¬ëŸ¼ ì €ì¥
    dates = None
    if 'ë‚ ì§œ' in df.columns:
        dates = df['ë‚ ì§œ'].copy()
    
    # Target ë¶„ë¦¬
    targets = None
    if 'target' in df.columns:
        targets = df['target'].values
    
    features_df = df.drop(columns=['target'] if 'target' in df.columns else [])
    if dates is not None:
        features_df = features_df.drop(columns=['ë‚ ì§œ'])
    
    model = model.to(device)
    model.eval()
    
    predictions = []
    probabilities_up = []
    probabilities_down = []
    
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì˜ˆì¸¡
    for i in range(len(features_df) - window_size):
        window_data = features_df.iloc[i:i+window_size].values
        data_tensor = torch.FloatTensor(window_data).unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(data_tensor)
            probs = torch.softmax(output, dim=1)
            pred_class = output.argmax(dim=1).item()
            prob_up = probs[0][1].item()
            prob_down = probs[0][0].item()
        
        predictions.append(pred_class)
        probabilities_up.append(prob_up)
        probabilities_down.append(prob_down)
    
    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    result_df = pd.DataFrame({
        'ë‚ ì§œ': dates.iloc[window_size:].values if dates is not None else None,
        'ì˜ˆì¸¡': predictions,
        'ìƒìŠ¹í™•ë¥ ': probabilities_up,
        'í•˜ë½í™•ë¥ ': probabilities_down
    })
    
    if targets is not None:
        result_df['ì‹¤ì œ'] = targets[window_size:]
        result_df['ì •í™•ë„'] = (result_df['ì˜ˆì¸¡'] == result_df['ì‹¤ì œ']).astype(int)
    
    return result_df

def main():
    parser = argparse.ArgumentParser(
        description="í•™ìŠµëœ ëª¨ë¸ë¡œ ì£¼ì‹ ì˜ˆì¸¡ ìˆ˜í–‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë‹¨ì¼ ì˜ˆì¸¡ (ìµœì‹  ë°ì´í„°ë¡œ ë‚´ì¼ ì˜ˆì¸¡)
  python predict.py --model models/best_model_epoch_50_acc_55.23.pth --data preprocessed_005930_20240101_20241231.csv
  
  # ë°°ì¹˜ ì˜ˆì¸¡ (ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡)
  python predict.py --model models/best_model_epoch_50_acc_55.23.pth --data preprocessed_005930_20240101_20241231.csv --batch
  
  # ê²°ê³¼ ì €ì¥
  python predict.py --model models/best_model.pth --data preprocessed_005930.csv --batch --output predictions.csv
        """
    )
    
    parser.add_argument("--model", type=str, required=True,
                       help="ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ (.pth)")
    parser.add_argument("--data", type=str, required=True,
                       help="ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--batch", action="store_true",
                       help="ë°°ì¹˜ ì˜ˆì¸¡ ëª¨ë“œ (ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡)")
    parser.add_argument("--output", type=str, default=None,
                       help="ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ (ë°°ì¹˜ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©)")
    parser.add_argument("--device", type=str, default="cpu",
                       choices=["cpu", "cuda"],
                       help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: cpu)")
    parser.add_argument("--window-size", type=int, default=60,
                       help="ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 60)")
    
    args = parser.parse_args()
    
    # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
    model_path = args.model
    if not os.path.isabs(model_path):
        model_path = Path("D:/stock/_v5") / model_path
        model_path = str(model_path)
    
    data_path = args.data
    if not os.path.isabs(data_path):
        data_path = Path("D:/stock/_v5/_data") / data_path
        data_path = str(data_path)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = args.device
    if device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        device = "cpu"
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        model, input_dim = load_model(model_path, device=device)
        
        if args.batch:
            # ë°°ì¹˜ ì˜ˆì¸¡
            result_df = predict_batch(model, data_path, window_size=args.window_size, device=device)
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼")
            print(f"{'='*60}")
            print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(result_df)}")
            
            if 'ì •í™•ë„' in result_df.columns:
                accuracy = result_df['ì •í™•ë„'].mean() * 100
                print(f"ì „ì²´ ì •í™•ë„: {accuracy:.2f}%")
            
            print(f"\nìµœê·¼ 10ì¼ ì˜ˆì¸¡:")
            print(result_df.tail(10).to_string(index=False))
            
            # ê²°ê³¼ ì €ì¥
            if args.output:
                output_path = args.output
                if not os.path.isabs(output_path):
                    output_path = Path("D:/stock/_v5/_data") / output_path
                result_df.to_csv(output_path, index=False, encoding='utf-8-sig')
                print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_path}")
        else:
            # ë‹¨ì¼ ì˜ˆì¸¡ (ìµœì‹  ë°ì´í„°ë¡œ ë‚´ì¼ ì˜ˆì¸¡)
            data, dates, feature_names = prepare_prediction_data(data_path, window_size=args.window_size)
            
            pred_class, prob_up, prob_down = predict(model, data, device=device)
            
            print(f"\n{'='*60}")
            print(f"ğŸ”® ì˜ˆì¸¡ ê²°ê³¼")
            print(f"{'='*60}")
            print(f"ì˜ˆì¸¡: {'ğŸ“ˆ ìƒìŠ¹' if pred_class == 1 else 'ğŸ“‰ í•˜ë½'}")
            print(f"ìƒìŠ¹ í™•ë¥ : {prob_up*100:.2f}%")
            print(f"í•˜ë½ í™•ë¥ : {prob_down*100:.2f}%")
            
            if dates is not None:
                print(f"\nì‚¬ìš©ëœ ë°ì´í„° ê¸°ê°„:")
                print(f"  ì‹œì‘ì¼: {dates.iloc[-args.window_size]}")
                print(f"  ì¢…ë£Œì¼: {dates.iloc[-1]}")
        
        print(f"\n{'='*60}")
        print(f"âœ¨ ì˜ˆì¸¡ ì™„ë£Œ!")
        print(f"{'='*60}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()

