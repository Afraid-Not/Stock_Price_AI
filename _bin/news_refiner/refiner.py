"""
í•œêµ­ì–´ FinBERTë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ëª¨ë“ˆ
"""
import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import List, Optional
import os
import warnings
warnings.filterwarnings('ignore')


class FinBERTRefiner:
    """í•œêµ­ì–´ FinBERTë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "snunlp/KR-FinBert-SC"):
        """
        FinBERT ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
                - "snunlp/KR-FinBert-SC": í•œêµ­ì–´ ê¸ˆìœµ ê°ì„± ë¶„ì„ ëª¨ë¸ (ê¶Œì¥)
                - "monologg/koelectra-base-v3-discriminator": ì¼ë°˜ í•œêµ­ì–´ ëª¨ë¸
        """
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ FinBERT ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        print(f"ğŸ“± ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
            self.model.to(self.device)
            self.model.eval()
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ëŒ€ì•ˆ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            # ëŒ€ì•ˆ ëª¨ë¸ ì‹œë„
            try:
                self.model_name = "monologg/koelectra-base-v3-discriminator"
                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
                # ì¼ë°˜ ëª¨ë¸ì€ ë¶„ë¥˜ í—¤ë“œë¥¼ ì¶”ê°€í•´ì•¼ í•  ìˆ˜ ìˆìŒ
                self.model = AutoModelForSequenceClassification.from_pretrained(
                    self.model_name,
                    num_labels=3  # ê¸ì •, ì¤‘ë¦½, ë¶€ì •
                )
                self.model.to(self.device)
                self.model.eval()
                print("âœ… ëŒ€ì•ˆ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            except Exception as e2:
                print(f"âŒ ëŒ€ì•ˆ ëª¨ë¸ë„ ë¡œë”© ì‹¤íŒ¨: {e2}")
                raise
    
    def predict_sentiment(self, text: str) -> dict:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ê°ì„± ë¶„ì„
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            dict: ê°ì„± ë¶„ì„ ê²°ê³¼
                - label: ê°ì„± ë ˆì´ë¸” (0: ë¶€ì •, 1: ì¤‘ë¦½, 2: ê¸ì •)
                - score: ì‹ ë¢°ë„ ì ìˆ˜
                - sentiment: ê°ì„± í…ìŠ¤íŠ¸ ("ë¶€ì •", "ì¤‘ë¦½", "ê¸ì •")
                - scores: ê° ê°ì„±ë³„ ì ìˆ˜ (ë¶€ì •, ì¤‘ë¦½, ê¸ì •)
        """
        if not text or pd.isna(text):
            return {
                "label": 1,
                "score": 0.0,
                "sentiment": "ì¤‘ë¦½",
                "scores": {"ë¶€ì •": 0.0, "ì¤‘ë¦½": 1.0, "ê¸ì •": 0.0}
            }
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ìµœëŒ€ ê¸¸ì´ ì œí•œ)
        text = str(text).strip()
        if len(text) > 512:  # BERT ìµœëŒ€ ê¸¸ì´
            text = text[:512]
        
        try:
            # í† í°í™” ë° ì¸ì½”ë”©
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            ).to(self.device)
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probs = torch.softmax(logits, dim=-1)
                predicted_label = torch.argmax(probs, dim=-1).item()
                confidence = probs[0][predicted_label].item()
            
            # ê° ê°ì„±ë³„ ì ìˆ˜ ì¶”ì¶œ
            prob_list = probs[0].cpu().tolist()
            # ë ˆì´ë¸” ë§¤í•‘ (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            sentiment_map = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}
            sentiment = sentiment_map.get(predicted_label, "ì¤‘ë¦½")
            
            # ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ë ˆì´ë¸” ìˆœì„œì— ë§ì¶°)
            scores = {
                "ë¶€ì •": prob_list[0] if len(prob_list) > 0 else 0.0,
                "ì¤‘ë¦½": prob_list[1] if len(prob_list) > 1 else 0.0,
                "ê¸ì •": prob_list[2] if len(prob_list) > 2 else 0.0
            }
            
            return {
                "label": predicted_label,
                "score": confidence,
                "sentiment": sentiment,
                "scores": scores
            }
        except Exception as e:
            print(f"âš ï¸ ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "label": 1,
                "score": 0.0,
                "sentiment": "ì¤‘ë¦½",
                "scores": {"ë¶€ì •": 0.0, "ì¤‘ë¦½": 1.0, "ê¸ì •": 0.0}
            }
    
    def predict_batch(self, texts: List[str], batch_size: int = 32) -> List[dict]:
        """
        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ë°°ì¹˜ ê°ì„± ë¶„ì„
        
        Args:
            texts: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            List[dict]: ê°ì„± ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            batch_results = []
            
            for text in batch_texts:
                result = self.predict_sentiment(text)
                batch_results.append(result)
            
            results.extend(batch_results)
            
            if (i + batch_size) % 100 == 0:
                print(f"  ì§„í–‰ë¥ : {min(i + batch_size, len(texts))}/{len(texts)}")
        
        return results
    
    def refine_news(self, df: pd.DataFrame, text_column: str = "HTS_ê³µì‹œ_ì œëª©_ë‚´ìš©", 
                   date_column: str = "ì‘ì„±ì¼ì", time_column: str = "ì‘ì„±ì‹œê°„") -> pd.DataFrame:
        """
        ë‰´ìŠ¤ ë°ì´í„°í”„ë ˆì„ì— ê°ì„± ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        
        Args:
            df: ë‰´ìŠ¤ ë°ì´í„°í”„ë ˆì„
            text_column: ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
            time_column: ì‹œê°„ ì»¬ëŸ¼ëª…
            
        Returns:
            pd.DataFrame: ê°ì„± ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        if text_column not in df.columns:
            print(f"âš ï¸ ì»¬ëŸ¼ '{text_column}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
            return df
        
        print(f"\nğŸ“Š ê°ì„± ë¶„ì„ ì‹œì‘...")
        print(f"  ì´ {len(df)}ê±´ì˜ ë‰´ìŠ¤ ë¶„ì„")
        print(f"  ë¶„ì„ ì»¬ëŸ¼: {text_column}")
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = df[text_column].fillna("").astype(str).tolist()
        
        # ë°°ì¹˜ ê°ì„± ë¶„ì„
        results = self.predict_batch(texts, batch_size=16)
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        df_result = df.copy()
        df_result["ê°ì„±_ë ˆì´ë¸”"] = [r["label"] for r in results]
        df_result["ê°ì„±_ì ìˆ˜"] = [r["score"] for r in results]
        df_result["ê°ì„±"] = [r["sentiment"] for r in results]
        
        # ê° ê°ì„±ë³„ ì ìˆ˜ ì¶”ê°€
        df_result["ë¶€ì •_ì ìˆ˜"] = [r["scores"]["ë¶€ì •"] for r in results]
        df_result["ì¤‘ë¦½_ì ìˆ˜"] = [r["scores"]["ì¤‘ë¦½"] for r in results]
        df_result["ê¸ì •_ì ìˆ˜"] = [r["scores"]["ê¸ì •"] for r in results]
        
        # ê°ì„± ë¶„í¬ ì¶œë ¥
        sentiment_counts = df_result["ê°ì„±"].value_counts()
        print(f"\nâœ… ê°ì„± ë¶„ì„ ì™„ë£Œ")
        print(f"ê°ì„± ë¶„í¬:")
        for sentiment, count in sentiment_counts.items():
            percentage = (count / len(df_result)) * 100
            print(f"  {sentiment}: {count}ê±´ ({percentage:.1f}%)")
        
        return df_result
    
    def format_output(self, df: pd.DataFrame, 
                     date_column: str = "ì‘ì„±ì¼ì", 
                     time_column: str = "ì‘ì„±ì‹œê°„",
                     text_column: str = "HTS_ê³µì‹œ_ì œëª©_ë‚´ìš©") -> pd.DataFrame:
        """
        ì¶œë ¥ìš© ë°ì´í„°í”„ë ˆì„ í˜•ì‹ ë³€í™˜
        ë‚ ì§œ / ì‹œê°„(ì‹œ,ë¶„,ì´ˆ) / ë‚´ìš© / ì ìˆ˜(ë¶€ì •, ê¸ì •, ì¤‘ë¦½) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
            time_column: ì‹œê°„ ì»¬ëŸ¼ëª…
            text_column: ë‚´ìš© ì»¬ëŸ¼ëª…
            
        Returns:
            pd.DataFrame: í˜•ì‹ ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„
        """
        # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYYMMDD -> YYYY-MM-DD)
        if date_column in df.columns:
            dates = df[date_column].astype(str)
            dates_formatted = dates.apply(
                lambda x: f"{x[:4]}-{x[4:6]}-{x[6:8]}" if len(x) == 8 else x
            )
        else:
            dates_formatted = pd.Series([""] * len(df))
        
        # ì‹œê°„ í˜•ì‹ ë³€í™˜ (HHMMSS -> HH:MM:SS)
        if time_column in df.columns:
            times = df[time_column].astype(str).str.zfill(6)
            times_formatted = times.apply(
                lambda x: f"{x[:2]}:{x[2:4]}:{x[4:6]}" if len(x) == 6 else x
            )
        else:
            times_formatted = pd.Series([""] * len(df))
        
        # ë‚´ìš© ì¶”ì¶œ
        if text_column in df.columns:
            contents = df[text_column].fillna("").astype(str)
        else:
            contents = pd.Series([""] * len(df))
        
        # ì ìˆ˜ ì¶”ì¶œ (ë¶€ì •, ì¤‘ë¦½, ê¸ì •)
        neg_scores = df["ë¶€ì •_ì ìˆ˜"] if "ë¶€ì •_ì ìˆ˜" in df.columns else pd.Series([0.0] * len(df))
        neu_scores = df["ì¤‘ë¦½_ì ìˆ˜"] if "ì¤‘ë¦½_ì ìˆ˜" in df.columns else pd.Series([0.0] * len(df))
        pos_scores = df["ê¸ì •_ì ìˆ˜"] if "ê¸ì •_ì ìˆ˜" in df.columns else pd.Series([0.0] * len(df))
        
        # ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_output = pd.DataFrame({
            "ë‚ ì§œ": dates_formatted,
            "ì‹œê°„": times_formatted,
            "ë‚´ìš©": contents,
            "ë¶€ì •_ì ìˆ˜": neg_scores.round(4),
            "ì¤‘ë¦½_ì ìˆ˜": neu_scores.round(4),
            "ê¸ì •_ì ìˆ˜": pos_scores.round(4)
        })
        
        return df_output
    
    def aggregate_daily_sentiment(self, df: pd.DataFrame, 
                                   date_column: str = "ë‚ ì§œ",
                                   method: str = "mean") -> pd.DataFrame:
        """
        ë‚ ì§œë³„ë¡œ ê°ì • ì ìˆ˜ë¥¼ ì§‘ê³„í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            df: ê°ì„± ë¶„ì„ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
            method: ì§‘ê³„ ë°©ë²•
                - "mean": í‰ê·  (ê¸°ë³¸ê°’)
                - "weighted": ê°€ì¤‘ í‰ê·  (ë‰´ìŠ¤ ê°œìˆ˜ ê¸°ë°˜)
                - "max": ìµœëŒ€ê°’
                - "median": ì¤‘ì•™ê°’
                
        Returns:
            pd.DataFrame: ë‚ ì§œë³„ ì§‘ê³„ëœ ê°ì • ì ìˆ˜
        """
        if date_column not in df.columns:
            print(f"âš ï¸ ë‚ ì§œ ì»¬ëŸ¼ '{date_column}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ì ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        score_columns = ["ë¶€ì •_ì ìˆ˜", "ì¤‘ë¦½_ì ìˆ˜", "ê¸ì •_ì ìˆ˜"]
        available_scores = [col for col in score_columns if col in df.columns]
        
        if not available_scores:
            print(f"âš ï¸ ì ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ë‚ ì§œë³„ ì§‘ê³„
        if method == "mean":
            # í‰ê· 
            df_daily = df.groupby(date_column)[available_scores].mean().reset_index()
            df_daily["ë‰´ìŠ¤_ê°œìˆ˜"] = df.groupby(date_column).size().values
            
        elif method == "weighted":
            # ê°€ì¤‘ í‰ê·  (ë‰´ìŠ¤ ê°œìˆ˜ë¡œ ê°€ì¤‘ì¹˜ ì ìš©)
            df_daily = df.groupby(date_column)[available_scores].mean().reset_index()
            df_daily["ë‰´ìŠ¤_ê°œìˆ˜"] = df.groupby(date_column).size().values
            
        elif method == "max":
            # ìµœëŒ€ê°’
            df_daily = df.groupby(date_column)[available_scores].max().reset_index()
            df_daily["ë‰´ìŠ¤_ê°œìˆ˜"] = df.groupby(date_column).size().values
            
        elif method == "median":
            # ì¤‘ì•™ê°’
            df_daily = df.groupby(date_column)[available_scores].median().reset_index()
            df_daily["ë‰´ìŠ¤_ê°œìˆ˜"] = df.groupby(date_column).size().values
            
        else:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì§‘ê³„ ë°©ë²•: {method}. í‰ê· ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            df_daily = df.groupby(date_column)[available_scores].mean().reset_index()
            df_daily["ë‰´ìŠ¤_ê°œìˆ˜"] = df.groupby(date_column).size().values
        
        # ì ìˆ˜ ë°˜ì˜¬ë¦¼
        for col in available_scores:
            df_daily[col] = df_daily[col].round(4)
        
        # ì£¼ìš” ê°ì • ê²°ì • (ê°€ì¥ ë†’ì€ ì ìˆ˜)
        if len(available_scores) == 3:
            df_daily["ì£¼ìš”_ê°ì •"] = df_daily[available_scores].idxmax(axis=1)
            df_daily["ì£¼ìš”_ê°ì •"] = df_daily["ì£¼ìš”_ê°ì •"].str.replace("_ì ìˆ˜", "")
            df_daily["ì£¼ìš”_ê°ì •_ì ìˆ˜"] = df_daily[available_scores].max(axis=1)
            
            # ë‹¨ì¼ ê°ì„± ì ìˆ˜ ê³„ì‚° (ê¸ì • - ë¶€ì •, ë²”ìœ„: -1 ~ 1)
            if "ë¶€ì •_ì ìˆ˜" in df_daily.columns and "ê¸ì •_ì ìˆ˜" in df_daily.columns:
                df_daily["ê°ì„±_ì ìˆ˜"] = (df_daily["ê¸ì •_ì ìˆ˜"] - df_daily["ë¶€ì •_ì ìˆ˜"]).round(4)
        
        # ë‚ ì§œìˆœ ì •ë ¬
        df_daily = df_daily.sort_values(date_column, ascending=False).reset_index(drop=True)
        
        print(f"\nğŸ“Š ë‚ ì§œë³„ ì§‘ê³„ ì™„ë£Œ")
        print(f"  ì§‘ê³„ ë°©ë²•: {method}")
        print(f"  ì´ {len(df_daily)}ì¼ì˜ ë°ì´í„°")
        
        # ê°ì„± ì ìˆ˜ í†µê³„ ì¶œë ¥
        if "ê°ì„±_ì ìˆ˜" in df_daily.columns:
            print(f"\nê°ì„± ì ìˆ˜ í†µê³„:")
            print(f"  í‰ê· : {df_daily['ê°ì„±_ì ìˆ˜'].mean():.4f}")
            print(f"  ìµœì†Œ: {df_daily['ê°ì„±_ì ìˆ˜'].min():.4f}")
            print(f"  ìµœëŒ€: {df_daily['ê°ì„±_ì ìˆ˜'].max():.4f}")
            print(f"  í‘œì¤€í¸ì°¨: {df_daily['ê°ì„±_ì ìˆ˜'].std():.4f}")
        
        return df_daily
    
    def format_sentiment_output(self, df: pd.DataFrame, 
                                format_type: str = "all") -> pd.DataFrame:
        """
        ê°ì„± ì ìˆ˜ ì¶œë ¥ í˜•ì‹ ë³€í™˜
        
        Args:
            df: ë‚ ì§œë³„ ì§‘ê³„ ë°ì´í„°í”„ë ˆì„
            format_type: ì¶œë ¥ í˜•ì‹
                - "all": ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì ìˆ˜ ëª¨ë‘ ì‚¬ìš© (ê¸°ë³¸ê°’)
                - "single": ë‹¨ì¼ ê°ì„± ì ìˆ˜ë§Œ ì‚¬ìš© (ê¸ì • - ë¶€ì •, ë²”ìœ„: -1 ~ 1)
                - "binary": ë¶€ì •/ê¸ì • ì ìˆ˜ë§Œ ì‚¬ìš© (ì¤‘ë¦½ ì œì™¸)
                
        Returns:
            pd.DataFrame: í˜•ì‹ ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„
        """
        df_output = df.copy()
        
        if format_type == "single":
            # ë‹¨ì¼ ê°ì„± ì ìˆ˜ë§Œ ì‚¬ìš© (ì—°ì†ê°’)
            if "ê°ì„±_ì ìˆ˜" in df_output.columns:
                keep_columns = ["ë‚ ì§œ", "ê°ì„±_ì ìˆ˜", "ë‰´ìŠ¤_ê°œìˆ˜"]
                if "ì£¼ìš”_ê°ì •" in df_output.columns:
                    keep_columns.append("ì£¼ìš”_ê°ì •")
                df_output = df_output[keep_columns]
            else:
                print("âš ï¸ ê°ì„±_ì ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. 'all' í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
        elif format_type == "binary":
            # ë¶€ì •/ê¸ì •ë§Œ ì‚¬ìš© (ì¤‘ë¦½ ì œì™¸)
            if "ë¶€ì •_ì ìˆ˜" in df_output.columns and "ê¸ì •_ì ìˆ˜" in df_output.columns:
                keep_columns = ["ë‚ ì§œ", "ë¶€ì •_ì ìˆ˜", "ê¸ì •_ì ìˆ˜", "ë‰´ìŠ¤_ê°œìˆ˜"]
                if "ì£¼ìš”_ê°ì •" in df_output.columns:
                    keep_columns.append("ì£¼ìš”_ê°ì •")
                if "ê°ì„±_ì ìˆ˜" in df_output.columns:
                    keep_columns.append("ê°ì„±_ì ìˆ˜")
                df_output = df_output[keep_columns]
            else:
                print("âš ï¸ ë¶€ì •/ê¸ì • ì ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. 'all' í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # format_type == "all"ì´ë©´ ëª¨ë“  ì»¬ëŸ¼ ìœ ì§€
        
        return df_output


def convert_daily_to_single(input_path: str, output_path: Optional[str] = None) -> pd.DataFrame:
    """
    ê¸°ì¡´ ë‚ ì§œë³„ ì§‘ê³„ íŒŒì¼ì„ ë‹¨ì¼ ê°ì„± ì ìˆ˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        input_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ (ë‚ ì§œë³„ ì§‘ê³„ íŒŒì¼)
        output_path: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì…ë ¥ íŒŒì¼ëª…ì— _single ì¶”ê°€)
        
    Returns:
        pd.DataFrame: ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„
    """
    print(f"ğŸ“‚ íŒŒì¼ ì½ê¸°: {input_path}")
    try:
        df = pd.read_csv(input_path, encoding='utf-8-sig')
    except:
        df = pd.read_csv(input_path, encoding='cp949')
    
    print(f"  ì´ {len(df)}ì¼ì˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    
    # ê°ì„± ì ìˆ˜ ê³„ì‚° (ê¸ì • - ë¶€ì •)
    if "ë¶€ì •_ì ìˆ˜" in df.columns and "ê¸ì •_ì ìˆ˜" in df.columns:
        df["ê°ì„±_ì ìˆ˜"] = (df["ê¸ì •_ì ìˆ˜"] - df["ë¶€ì •_ì ìˆ˜"]).round(4)
    elif "ê°ì„±_ì ìˆ˜" not in df.columns:
        print("âš ï¸ ë¶€ì •/ê¸ì • ì ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return df
    
    # ë‹¨ì¼ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    keep_columns = ["ë‚ ì§œ", "ê°ì„±_ì ìˆ˜", "ë‰´ìŠ¤_ê°œìˆ˜"]
    if "ì£¼ìš”_ê°ì •" in df.columns:
        keep_columns.append("ì£¼ìš”_ê°ì •")
    
    df_output = df[keep_columns].copy()
    
    # ê²°ê³¼ ì €ì¥
    if output_path is None:
        base_name = os.path.splitext(input_path)[0]
        output_path = f"{base_name}_single.csv"
    
    df_output.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ë³€í™˜ ì™„ë£Œ: {output_path}")
    print(f"  í˜•ì‹: ë‚ ì§œ / ê°ì„±_ì ìˆ˜(ê¸ì •-ë¶€ì •, ì—°ì†ê°’) / ë‰´ìŠ¤_ê°œìˆ˜")
    
    # ê°ì„± ì ìˆ˜ í†µê³„ ì¶œë ¥
    print(f"\nê°ì„± ì ìˆ˜ í†µê³„:")
    print(f"  í‰ê· : {df_output['ê°ì„±_ì ìˆ˜'].mean():.4f}")
    print(f"  ìµœì†Œ: {df_output['ê°ì„±_ì ìˆ˜'].min():.4f}")
    print(f"  ìµœëŒ€: {df_output['ê°ì„±_ì ìˆ˜'].max():.4f}")
    print(f"  í‘œì¤€í¸ì°¨: {df_output['ê°ì„±_ì ìˆ˜'].std():.4f}")
    
    return df_output


def refine_news_file(
    input_path: str,
    output_path: Optional[str] = None,
    text_column: str = "HTS_ê³µì‹œ_ì œëª©_ë‚´ìš©",
    date_column: str = "ì‘ì„±ì¼ì",
    time_column: str = "ì‘ì„±ì‹œê°„",
    model_name: str = "snunlp/KR-FinBert-SC",
    format_output: bool = True,
    aggregate_daily: bool = False,
    aggregation_method: str = "mean",
    sentiment_format: str = "all"
) -> pd.DataFrame:
    """
    ë‰´ìŠ¤ CSV íŒŒì¼ì— ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        input_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì…ë ¥ íŒŒì¼ëª…ì— _refined ì¶”ê°€)
        text_column: ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
        date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
        time_column: ì‹œê°„ ì»¬ëŸ¼ëª…
        model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        format_output: Trueë©´ ë‚ ì§œ/ì‹œê°„/ë‚´ìš©/ì ìˆ˜ í˜•ì‹ìœ¼ë¡œ ì €ì¥, Falseë©´ ì›ë³¸+ê²°ê³¼ í˜•ì‹
        aggregate_daily: ë‚ ì§œë³„ ì§‘ê³„ ì—¬ë¶€
        aggregation_method: ì§‘ê³„ ë°©ë²•
        sentiment_format: ê°ì„± ì ìˆ˜ ì¶œë ¥ í˜•ì‹
            - "all": ë¶€ì •/ì¤‘ë¦½/ê¸ì • ì ìˆ˜ ëª¨ë‘ ì‚¬ìš© (ê¸°ë³¸ê°’)
            - "single": ë‹¨ì¼ ê°ì„± ì ìˆ˜ë§Œ ì‚¬ìš© (ê¸ì • - ë¶€ì •)
            - "binary": ë¶€ì •/ê¸ì • ì ìˆ˜ë§Œ ì‚¬ìš© (ì¤‘ë¦½ ì œì™¸)
        
    Returns:
        pd.DataFrame: ê°ì„± ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    # íŒŒì¼ ì½ê¸°
    print(f"ğŸ“‚ íŒŒì¼ ì½ê¸°: {input_path}")
    try:
        df = pd.read_csv(input_path, encoding='utf-8-sig')
    except:
        df = pd.read_csv(input_path, encoding='cp949')
    
    print(f"  ì´ {len(df)}ê±´ì˜ ë‰´ìŠ¤ ë¡œë“œ ì™„ë£Œ")
    
    # FinBERT ì´ˆê¸°í™”
    refiner = FinBERTRefiner(model_name=model_name)
    
    # ê°ì„± ë¶„ì„ ìˆ˜í–‰
    df_refined = refiner.refine_news(
        df, 
        text_column=text_column,
        date_column=date_column,
        time_column=time_column
    )
    
    # ì¶œë ¥ í˜•ì‹ ë³€í™˜
    if format_output:
        df_output = refiner.format_output(
            df_refined,
            date_column=date_column,
            time_column=time_column,
            text_column=text_column
        )
    else:
        df_output = df_refined
    
    # ë‚ ì§œë³„ ì§‘ê³„
    if aggregate_daily:
        # ë‚ ì§œ ì»¬ëŸ¼ëª… í™•ì¸ (format_output í›„ì—ëŠ” "ë‚ ì§œ"ë¡œ ë³€ê²½ë¨)
        daily_date_column = "ë‚ ì§œ" if format_output else date_column
        df_daily = refiner.aggregate_daily_sentiment(
            df_output,
            date_column=daily_date_column,
            method=aggregation_method
        )
        
        # ê°ì„± ì ìˆ˜ í˜•ì‹ ë³€í™˜
        df_daily = refiner.format_sentiment_output(df_daily, format_type=sentiment_format)
        
        # ì§‘ê³„ ê²°ê³¼ ì €ì¥
        if output_path is None:
            base_name = os.path.splitext(input_path)[0]
            daily_output_path = f"{base_name}_daily.csv"
        else:
            base_name = os.path.splitext(output_path)[0]
            daily_output_path = f"{base_name}_daily.csv"
        
        df_daily.to_csv(daily_output_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ë‚ ì§œë³„ ì§‘ê³„ ê²°ê³¼ ì €ì¥: {daily_output_path}")
        print(f"  ê°ì„± ì ìˆ˜ í˜•ì‹: {sentiment_format}")
        
        # ê°œë³„ ë‰´ìŠ¤ ê²°ê³¼ë„ ì €ì¥
        if output_path is None:
            base_name = os.path.splitext(input_path)[0]
            output_path = f"{base_name}_refined.csv"
        
        df_output.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ê°œë³„ ë‰´ìŠ¤ ê²°ê³¼ ì €ì¥: {output_path}")
        
        return df_daily
    else:
        # ê²°ê³¼ ì €ì¥
        if output_path is None:
            base_name = os.path.splitext(input_path)[0]
            output_path = f"{base_name}_refined.csv"
        
        df_output.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        print(f"  ì €ì¥ í˜•ì‹: ë‚ ì§œ / ì‹œê°„ / ë‚´ìš© / ì ìˆ˜(ë¶€ì •, ì¤‘ë¦½, ê¸ì •)")
        
        return df_output


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="í•œêµ­ì–´ FinBERTë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ê°ì„± ë¶„ì„",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš©
  python refiner.py -i news_005930.csv
  
  # ì¶œë ¥ íŒŒì¼ ì§€ì •
  python refiner.py -i news_005930.csv -o news_005930_refined.csv
  
  # ë‚ ì§œë³„ ì§‘ê³„ (í•˜ë£¨ì˜ ê°ì • ì ìˆ˜)
  python refiner.py -i news_005930.csv --aggregate
  
  # ë‚ ì§œë³„ ì§‘ê³„ (ì¤‘ì•™ê°’ ì‚¬ìš©)
  python refiner.py -i news_005930.csv --aggregate --aggregation-method median
  
  # ë‹¨ì¼ ê°ì„± ì ìˆ˜ë§Œ ì‚¬ìš© (ê¸ì • - ë¶€ì •)
  python refiner.py -i news_005930.csv --aggregate --sentiment-format single
  
  # ë¶€ì •/ê¸ì •ë§Œ ì‚¬ìš© (ì¤‘ë¦½ ì œì™¸)
  python refiner.py -i news_005930.csv --aggregate --sentiment-format binary
  
  # ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì‚¬ìš©
  python refiner.py -i news_005930.csv -c "ì œëª©"
  
  # ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©
  python refiner.py -i news_005930.csv -m "monologg/koelectra-base-v3-discriminator"
        """
    )
    
    parser.add_argument(
        "-i", "--input",
        type=str,
        required=True,
        help="ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ"
    )
    
    parser.add_argument(
        "-o", "--output",
        type=str,
        default=None,
        help="ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ì…ë ¥íŒŒì¼ëª…_refined.csv)"
    )
    
    parser.add_argument(
        "-c", "--column",
        type=str,
        default="HTS_ê³µì‹œ_ì œëª©_ë‚´ìš©",
        help="ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: HTS_ê³µì‹œ_ì œëª©_ë‚´ìš©)"
    )
    
    parser.add_argument(
        "-m", "--model",
        type=str,
        default="snunlp/KR-FinBert-SC",
        help="ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: snunlp/KR-FinBert-SC)"
    )
    
    parser.add_argument(
        "--date-column",
        type=str,
        default="ì‘ì„±ì¼ì",
        help="ë‚ ì§œ ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: ì‘ì„±ì¼ì)"
    )
    
    parser.add_argument(
        "--time-column",
        type=str,
        default="ì‘ì„±ì‹œê°„",
        help="ì‹œê°„ ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: ì‘ì„±ì‹œê°„)"
    )
    
    parser.add_argument(
        "--no-format",
        action="store_true",
        help="ì›ë³¸ í˜•ì‹ ìœ ì§€ (ë‚ ì§œ/ì‹œê°„/ë‚´ìš©/ì ìˆ˜ í˜•ì‹ ë³€í™˜ ì•ˆ í•¨)"
    )
    
    parser.add_argument(
        "--aggregate",
        action="store_true",
        help="ë‚ ì§œë³„ë¡œ ê°ì • ì ìˆ˜ ì§‘ê³„ (í•˜ë£¨ì˜ ê°ì • ì ìˆ˜ ê³„ì‚°)"
    )
    
    parser.add_argument(
        "--aggregation-method",
        type=str,
        default="mean",
        choices=["mean", "weighted", "max", "median"],
        help="ì§‘ê³„ ë°©ë²• (ê¸°ë³¸ê°’: mean - í‰ê· )"
    )
    
    parser.add_argument(
        "--sentiment-format",
        type=str,
        default="single",
        choices=["all", "single", "binary"],
        help="ê°ì„± ì ìˆ˜ ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸ê°’: single - ê¸ì •-ë¶€ì • ë‹¨ì¼ ì ìˆ˜)"
    )
    
    parser.add_argument(
        "--convert",
        action="store_true",
        help="ê¸°ì¡´ ë‚ ì§œë³„ ì§‘ê³„ íŒŒì¼ì„ ë‹¨ì¼ ê°ì„± ì ìˆ˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"
    )
    
    args = parser.parse_args()
    
    # ë³€í™˜ ëª¨ë“œ
    if args.convert:
        df_result = convert_daily_to_single(
            input_path=args.input,
            output_path=args.output
        )
        print("\n" + "=" * 60)
        print("ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        print("=" * 60)
        print(df_result.head(10))
    else:
        # ê°ì„± ë¶„ì„ ìˆ˜í–‰
        df_result = refine_news_file(
            input_path=args.input,
            output_path=args.output,
            text_column=args.column,
            date_column=args.date_column,
            time_column=args.time_column,
            model_name=args.model,
            format_output=not args.no_format,
            aggregate_daily=args.aggregate,
            aggregation_method=args.aggregation_method,
            sentiment_format=args.sentiment_format
        )
        
        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        print("\n" + "=" * 60)
        print("ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        print("=" * 60)
        print(df_result.head(10))

