import argparse
import os
import sys
import torch
import pandas as pd
from pathlib import Path

# ëª¨ë“ˆ ì„í¬íŠ¸
from s00_get_token import get_access_token  # í† í° ë°œê¸‰ (s01ì—ì„œ ì‚¬ìš©)
from s01_kis_data_get import collect_stock_data
from s02_rename import rename_file
from s03_preprocessing import StockPreprocessor
from s05_architecture import MultiScaleEnsemble

def collect_data(code, start_date, end_date, base_dir):
    """1ë‹¨ê³„: ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print(f"{'='*60}")
    print(f"ì¢…ëª©ì½”ë“œ: {code}")
    print(f"ê¸°ê°„: {start_date} ~ {end_date}")
    
    raw_path = f"{base_dir}/{code}_{start_date}_{end_date}.csv"
    
    # ì´ë¯¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ ì˜µì…˜ ì œê³µ
    if os.path.exists(raw_path):
        print(f"âš ï¸ ì´ë¯¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤: {raw_path}")
        response = input("ë‹¤ì‹œ ìˆ˜ì§‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if response != 'y':
            print("âœ… ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©")
            return raw_path
    
    collect_stock_data(code, start_date, end_date)
    
    if not os.path.exists(raw_path):
        raise FileNotFoundError(f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {raw_path}")
    
    print(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {raw_path}")
    return raw_path

def preprocess_data(raw_path, code, start_date, end_date, base_dir, is_train):
    """2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
    print(f"{'='*60}")
    
    renamed_path = f"{base_dir}/{code}_renamed_temp.csv"
    final_path = f"{base_dir}/preprocessed_{code}_{start_date}_{end_date}.csv"
    
    # ì»¬ëŸ¼ëª… ë³€ê²½
    print("ğŸ“ ì»¬ëŸ¼ëª… ë³€ê²½ ì¤‘...")
    if not rename_file(raw_path, renamed_path):
        raise Exception("ì»¬ëŸ¼ëª… ë³€ê²½ ì‹¤íŒ¨")
    
    # ì „ì²˜ë¦¬
    print("ğŸ§ª ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
    preprocessor = StockPreprocessor()
    preprocessor.run_pipeline(renamed_path, final_path, is_train=is_train)
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if os.path.exists(renamed_path):
        os.remove(renamed_path)
    
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {final_path}")
    return final_path

def load_model(model_path, device='cpu'):
    """ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‚ 3ë‹¨ê³„: ëª¨ë¸ ë¡œë“œ")
    print(f"{'='*60}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # ëª¨ë¸ ì •ë³´ í™•ì¸
    input_dim = checkpoint.get('input_dim')
    if input_dim is None:
        raise ValueError("ëª¨ë¸ íŒŒì¼ì— input_dim ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = MultiScaleEnsemble(input_dim)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì…ë ¥ ì°¨ì›: {input_dim}")
    print(f"   - ê²€ì¦ ì •í™•ë„: {checkpoint.get('val_acc', 'N/A'):.2f}%")
    print(f"   - í•™ìŠµ ì—í¬í¬: {checkpoint.get('epoch', 'N/A')}")
    
    return model, input_dim

def prepare_prediction_data(data_path, window_size=60, code=None, end_date=None):
    """ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š 4ë‹¨ê³„: ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„")
    print(f"{'='*60}")
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
    
    df = pd.read_csv(data_path)
    
    # Target ì»¬ëŸ¼ ì œê±° (ì˜ˆì¸¡ìš©ì´ë¯€ë¡œ)
    if 'target' in df.columns:
        df = df.drop(columns=['target'])
    
    # ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸ ë° ì €ì¥
    date_col = None
    if 'ë‚ ì§œ' in df.columns:
        date_col = df['ë‚ ì§œ'].copy()
        df = df.drop(columns=['ë‚ ì§œ'])
    else:
        # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ íŒŒì¼ì—ì„œ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ: preprocessed_005930_20080701_20260127.csv
        import re
        from datetime import datetime, timedelta
        filename = os.path.basename(data_path)
        date_match = re.search(r'preprocessed_(\d{6})_(\d{8})_(\d{8})', filename)
        if date_match:
            code_str = date_match.group(1)
            start_date_str = date_match.group(2)
            end_date_str = date_match.group(3)
            
            # ì›ë³¸ íŒŒì¼ ê²½ë¡œ ì‹œë„
            base_dir = os.path.dirname(data_path)
            raw_path = f"{base_dir}/{code_str}_{start_date_str}_{end_date_str}.csv"
            renamed_path = f"{base_dir}/{code_str}_renamed_temp.csv"
            
            # ë¦¬ë„¤ì„ëœ íŒŒì¼ì´ë‚˜ ì›ë³¸ íŒŒì¼ì—ì„œ ë‚ ì§œ ì½ê¸°
            for try_path in [renamed_path, raw_path]:
                if os.path.exists(try_path):
                    try:
                        raw_df = pd.read_csv(try_path)
                        if 'ë‚ ì§œ' in raw_df.columns:
                            # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                            raw_df['ë‚ ì§œ'] = pd.to_datetime(raw_df['ë‚ ì§œ'].astype(str), format='%Y%m%d', errors='coerce')
                            raw_df = raw_df.dropna(subset=['ë‚ ì§œ'])
                            # ì „ì²˜ë¦¬ëœ ë°ì´í„°ì™€ í–‰ ìˆ˜ê°€ ë§ëŠ”ì§€ í™•ì¸
                            if len(raw_df) >= len(df):
                                # ë§ˆì§€ë§‰ len(df)ê°œë§Œ ì‚¬ìš©
                                date_col = raw_df['ë‚ ì§œ'].iloc[-len(df):].reset_index(drop=True)
                                date_col = date_col.dt.strftime('%Y-%m-%d')
                                break
                    except Exception as e:
                        continue
            
            # íŒŒì¼ì—ì„œ ì½ì§€ ëª»í–ˆìœ¼ë©´ íŒŒì¼ëª…ì˜ ì¢…ë£Œì¼ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì •
            if date_col is None:
                try:
                    end_date = datetime.strptime(end_date_str, '%Y%m%d')
                    # ì£¼ë§ ì œì™¸í•˜ê³  ë‚ ì§œ ìƒì„±
                    dates = []
                    current_date = end_date
                    for _ in range(len(df)):
                        # ì£¼ë§ì´ë©´ í‰ì¼ë¡œ ì´ë™
                        while current_date.weekday() >= 5:  # í† ìš”ì¼(5) ë˜ëŠ” ì¼ìš”ì¼(6)
                            current_date -= timedelta(days=1)
                        dates.insert(0, current_date.strftime('%Y-%m-%d'))
                        current_date -= timedelta(days=1)
                    date_col = pd.Series(dates)
                except:
                    pass
    
    # ìµœê·¼ window_sizeì¼ ë°ì´í„° ì¶”ì¶œ
    if len(df) < window_size:
        raise ValueError(f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ {window_size}ì¼ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(df)}ì¼)")
    
    # ìµœê·¼ window_sizeì¼ ë°ì´í„°
    recent_data = df.iloc[-window_size:].values
    
    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
    print(f"   - ì „ì²´ ë°ì´í„°: {len(df)}ì¼")
    print(f"   - ì˜ˆì¸¡ìš© ë°ì´í„°: {window_size}ì¼")
    print(f"   - í”¼ì²˜ ìˆ˜: {recent_data.shape[1]}")
    
    return recent_data, date_col

def predict(model, data, device='cpu'):
    """ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰"""
    print(f"\n{'='*60}")
    print(f"ğŸ”® 5ë‹¨ê³„: ì˜ˆì¸¡ ìˆ˜í–‰")
    print(f"{'='*60}")
    
    model = model.to(device)
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€: (window_size, features) -> (1, window_size, features)
    data_tensor = torch.FloatTensor(data).unsqueeze(0).to(device)
    
    with torch.no_grad():
        output = model(data_tensor)
        # ì†Œí”„íŠ¸ë§¥ìŠ¤ í™•ë¥ 
        probs = torch.softmax(output, dim=1)
        # ì˜ˆì¸¡ í´ë˜ìŠ¤
        pred_class = output.argmax(dim=1).item()
        # í™•ë¥ ê°’
        prob_up = probs[0][1].item()
        prob_down = probs[0][0].item()
    
    return pred_class, prob_up, prob_down

def run_full_pipeline(code, model_path, start_date=None, end_date=None,
                     skip_collect=False, skip_preprocess=False,
                     is_train=False, window_size=60, device='cpu', predict_tomorrow=False,
                     data_path=None):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ë°ì´í„° ìˆ˜ì§‘ â†’ ì „ì²˜ë¦¬ â†’ ì˜ˆì¸¡"""
    base_dir = "D:/stock/_v5/_data"
    os.makedirs(base_dir, exist_ok=True)
    
    # ë°ì´í„° ê²½ë¡œ ê²°ì •
    if data_path:
        # ì§ì ‘ ì§€ì •ëœ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
        final_path = data_path
        if not os.path.isabs(final_path):
            final_path = os.path.join(base_dir, final_path)
    elif start_date and end_date:
        # ë‚ ì§œë¡œ íŒŒì¼ ê²½ë¡œ ìƒì„±
        raw_path = f"{base_dir}/{code}_{start_date}_{end_date}.csv"
        final_path = f"{base_dir}/preprocessed_{code}_{start_date}_{end_date}.csv"
    else:
        raise ValueError("--data ì˜µì…˜ ë˜ëŠ” --start/--end ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        device = "cpu"
    
    try:
        # 1. ë°ì´í„° ìˆ˜ì§‘ (s00, s01)
        if not skip_collect:
            raw_path = collect_data(code, start_date, end_date, base_dir)
        
        # 2. ì „ì²˜ë¦¬ (s02, s03)
        if not skip_preprocess:
            if data_path:
                raise ValueError("--data ì˜µì…˜ì„ ì‚¬ìš©í•  ë•ŒëŠ” --skip-preprocess ì˜µì…˜ë„ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.")
            # skip_collectê°€ Trueë©´ ì›ë³¸ íŒŒì¼ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í™•ì¸
            if skip_collect and not os.path.exists(raw_path):
                raise FileNotFoundError(f"ì›ë³¸ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {raw_path}\nì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ì›ë³¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            final_path = preprocess_data(raw_path, code, start_date, end_date, base_dir, is_train)
        else:
            # ì „ì²˜ë¦¬ ìŠ¤í‚µ ì‹œ ì „ì²˜ë¦¬ëœ íŒŒì¼ í™•ì¸
            if not os.path.exists(final_path):
                raise FileNotFoundError(f"ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì—ˆì§€ë§Œ ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {final_path}")
        
        # 3. ëª¨ë¸ ë¡œë“œ (s05)
        model, input_dim = load_model(model_path, device=device)
        
        # 4. ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ (s04 ê°œë… í™œìš©)
        prediction_data, date_col = prepare_prediction_data(final_path, window_size=window_size, code=code, end_date=end_date if end_date else None)
        
        # 5. ì˜ˆì¸¡ ìˆ˜í–‰ (s05)
        pred_class, prob_up, prob_down = predict(model, prediction_data, device=device)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*60}")
        print(f"âœ¨ ì˜ˆì¸¡ ê²°ê³¼")
        print(f"{'='*60}")
        
        # ì˜ˆì¸¡ ëŒ€ìƒ ë‚ ì§œ ê³„ì‚°
        prediction_date_str = None
        last_date_str = None
        from datetime import datetime, timedelta
        
        if predict_tomorrow:
            # --tomorrow ì˜µì…˜: ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë‚´ì¼ ì˜ˆì¸¡
            today = datetime.now()
            # ë‹¤ìŒ ê±°ë˜ì¼ ê³„ì‚° (ì£¼ë§ ì œì™¸)
            tomorrow = today + timedelta(days=1)
            if tomorrow.weekday() == 5:  # í† ìš”ì¼
                tomorrow += timedelta(days=2)
            elif tomorrow.weekday() == 6:  # ì¼ìš”ì¼
                tomorrow += timedelta(days=1)
            
            prediction_date_str = tomorrow.strftime('%Y-%m-%d')
            print(f"ğŸ“… ì˜ˆì¸¡ ëŒ€ìƒ ë‚ ì§œ: {prediction_date_str} (ë‚´ì¼)")
            print(f"ğŸ“Š ê¸°ì¤€ ë‚ ì§œ: {today.strftime('%Y-%m-%d')} (ì˜¤ëŠ˜)")
        elif date_col is not None and len(date_col) > 0:
            last_date_str = str(date_col.iloc[-1])
            # ë‚ ì§œ í˜•ì‹ íŒŒì‹± (YYYY-MM-DD ë˜ëŠ” YYYYMMDD ë“±)
            try:
                # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì‹œë„
                last_date = None
                for fmt in ['%Y-%m-%d', '%Y%m%d', '%Y/%m/%d']:
                    try:
                        last_date = datetime.strptime(last_date_str, fmt)
                        break
                    except ValueError:
                        continue
                
                if last_date:
                    # ë‹¤ìŒ ê±°ë˜ì¼ ì˜ˆì¸¡ (ì£¼ë§ ì œì™¸)
                    next_date = last_date + timedelta(days=1)
                    # í† ìš”ì¼ì´ë©´ ì›”ìš”ì¼ë¡œ
                    if next_date.weekday() == 5:  # í† ìš”ì¼
                        next_date += timedelta(days=2)
                    elif next_date.weekday() == 6:  # ì¼ìš”ì¼
                        next_date += timedelta(days=1)
                    
                    prediction_date_str = next_date.strftime('%Y-%m-%d')
                    print(f"ğŸ“… ì˜ˆì¸¡ ëŒ€ìƒ ë‚ ì§œ: {prediction_date_str} (ë‹¤ìŒ ê±°ë˜ì¼)")
                    print(f"ğŸ“Š ê¸°ì¤€ ë‚ ì§œ: {last_date.strftime('%Y-%m-%d')} (ë§ˆì§€ë§‰ ë°ì´í„°)")
            except Exception as e:
                pass
        
        print(f"\nì˜ˆì¸¡: {'ğŸ“ˆ ìƒìŠ¹' if pred_class == 1 else 'ğŸ“‰ í•˜ë½'}")
        print(f"ìƒìŠ¹ í™•ë¥ : {prob_up*100:.2f}%")
        print(f"í•˜ë½ í™•ë¥ : {prob_down*100:.2f}%")
        
        if date_col is not None and len(date_col) > 0:
            print(f"\nì‚¬ìš©ëœ ë°ì´í„° ê¸°ê°„:")
            print(f"  ì‹œì‘ì¼: {date_col.iloc[-window_size]}")
            print(f"  ì¢…ë£Œì¼: {date_col.iloc[-1]}")
            if prediction_date_str:
                print(f"  ì˜ˆì¸¡ì¼: {prediction_date_str}")
        
        print(f"\n{'='*60}")
        print(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print(f"{'='*60}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

def main():
    parser = argparse.ArgumentParser(
        description="ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘/ì „ì²˜ë¦¬/ì˜ˆì¸¡ í†µí•© íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ìˆ˜ì§‘ â†’ ì „ì²˜ë¦¬ â†’ ì˜ˆì¸¡)
  python full_pipeline.py --code 005930 --start 20240101 --end 20241231 --model models/best_model.pth
  
  # ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ ë°”ë¡œ ì˜ˆì¸¡ (ìˆ˜ì§‘/ì „ì²˜ë¦¬ ìŠ¤í‚µ)
  python full_pipeline.py --code 005930 --start 20240101 --end 20241231 --model models/best_model.pth --skip-collect --skip-preprocess
  
  # ìŠ¤ì¼€ì¼ëŸ¬ ì¬í•™ìŠµ í›„ ì˜ˆì¸¡
  python full_pipeline.py --code 005930 --start 20240101 --end 20241231 --model models/best_model.pth --train
  
  # CUDA ì‚¬ìš©
  python full_pipeline.py --code 005930 --start 20240101 --end 20241231 --model models/best_model.pth --device cuda
  
  # ë‚´ì¼ ì˜ˆì¸¡ (ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€) - íŒŒì¼ ì§ì ‘ ì§€ì •
  python full_pipeline.py --model models/best_model.pth --data preprocessed_005930_20080701_20260127.csv --tomorrow
  
  # ë‚´ì¼ ì˜ˆì¸¡ (ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€) - ë‚ ì§œë¡œ íŒŒì¼ ì°¾ê¸°
  python full_pipeline.py --code 005930 --start 20080701 --end 20260127 --model models/best_model.pth --tomorrow --skip-collect --skip-preprocess
        """
    )
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument("--code", type=str, help="ì¢…ëª©ì½”ë“œ (ì˜ˆ: 005930) - ë°ì´í„° ìˆ˜ì§‘/ì „ì²˜ë¦¬ ì‹œ í•„ìš”")
    parser.add_argument("--start", type=str, help="ì‹œì‘ì¼ (YYYYMMDD) - ë°ì´í„° ìˆ˜ì§‘/ì „ì²˜ë¦¬ ì‹œ í•„ìš”")
    parser.add_argument("--end", type=str, help="ì¢…ë£Œì¼ (YYYYMMDD) - ë°ì´í„° ìˆ˜ì§‘/ì „ì²˜ë¦¬ ì‹œ í•„ìš”")
    parser.add_argument("--model", type=str, required=True, help="ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ (.pth)")
    parser.add_argument("--data", type=str, help="ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (--skip-collect --skip-preprocess ì‚¬ìš© ì‹œ)")
    
    # ë‹¨ê³„ ìŠ¤í‚µ ì˜µì…˜
    parser.add_argument("--skip-collect", action="store_true", help="ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--skip-preprocess", action="store_true", help="ì „ì²˜ë¦¬ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°")
    
    # ì „ì²˜ë¦¬ ì˜µì…˜
    parser.add_argument("--train", action="store_true", help="ìŠ¤ì¼€ì¼ëŸ¬ ì‹ ê·œ í•™ìŠµ (ê¸°ë³¸ê°’: False)")
    
    # ì˜ˆì¸¡ ì˜µì…˜
    parser.add_argument("--window-size", type=int, default=60, help="ì˜ˆì¸¡ ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 60)")
    parser.add_argument("--device", type=str, default="cpu", choices=["cpu", "cuda"],
                       help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: cpu)")
    parser.add_argument("--tomorrow", action="store_true",
                       help="ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë‚´ì¼ ì˜ˆì¸¡ (ê¸°ë³¸ê°’: ë§ˆì§€ë§‰ ë°ì´í„°ì˜ ë‹¤ìŒ ê±°ë˜ì¼)")
    
    args = parser.parse_args()
    
    # ì¸ì ê²€ì¦
    if args.data:
        # --data ì˜µì…˜ ì‚¬ìš© ì‹œ
        if not args.skip_preprocess:
            print("âŒ --data ì˜µì…˜ì„ ì‚¬ìš©í•  ë•ŒëŠ” --skip-preprocess ì˜µì…˜ë„ í•„ìš”í•©ë‹ˆë‹¤.")
            sys.exit(1)
        code = args.code  # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•˜ì§€ë§Œ ì¼ë‹¨ None í—ˆìš©
        start_date = None
        end_date = None
    else:
        # --start/--end ì˜µì…˜ ì‚¬ìš© ì‹œ
        if not args.code or not args.start or not args.end:
            print("âŒ --data ì˜µì…˜ì„ ì‚¬ìš©í•˜ì§€ ì•Šì„ ê²½ìš° --code, --start, --endê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")
            sys.exit(1)
        
        # ë‚ ì§œ í˜•ì‹ ê²€ì¦
        try:
            from datetime import datetime
            datetime.strptime(args.start, "%Y%m%d")
            datetime.strptime(args.end, "%Y%m%d")
        except ValueError:
            print("âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYYMMDD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
        
        code = args.code
        start_date = args.start
        end_date = args.end
    
    # ëª¨ë¸ ê²½ë¡œ ì²˜ë¦¬
    model_path = args.model
    if not os.path.isabs(model_path):
        model_path = Path("D:/stock/_v5") / model_path
        model_path = str(model_path)
    
    run_full_pipeline(
        code=code,
        model_path=model_path,
        start_date=start_date,
        end_date=end_date,
        skip_collect=args.skip_collect,
        skip_preprocess=args.skip_preprocess,
        is_train=args.train,
        window_size=args.window_size,
        device=args.device,
        predict_tomorrow=args.tomorrow,
        data_path=args.data
    )

if __name__ == "__main__":
    main()