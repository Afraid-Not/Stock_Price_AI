import pandas as pd
import numpy as np
import argparse
import os
import json
import joblib
from pathlib import Path
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'

# íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸
import catboost as cb

# ë”¥ëŸ¬ë‹ ëª¨ë¸
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.optim import Adam

class TimeSeriesDataset(Dataset):
    """ì‹œê³„ì—´ ë°ì´í„°ì…‹"""
    def __init__(self, X, y, sequence_length=30):
        self.X = X
        self.y = y
        self.sequence_length = sequence_length
        
    def __len__(self):
        return len(self.X) - self.sequence_length + 1
    
    def __getitem__(self, idx):
        seq_X = self.X[idx:idx+self.sequence_length]
        target = self.y[idx+self.sequence_length-1]
        # float32ë¡œ ë³€í™˜í•˜ì—¬ PyTorchì™€ í˜¸í™˜ì„± í™•ë³´
        seq_X = seq_X.astype(np.float32)
        # CrossEntropyLossëŠ” ìŠ¤ì¹¼ë¼ í…ì„œë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ .item() ë˜ëŠ” ì§ì ‘ ë³€í™˜
        return torch.from_numpy(seq_X).float(), torch.tensor(int(target), dtype=torch.long)

class LSTMClassifier(nn.Module):
    """LSTM ë¶„ë¥˜ ëª¨ë¸"""
    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=2, dropout=0.2):
        super(LSTMClassifier, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, 
                           batch_first=True, dropout=dropout if num_layers > 1 else 0)
        self.fc = nn.Linear(hidden_size, num_classes)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # x shape: (batch, seq_len, features)
        lstm_out, _ = self.lstm(x)
        # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ë§Œ ì‚¬ìš©
        last_out = lstm_out[:, -1, :]
        out = self.dropout(last_out)
        out = self.fc(out)
        return out

class EnsembleTrainer:
    def __init__(self, data_path, model_dir="D:/stock/_v8/models", n_splits=5, 
                 sequence_length=30, device='cuda' if torch.cuda.is_available() else 'cpu',
                 catboost_weight=0.5, lstm_weight=0.5):
        self.data_path = data_path
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        self.n_splits = n_splits
        self.kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)
        self.sequence_length = sequence_length
        self.device = device
        self.catboost_weight = catboost_weight
        self.lstm_weight = lstm_weight
        
        self.results = {}
        
    def load_data(self, test_size=50):
        """ë°ì´í„° ë¡œë“œ ë° ë¶„ë¦¬"""
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ: {self.data_path}")
        df = pd.read_csv(self.data_path)
        
        if 'target' not in df.columns:
            raise ValueError("'target' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì œê±°
        if 'ë‚ ì§œ' in df.columns:
            df = df.drop(columns=['ë‚ ì§œ'])
        
        # next_rtnì´ ìˆìœ¼ë©´ ì œê±° (íƒ€ê²Ÿ ìƒì„±ì—ë§Œ ì‚¬ìš©)
        if 'next_rtn' in df.columns:
            df = df.drop(columns=['next_rtn'])
        
        if len(df) <= test_size:
            raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ {test_size + 1}í–‰ í•„ìš”í•©ë‹ˆë‹¤.")
        
        df_train_val = df.iloc[:-test_size].copy()
        df_test = df.iloc[-test_size:].copy()
        
        X_train_val = df_train_val.drop(columns=['target']).values
        y_train_val = df_train_val['target'].values
        
        X_test = df_test.drop(columns=['target']).values
        y_test = df_test['target'].values
        
        print(f"   ì „ì²´ ë°ì´í„°: {len(df)}í–‰ Ã— {X_train_val.shape[1]}í”¼ì²˜")
        print(f"   Train+Val: {len(df_train_val)}í–‰")
        print(f"   Test: {len(df_test)}í–‰")
        print(f"   Target ë¶„í¬: {np.bincount(y_train_val)}")
        
        return X_train_val, y_train_val, X_test, y_test
    
    def train_catboost(self, X_train, y_train, X_val, y_val):
        """CatBoost í•™ìŠµ"""
        print("  ğŸ± CatBoost í•™ìŠµ ì¤‘...")
        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
        pos_count = np.sum(y_train == 1)
        neg_count = np.sum(y_train == 0)
        class_weights = [neg_count / pos_count if pos_count > 0 else 1.0, 1.0]
        
        model = cb.CatBoostClassifier(
            iterations=300,
            learning_rate=0.05,
            depth=6,
            loss_function='Logloss',
            eval_metric='Logloss',
            class_weights=class_weights,
            min_data_in_leaf=20,
            random_seed=42,
            verbose=False
        )
        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=False)
        return model
    
    def train_lstm(self, X_train, y_train, X_val, y_val, input_size):
        """LSTM í•™ìŠµ"""
        print("  ğŸ”„ LSTM í•™ìŠµ ì¤‘...")
        
        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        train_dataset = TimeSeriesDataset(X_train, y_train, self.sequence_length)
        val_dataset = TimeSeriesDataset(X_val, y_val, self.sequence_length)
        
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
        
        model = LSTMClassifier(input_size=input_size, hidden_size=64, num_layers=2, num_classes=2).to(self.device)
        
        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬: Weighted Loss
        pos_count = np.sum(y_train == 1)
        neg_count = np.sum(y_train == 0)
        if pos_count > 0 and neg_count > 0:
            weight = torch.tensor([neg_count / pos_count, 1.0], dtype=torch.float32).to(self.device)
        else:
            weight = torch.tensor([1.0, 1.0], dtype=torch.float32).to(self.device)
        criterion = nn.CrossEntropyLoss(weight=weight)
        optimizer = Adam(model.parameters(), lr=0.001)
        
        best_val_acc = 0
        patience = 10
        patience_counter = 0
        
        for epoch in range(50):
            # Train
            model.train()
            train_loss = 0
            for batch_X, batch_y in train_loader:
                batch_X = batch_X.to(self.device).float()
                batch_y = batch_y.to(self.device)
                optimizer.zero_grad()
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            # Validation
            model.eval()
            val_correct = 0
            val_total = 0
            with torch.no_grad():
                for batch_X, batch_y in val_loader:
                    batch_X = batch_X.to(self.device).float()
                    batch_y = batch_y.to(self.device)
                    outputs = model(batch_X)
                    _, predicted = torch.max(outputs.data, 1)
                    val_total += batch_y.size(0)
                    val_correct += (predicted == batch_y).sum().item()
            
            val_acc = val_correct / val_total if val_total > 0 else 0
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                best_model_state = model.state_dict().copy()
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    break
        
        model.load_state_dict(best_model_state)
        return model
    
    def predict_catboost_proba(self, model, X):
        """CatBoost ì˜ˆì¸¡ í™•ë¥ """
        return model.predict_proba(X)
    
    def predict_lstm_proba(self, model, X, y):
        """LSTM ì˜ˆì¸¡ í™•ë¥ """
        model.eval()
        # ì „ì²´ ë°ì´í„°ë¥¼ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ (float32ë¡œ ë³€í™˜)
        if len(X) < self.sequence_length:
            padding = np.tile(X[0:1], (self.sequence_length - len(X), 1))
            X_padded = np.vstack([padding, X]).astype(np.float32)
            y_padded = np.concatenate([[y[0]] * (self.sequence_length - len(y)), y])
        else:
            X_padded = X.astype(np.float32)
            y_padded = y
        
        dataset = TimeSeriesDataset(X_padded, y_padded, self.sequence_length)
        loader = DataLoader(dataset, batch_size=32, shuffle=False)
        
        probabilities = []
        with torch.no_grad():
            for batch_X, _ in loader:
                batch_X = batch_X.to(self.device).float()
                outputs = model(batch_X)
                probs = torch.softmax(outputs, dim=1)
                probabilities.append(probs.cpu().numpy())
        
        prob_array = np.vstack(probabilities)
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ì•ë¶€ë¶„ì€ ì˜ˆì¸¡ ë¶ˆê°€í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ í™•ë¥ ë¡œ íŒ¨ë”©
        if len(prob_array) > 0:
            padding = np.tile(prob_array[0:1], (self.sequence_length - 1, 1))
            return np.vstack([padding, prob_array])
        else:
            return np.array([])
    
    def ensemble_predict(self, catboost_model, lstm_model, X_test, y_test):
        """ì•™ìƒë¸” ì˜ˆì¸¡ (ê°€ì¤‘ í‰ê· )"""
        # CatBoost ì˜ˆì¸¡ í™•ë¥ 
        cb_proba = self.predict_catboost_proba(catboost_model, X_test)
        
        # LSTM ì˜ˆì¸¡ í™•ë¥ 
        lstm_proba = self.predict_lstm_proba(lstm_model, X_test, y_test)
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ì•ë¶€ë¶„ ì œê±°
        if len(lstm_proba) > len(cb_proba):
            lstm_proba_trimmed = lstm_proba[self.sequence_length-1:]
        else:
            lstm_proba_trimmed = lstm_proba
        
        # ê¸¸ì´ ë§ì¶”ê¸°
        min_len = min(len(cb_proba), len(lstm_proba_trimmed))
        cb_proba = cb_proba[:min_len]
        lstm_proba_trimmed = lstm_proba_trimmed[:min_len]
        
        # ê°€ì¤‘ í‰ê· 
        ensemble_proba = (self.catboost_weight * cb_proba + 
                         self.lstm_weight * lstm_proba_trimmed)
        
        # í´ë˜ìŠ¤ ì˜ˆì¸¡
        ensemble_pred = np.argmax(ensemble_proba, axis=1)
        
        return ensemble_pred, ensemble_proba
    
    def evaluate_model(self, y_true, y_pred, model_name):
        """ëª¨ë¸ í‰ê°€"""
        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, average='weighted')
        precision = precision_score(y_true, y_pred, average='weighted')
        recall = recall_score(y_true, y_pred, average='weighted')
        
        try:
            auc = roc_auc_score(y_true, y_pred)
        except:
            auc = 0.0
        
        return {
            'accuracy': acc,
            'f1_score': f1,
            'precision': precision,
            'recall': recall,
            'auc': auc
        }
    
    def train_and_evaluate(self, X_train_val, y_train_val, X_test, y_test):
        """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ CatBoost + LSTM ì•™ìƒë¸” í•™ìŠµ ì‹œì‘")
        print(f"   CatBoost ê°€ì¤‘ì¹˜: {self.catboost_weight}")
        print(f"   LSTM ê°€ì¤‘ì¹˜: {self.lstm_weight}")
        print(f"{'='*60}\n")
        
        input_size = X_train_val.shape[1]
        all_results = {}
        
        # KFoldë¡œ í•™ìŠµ
        for fold_idx, (train_idx, val_idx) in enumerate(self.kfold.split(X_train_val)):
            print(f"\nğŸ“Š Fold {fold_idx + 1}/{self.n_splits}")
            print("-" * 60)
            
            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]
            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]
            
            # 1. CatBoost í•™ìŠµ
            catboost_model = self.train_catboost(X_train, y_train, X_val, y_val)
            
            # 2. LSTM í•™ìŠµ
            lstm_model = self.train_lstm(X_train, y_train, X_val, y_val, input_size)
            
            # 3. ê°œë³„ ëª¨ë¸ í‰ê°€
            cb_pred = catboost_model.predict(X_test)
            cb_metrics = self.evaluate_model(y_test, cb_pred, 'CatBoost')
            print(f"  âœ… CatBoost - Acc: {cb_metrics['accuracy']:.4f}, F1: {cb_metrics['f1_score']:.4f}")
            
            lstm_pred, _ = self.ensemble_predict(catboost_model, lstm_model, X_test, y_test)
            # ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ì•ë¶€ë¶„ ì œê±°
            y_test_trimmed = y_test[self.sequence_length-1:]
            lstm_pred_trimmed = lstm_pred[self.sequence_length-1:]
            min_len = min(len(y_test_trimmed), len(lstm_pred_trimmed))
            lstm_metrics = self.evaluate_model(y_test_trimmed[:min_len], lstm_pred_trimmed[:min_len], 'LSTM')
            print(f"  âœ… LSTM - Acc: {lstm_metrics['accuracy']:.4f}, F1: {lstm_metrics['f1_score']:.4f}")
            
            # 4. ì•™ìƒë¸” ì˜ˆì¸¡
            ensemble_pred, ensemble_proba = self.ensemble_predict(catboost_model, lstm_model, X_test, y_test)
            
            # ê¸¸ì´ ë§ì¶”ê¸°
            min_len = min(len(y_test), len(ensemble_pred))
            y_test_final = y_test[:min_len]
            ensemble_pred_final = ensemble_pred[:min_len]
            
            ensemble_metrics = self.evaluate_model(y_test_final, ensemble_pred_final, 'Ensemble')
            print(f"  âœ… Ensemble - Acc: {ensemble_metrics['accuracy']:.4f}, F1: {ensemble_metrics['f1_score']:.4f}")
            
            all_results[f'fold_{fold_idx+1}'] = {
                'CatBoost': cb_metrics,
                'LSTM': lstm_metrics,
                'Ensemble': ensemble_metrics
            }
        
        # ê²°ê³¼ ì§‘ê³„
        self.aggregate_results(all_results)
        
        return all_results
    
    def aggregate_results(self, all_results):
        """ê²°ê³¼ ì§‘ê³„ ë° ì €ì¥"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ê²°ê³¼ ì§‘ê³„")
        print(f"{'='*60}\n")
        
        model_names = ['CatBoost', 'LSTM', 'Ensemble']
        metrics_list = ['accuracy', 'f1_score', 'precision', 'recall', 'auc']
        
        summary = {}
        
        for model_name in model_names:
            model_metrics = {metric: [] for metric in metrics_list}
            
            for fold_key, fold_results in all_results.items():
                if model_name in fold_results:
                    for metric in metrics_list:
                        if metric in fold_results[model_name]:
                            model_metrics[metric].append(fold_results[model_name][metric])
            
            if any(len(v) > 0 for v in model_metrics.values()):
                summary[model_name] = {
                    metric: {
                        'mean': np.mean(model_metrics[metric]),
                        'std': np.std(model_metrics[metric])
                    }
                    for metric in metrics_list if len(model_metrics[metric]) > 0
                }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"{'ëª¨ë¸':<15} {'Accuracy':<15} {'F1 Score':<15} {'Precision':<15} {'Recall':<15} {'AUC':<15}")
        print("-" * 90)
        
        for model_name, metrics in summary.items():
            acc = metrics.get('accuracy', {}).get('mean', 0)
            f1 = metrics.get('f1_score', {}).get('mean', 0)
            prec = metrics.get('precision', {}).get('mean', 0)
            rec = metrics.get('recall', {}).get('mean', 0)
            auc = metrics.get('auc', {}).get('mean', 0)
            
            print(f"{model_name:<15} {acc:.4f}Â±{metrics.get('accuracy', {}).get('std', 0):.4f}  "
                  f"{f1:.4f}Â±{metrics.get('f1_score', {}).get('std', 0):.4f}  "
                  f"{prec:.4f}Â±{metrics.get('precision', {}).get('std', 0):.4f}  "
                  f"{rec:.4f}Â±{metrics.get('recall', {}).get('std', 0):.4f}  "
                  f"{auc:.4f}Â±{metrics.get('auc', {}).get('std', 0):.4f}")
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = self.model_dir / f"ensemble_results_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump({
                'weights': {
                    'catboost': self.catboost_weight,
                    'lstm': self.lstm_weight
                },
                'summary': summary,
                'detailed_results': all_results
            }, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}")
        
        # ì‹œê°í™”
        self.plot_comparison(summary, timestamp)
        
        self.results = summary
    
    def plot_comparison(self, summary, timestamp):
        """ê²°ê³¼ ë¹„êµ ì‹œê°í™”"""
        model_names = list(summary.keys())
        metrics = ['accuracy', 'f1_score', 'precision', 'recall']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        for idx, metric in enumerate(metrics):
            ax = axes[idx]
            means = [summary[model][metric]['mean'] for model in model_names]
            stds = [summary[model][metric]['std'] for model in model_names]
            
            x_pos = np.arange(len(model_names))
            ax.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7)
            ax.set_xlabel('Model')
            ax.set_ylabel(metric.capitalize())
            ax.set_title(f'{metric.capitalize()} Comparison')
            ax.set_xticks(x_pos)
            ax.set_xticklabels(model_names, rotation=45, ha='right')
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot_file = self.model_dir / f"ensemble_comparison_{timestamp}.png"
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š ì‹œê°í™” ì €ì¥: {plot_file}")
        plt.close()

def main():
    parser = argparse.ArgumentParser(description="CatBoost + LSTM ì•™ìƒë¸” í•™ìŠµ")
    parser.add_argument("--data", type=str, required=True, help="ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model-dir", type=str, default="D:/stock/_v8/models", help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--n-splits", type=int, default=5, help="KFold ë¶„í•  ìˆ˜")
    parser.add_argument("--sequence-length", type=int, default=30, help="ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ê¸¸ì´")
    parser.add_argument("--test-size", type=int, default=50, help="í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í¬ê¸°")
    parser.add_argument("--catboost-weight", type=float, default=0.5, help="CatBoost ê°€ì¤‘ì¹˜")
    parser.add_argument("--lstm-weight", type=float, default=0.5, help="LSTM ê°€ì¤‘ì¹˜")
    
    args = parser.parse_args()
    
    # ê°€ì¤‘ì¹˜ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”
    total_weight = args.catboost_weight + args.lstm_weight
    if total_weight > 0:
        args.catboost_weight /= total_weight
        args.lstm_weight /= total_weight
    
    trainer = EnsembleTrainer(
        data_path=args.data,
        model_dir=args.model_dir,
        n_splits=args.n_splits,
        sequence_length=args.sequence_length,
        catboost_weight=args.catboost_weight,
        lstm_weight=args.lstm_weight
    )
    
    X_train_val, y_train_val, X_test, y_test = trainer.load_data(test_size=args.test_size)
    results = trainer.train_and_evaluate(X_train_val, y_train_val, X_test, y_test)
    
    print(f"\n{'='*60}")
    print(f"âœ… ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ ì™„ë£Œ!")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()




