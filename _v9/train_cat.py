"""
CatBoost ì „ìš© í•™ìŠµ + Optuna íŠœë‹
- 9ê°œ ì¢…ëª©: ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, NAVER, ì¹´ì¹´ì˜¤, ì‚¼ì„±SDI, LGì „ì, LGë””ìŠ¤í”Œë ˆì´, ì‚¼ì„±SDS, KT
- íƒ€ê²Ÿ: ì˜¤ëŠ˜ ì¢…ê°€ â†’ ë‚´ì¼ ì¢…ê°€ (1% ì´ìƒ ìƒìŠ¹/í•˜ë½)
"""
import pandas as pd
import numpy as np
import random
import warnings
import argparse
import optuna
from optuna.samplers import TPESampler
warnings.filterwarnings('ignore')

from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder
from catboost import CatBoostClassifier
import joblib
import os
from datetime import datetime


def set_seed(seed: int):
    """ëª¨ë“  ëœë¤ ì‹œë“œ ê³ ì •"""
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)


# 9ê°œ ì¢…ëª© ì½”ë“œ
TARGET_STOCKS = [
    '005930',  # ì‚¼ì„±ì „ì
    '000660',  # SKí•˜ì´ë‹‰ìŠ¤
    '035420',  # NAVER
    '035720',  # ì¹´ì¹´ì˜¤
    '006400',  # ì‚¼ì„±SDI
    '066570',  # LGì „ì
    '034220',  # LGë””ìŠ¤í”Œë ˆì´
    '018260',  # ì‚¼ì„±SDS
    '030200',  # KT
]

STOCK_NAMES = {
    '005930': 'ì‚¼ì„±ì „ì',
    '000660': 'SKí•˜ì´ë‹‰ìŠ¤',
    '035420': 'NAVER',
    '035720': 'ì¹´ì¹´ì˜¤',
    '006400': 'ì‚¼ì„±SDI',
    '066570': 'LGì „ì',
    '034220': 'LGë””ìŠ¤í”Œë ˆì´',
    '018260': 'ì‚¼ì„±SDS',
    '030200': 'KT',
}


class CatBoostTrainer:
    def __init__(self, data_path, n_splits=5, lag_days=[1, 3, 5], 
                 target_threshold=0.01, seed=42):
        self.data_path = data_path
        self.n_splits = n_splits
        self.lag_days = lag_days
        self.target_threshold = target_threshold
        self.seed = seed
        self.model = None
        self.label_encoder = LabelEncoder()
        self.best_params = None
        
        set_seed(seed)
        
        self.model_dir = 'models_catboost'
        os.makedirs(self.model_dir, exist_ok=True)
        os.makedirs('tuning_results', exist_ok=True)
        
    def load_data(self):
        """9ê°œ ì¢…ëª©ë§Œ ë¡œë“œ"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(self.data_path)
        
        # stock_codeë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        df['stock_code'] = df['stock_code'].astype(str).str.zfill(6)
        
        # 9ê°œ ì¢…ëª©ë§Œ í•„í„°ë§
        df = df[df['stock_code'].isin(TARGET_STOCKS)].copy()
        
        # ë‚ ì§œ ì •ë ¬ - TimeSeriesSplitì„ ìœ„í•´ ë‚ ì§œ ìš°ì„ !
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'].astype(str), format='%Y%m%d', errors='coerce')
        df = df.dropna(subset=['ë‚ ì§œ'])
        df = df.sort_values(['ë‚ ì§œ', 'stock_code']).reset_index(drop=True)
        
        print(f"   ì›ë³¸ ë°ì´í„°: {len(df):,}ê±´")
        print(f"   ê¸°ê°„: {df['ë‚ ì§œ'].min().date()} ~ {df['ë‚ ì§œ'].max().date()}")
        print(f"   ì¢…ëª© ìˆ˜: {df['stock_code'].nunique()}ê°œ")
        
        # íƒ€ê²Ÿ ì¬ì •ì˜
        if self.target_threshold is not None:
            df = self.redefine_target(df)
        
        # Lag í”¼ì²˜ ì¶”ê°€
        df = self.add_lag_features(df)
        
        print(f"   Lag í”¼ì²˜ ì¶”ê°€ í›„: {len(df):,}ê±´")
        print(f"   í´ë˜ìŠ¤ ë¶„í¬: 0={len(df[df['target']==0]):,}, 1={len(df[df['target']==1]):,}")
        
        return df
    
    def redefine_target(self, df):
        """íƒ€ê²Ÿ ì¬ì •ì˜: ì˜¤ëŠ˜ ì¢…ê°€ â†’ ë‚´ì¼ ì¢…ê°€"""
        print(f"\nğŸ¯ íƒ€ê²Ÿ ì¬ì •ì˜ (ì„ê³„ê°’: Â±{self.target_threshold*100:.1f}%)")
        
        if 'next_rtn' not in df.columns:
            raise ValueError("next_rtn ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        df = df.dropna(subset=['next_rtn'])
        before_filter = len(df)
        
        df_up = df[df['next_rtn'] >= self.target_threshold].copy()
        df_up['target'] = 1
        
        df_down = df[df['next_rtn'] <= -self.target_threshold].copy()
        df_down['target'] = 0
        
        df_filtered = pd.concat([df_up, df_down], ignore_index=True)
        df_filtered = df_filtered.sort_values(['ë‚ ì§œ', 'stock_code']).reset_index(drop=True)
        df_filtered = df_filtered.drop(columns=['next_rtn'])
        
        excluded = before_filter - len(df_filtered)
        print(f"   ìƒìŠ¹: {len(df_up):,}ê±´, í•˜ë½: {len(df_down):,}ê±´")
        print(f"   ì œì™¸ (ë…¸ì´ì¦ˆ): {excluded:,}ê±´ ({excluded/before_filter*100:.1f}%)")
        
        return df_filtered
    
    def add_lag_features(self, df):
        """Lag í”¼ì²˜ ì¶”ê°€"""
        print(f"\nğŸ“Š Lag í”¼ì²˜ ìƒì„± ì¤‘... (lag_days: {self.lag_days})")
        
        base_features = [
            'open_gap', 'high_ratio', 'low_ratio', 'volatility',
            'ê°œì¸_ì²´ê²°ê°•ë„', 'ì™¸êµ­ì¸_ì²´ê²°ê°•ë„', 'ê¸°ê´€ê³„_ì²´ê²°ê°•ë„',
            'vol_ratio', 'rsi'
        ]
        base_features = [f for f in base_features if f in df.columns]
        
        lag_dfs = []
        for stock_code in df['stock_code'].unique():
            stock_df = df[df['stock_code'] == stock_code].copy()
            stock_df = stock_df.sort_values('ë‚ ì§œ')
            
            for lag in self.lag_days:
                for feat in base_features:
                    stock_df[f'{feat}_lag{lag}'] = stock_df[feat].shift(lag)
            
            lag_dfs.append(stock_df)
        
        df_with_lag = pd.concat(lag_dfs, ignore_index=True)
        
        before_drop = len(df_with_lag)
        df_with_lag = df_with_lag.dropna()
        
        # ë‚ ì§œ ìš°ì„  ì •ë ¬
        df_with_lag = df_with_lag.sort_values(['ë‚ ì§œ', 'stock_code']).reset_index(drop=True)
        
        new_features = [c for c in df_with_lag.columns if '_lag' in c]
        print(f"   ìƒì„±ëœ Lag í”¼ì²˜ ìˆ˜: {len(new_features)}ê°œ")
        print(f"   NaN ì œê±°: {before_drop - len(df_with_lag):,}ê±´")
        
        return df_with_lag
    
    def get_features(self, df):
        """í”¼ì²˜ ì»¬ëŸ¼ ì¶”ì¶œ"""
        exclude_cols = ['ë‚ ì§œ', 'target', 'stock_code', 'stock_code_encoded',
                        'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ',
                        'stock_name', 'next_rtn']
        
        feature_cols = [c for c in df.columns if c not in exclude_cols]
        return feature_cols
    
    def prepare_data(self):
        """ë°ì´í„° ì¤€ë¹„"""
        df = self.load_data()
        
        feature_cols = self.get_features(df)
        print(f"\nğŸ“Š í”¼ì²˜ ìˆ˜: {len(feature_cols)}ê°œ")
        
        # stock_code ì¸ì½”ë”©
        df['stock_code_encoded'] = self.label_encoder.fit_transform(df['stock_code'])
        if 'stock_code_encoded' not in feature_cols:
            feature_cols.append('stock_code_encoded')
        
        X = df[feature_cols].values
        y = df['target'].values
        
        return X, y, feature_cols
    
    def tune(self, n_trials=50, metric='f1'):
        """Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
        print("\n" + "=" * 60)
        print("ğŸ”¬ CatBoost Optuna íŠœë‹")
        print("=" * 60)
        print(f"ì‹œë“œ: {self.seed}")
        print(f"ì‹œí–‰ íšŸìˆ˜: {n_trials}")
        print(f"CV Folds: {self.n_splits}")
        print(f"í‰ê°€ ì§€í‘œ: {metric.upper()}")
        
        X, y, _ = self.prepare_data()
        
        def objective(trial):
            params = {
                'iterations': trial.suggest_int('iterations', 100, 1000),
                'depth': trial.suggest_int('depth', 4, 10),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),
                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),
                'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),
                'border_count': trial.suggest_int('border_count', 32, 255),
                'random_state': self.seed,
                'eval_metric': 'AUC',
                'early_stopping_rounds': 50,
                'verbose': False
            }
            
            tscv = TimeSeriesSplit(n_splits=self.n_splits)
            scores = []
            
            for train_idx, val_idx in tscv.split(X):
                X_train, X_val = X[train_idx], X[val_idx]
                y_train, y_val = y[train_idx], y[val_idx]
                
                model = CatBoostClassifier(**params)
                model.fit(X_train, y_train, eval_set=(X_val, y_val))
                
                y_pred = model.predict(X_val)
                y_prob = model.predict_proba(X_val)[:, 1]
                
                if metric == 'f1':
                    score = f1_score(y_val, y_pred)
                elif metric == 'auc':
                    score = roc_auc_score(y_val, y_prob)
                else:
                    score = accuracy_score(y_val, y_pred)
                
                scores.append(score)
            
            return np.mean(scores)
        
        study = optuna.create_study(
            direction='maximize',
            sampler=TPESampler(seed=self.seed)
        )
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)
        
        self.best_params = study.best_params
        
        print(f"\nâœ… ìµœì  {metric.upper()}: {study.best_value:.4f}")
        print("   ìµœì  íŒŒë¼ë¯¸í„°:")
        for k, v in study.best_params.items():
            print(f"      {k}: {v}")
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result = {
            'best_params': study.best_params,
            f'best_{metric}': study.best_value,
            'metric': metric
        }
        
        result_path = f"tuning_results/catboost_{timestamp}.pkl"
        joblib.dump(result, result_path)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {result_path}")
        
        # í…ìŠ¤íŠ¸ë¡œë„ ì €ì¥
        txt_path = f"tuning_results/catboost_params_{timestamp}.txt"
        with open(txt_path, 'w') as f:
            f.write(f"Seed: {self.seed}\n")
            f.write(f"Trials: {n_trials}\n")
            f.write(f"Metric: {metric}\n")
            f.write(f"Best {metric}: {study.best_value:.4f}\n\n")
            for k, v in study.best_params.items():
                f.write(f"{k}: {v}\n")
        print(f"ğŸ’¾ íŒŒë¼ë¯¸í„° ì €ì¥: {txt_path}")
        
        return study.best_params
    
    def train(self, params=None):
        """í•™ìŠµ ì‹¤í–‰"""
        print("\n" + "=" * 60)
        print("ğŸš€ CatBoost í•™ìŠµ ì‹œì‘")
        print("=" * 60)
        
        X, y, feature_cols = self.prepare_data()
        
        # íŒŒë¼ë¯¸í„° ì„¤ì •
        if params is None:
            params = self.best_params if self.best_params else {}
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        default_params = {
            'iterations': 500,
            'depth': 6,
            'learning_rate': 0.05,
            'l2_leaf_reg': 3.0,
            'bagging_temperature': 0.5,
            'random_strength': 0.1,
            'random_state': self.seed,
            'eval_metric': 'AUC',
            'early_stopping_rounds': 50,
            'verbose': False
        }
        
        for k, v in default_params.items():
            if k not in params:
                params[k] = v
        
        print("\nğŸ“‹ ì‚¬ìš© íŒŒë¼ë¯¸í„°:")
        for k, v in params.items():
            print(f"   {k}: {v}")
        
        # TimeSeriesSplit í•™ìŠµ
        tscv = TimeSeriesSplit(n_splits=self.n_splits)
        all_metrics = []
        
        print(f"\nğŸ“… {self.n_splits}-Fold TimeSeriesSplit í•™ìŠµ")
        print("=" * 60)
        
        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
            print(f"\n[Fold {fold + 1}/{self.n_splits}]")
            
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            
            print(f"   í•™ìŠµ: {len(train_idx):,}ê±´, ê²€ì¦: {len(val_idx):,}ê±´")
            
            model = CatBoostClassifier(**params)
            model.fit(X_train, y_train, eval_set=(X_val, y_val))
            
            y_pred = model.predict(X_val)
            y_prob = model.predict_proba(X_val)[:, 1]
            
            metrics = {
                'accuracy': accuracy_score(y_val, y_pred),
                'precision': precision_score(y_val, y_pred, zero_division=0),
                'recall': recall_score(y_val, y_pred, zero_division=0),
                'f1': f1_score(y_val, y_pred, zero_division=0),
                'auc': roc_auc_score(y_val, y_prob) if len(np.unique(y_val)) > 1 else 0.5
            }
            all_metrics.append(metrics)
            
            print(f"   Acc={metrics['accuracy']:.4f}, F1={metrics['f1']:.4f}, AUC={metrics['auc']:.4f}")
            
            # ë§ˆì§€ë§‰ Fold ëª¨ë¸ ì €ì¥
            if fold == self.n_splits - 1:
                self.model = model
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ“‹ êµì°¨ ê²€ì¦ ê²°ê³¼ (í‰ê·  Â± í‘œì¤€í¸ì°¨)")
        print("=" * 60)
        
        summary = {'seed': self.seed}
        for metric_name in ['accuracy', 'precision', 'recall', 'f1', 'auc']:
            values = [m[metric_name] for m in all_metrics]
            mean_val = np.mean(values)
            std_val = np.std(values)
            summary[f'{metric_name}_mean'] = mean_val
            summary[f'{metric_name}_std'] = std_val
            print(f"   {metric_name:10s}: {mean_val:.4f} Â± {std_val:.4f}")
        
        # ê²°ê³¼ CSVì— ì¶”ê°€
        summary['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        results_file = f"{self.model_dir}/all_results.csv"
        
        if os.path.exists(results_file):
            df_existing = pd.read_csv(results_file)
            df_new = pd.DataFrame([summary])
            df_all = pd.concat([df_existing, df_new], ignore_index=True)
        else:
            df_all = pd.DataFrame([summary])
        
        df_all.to_csv(results_file, index=False)
        print(f"\nğŸ“Š ê²°ê³¼ ì¶”ê°€: {results_file}")
        
        # ëª¨ë¸ ì €ì¥
        self.save_model(params)
        
        return all_metrics, summary
    
    def save_model(self, params):
        """ëª¨ë¸ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        print("\n" + "=" * 60)
        print("ğŸ’¾ ëª¨ë¸ ì €ì¥")
        print("=" * 60)
        
        # ëª¨ë¸ ì €ì¥
        model_path = f"{self.model_dir}/catboost_{timestamp}.pkl"
        joblib.dump(self.model, model_path)
        print(f"   ëª¨ë¸: {model_path}")
        
        # LabelEncoder ì €ì¥
        le_path = f"{self.model_dir}/label_encoder_{timestamp}.pkl"
        joblib.dump(self.label_encoder, le_path)
        print(f"   LabelEncoder: {le_path}")
        
        # íŒŒë¼ë¯¸í„° ì €ì¥
        params_path = f"{self.model_dir}/params_{timestamp}.pkl"
        joblib.dump(params, params_path)
        print(f"   íŒŒë¼ë¯¸í„°: {params_path}")
        
        # ì¢…ëª© ëª©ë¡ ì €ì¥
        stocks_path = f"{self.model_dir}/target_stocks_{timestamp}.txt"
        with open(stocks_path, 'w', encoding='utf-8') as f:
            for code in TARGET_STOCKS:
                f.write(f"{code},{STOCK_NAMES[code]}\n")
        print(f"   ì¢…ëª© ëª©ë¡: {stocks_path}")


def main():
    parser = argparse.ArgumentParser(description="CatBoost ì „ìš© í•™ìŠµ")
    parser.add_argument("--data", type=str, default="_data/merged_with_macro.csv")
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--n_splits", type=int, default=5)
    parser.add_argument("--threshold", type=float, default=0.01)
    
    # ëª¨ë“œ ì„ íƒ
    parser.add_argument("--mode", type=str, choices=['tune', 'train', 'all'], 
                        default='all', help="tune: íŠœë‹ë§Œ, train: í•™ìŠµë§Œ, all: ë‘˜ ë‹¤")
    parser.add_argument("--n_trials", type=int, default=50, help="Optuna ì‹œí–‰ íšŸìˆ˜")
    parser.add_argument("--metric", type=str, choices=['f1', 'auc', 'accuracy'],
                        default='f1', help="ìµœì í™” ì§€í‘œ")
    
    # ì§ì ‘ íŒŒë¼ë¯¸í„° ì§€ì • (train ëª¨ë“œìš©)
    parser.add_argument("--iterations", type=int, default=None)
    parser.add_argument("--depth", type=int, default=None)
    parser.add_argument("--learning_rate", type=float, default=None)
    
    args = parser.parse_args()
    
    print(f"ğŸ“‚ ë°ì´í„°: {args.data}")
    print(f"ğŸ² ì‹œë“œ: {args.seed}")
    print(f"ğŸ“Š ëª¨ë“œ: {args.mode}")
    
    trainer = CatBoostTrainer(
        data_path=args.data,
        n_splits=args.n_splits,
        target_threshold=args.threshold,
        seed=args.seed
    )
    
    # ì§ì ‘ íŒŒë¼ë¯¸í„° ì§€ì •
    custom_params = {}
    if args.iterations:
        custom_params['iterations'] = args.iterations
    if args.depth:
        custom_params['depth'] = args.depth
    if args.learning_rate:
        custom_params['learning_rate'] = args.learning_rate
    
    if args.mode == 'tune':
        trainer.tune(n_trials=args.n_trials, metric=args.metric)
        
    elif args.mode == 'train':
        trainer.train(params=custom_params if custom_params else None)
        
    elif args.mode == 'all':
        # íŠœë‹ í›„ í•™ìŠµ
        best_params = trainer.tune(n_trials=args.n_trials, metric=args.metric)
        trainer.train(params=best_params)
    
    print("\n" + "=" * 60)
    print("âœ… ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()

