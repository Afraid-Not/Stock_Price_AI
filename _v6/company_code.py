# 2026ë…„ 1ì›” ê¸°ì¤€ ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
stock_dict = {
    # --- KOSPI Top 20 ---
    "ì‚¼ì„±ì „ì": "005930", #
    "SKí•˜ì´ë‹‰ìŠ¤": "000660", #
    "í˜„ëŒ€ì°¨": "005380", #
    "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤": "012450",
    "ê¸°ì•„": "000270", #
    "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°": "034020", 
    "ì‚¼ì„±ë¬¼ì‚°": "028260", #
    "KBê¸ˆìœµ": "105560", #
    "ì…€íŠ¸ë¦¬ì˜¨": "068270", #
    "í•œí™”ì˜¤ì…˜": "042660", #
    "í˜„ëŒ€ëª¨ë¹„ìŠ¤": "012330", #
    "NAVER": "035420", #
    "ì‹ í•œì§€ì£¼": "055550", #
    "í•œêµ­ì „ë ¥": "015760", #
    "ê³ ë ¤ì•„ì—°": "010130", #
    "POSCOí™€ë”©ìŠ¤": "005490", #

    # --- KOSDAQ Top 20 ---
    "ì—ì½”í”„ë¡œë¹„ì— ": "247540", #
    "ì—ì½”í”„ë¡œ": "086520", #
    "ì•Œí…Œì˜¤ì  ": "196170", 
    "ë¦¬ê°€ì¼ë°”ì´ì˜¤": "141080", #
    "ì‚¼ì²œë‹¹ì œì•½": "000250", #
    "ë¦¬ë…¸ê³µì—…": "058470", #
    "í©íŠ¸ë¡ ": "087010", #
    "HLB": "028300", #
    "íŒŒë§ˆë¦¬ì„œì¹˜": "214450", 
    "ì…€íŠ¸ë¦¬ì˜¨ì œì•½": "068760",
    "í´ë˜ì‹œìŠ¤": "214150",
    "JYP Ent.": "035900",
    "SM": "041510",
    "ë™ì§„ì„ë¯¸ì¼": "005290",
    "ì‹¤ë¦¬ì½˜íˆ¬": "257720",
    "ISC": "095340"
}

def batch_create_datasets(start_date, end_date, is_train=True):
    """
    ëª¨ë“  ì¢…ëª©ì— ëŒ€í•´ ë°ì´í„°ì…‹ ìƒì„±
    
    Args:
        start_date: ì‹œì‘ì¼ (YYYYMMDD)
        end_date: ì¢…ë£Œì¼ (YYYYMMDD)
        is_train: ìŠ¤ì¼€ì¼ëŸ¬ ì‹ ê·œ í•™ìŠµ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    """
    from create_stock_dataset import run_full_pipeline
    
    codes = list(stock_dict.values())
    total = len(codes)
    success_count = 0
    fail_count = 0
    failed_codes = []
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Batch Dataset Creation Started")
    print(f"{'='*60}")
    print(f"Total Companies: {total}")
    print(f"Date Range: {start_date} ~ {end_date}")
    print(f"Train Mode: {is_train}")
    print(f"{'='*60}\n")
    
    for idx, code in enumerate(codes, 1):
        company_name = [k for k, v in stock_dict.items() if v == code][0]
        print(f"\n{'='*60}")
        print(f"[{idx}/{total}] {company_name} ({code})")
        print(f"{'='*60}")
        
        try:
            run_full_pipeline(code, start_date, end_date, is_train)
            success_count += 1
            print(f"âœ… [{idx}/{total}] {company_name} ({code}) ì™„ë£Œ")
        except Exception as e:
            fail_count += 1
            failed_codes.append((company_name, code, str(e)))
            print(f"âŒ [{idx}/{total}] {company_name} ({code}) ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ Batch Processing Summary")
    print(f"{'='*60}")
    print(f"Total:        {total}")
    print(f"Success:      {success_count}")
    print(f"Failed:       {fail_count}")
    
    if failed_codes:
        print(f"\nâŒ Failed Companies:")
        for name, code, error in failed_codes:
            print(f"   - {name} ({code}): {error}")
    
    print(f"\nâœ… Batch processing completed!")

if __name__ == "__main__":
    import argparse
    from datetime import datetime, timedelta
    
    parser = argparse.ArgumentParser(description="ëª¨ë“  ì¢…ëª© ë°ì´í„°ì…‹ ì¼ê´„ ìƒì„±")
    parser.add_argument("--start", type=str, default=None, help="ì‹œì‘ì¼ (YYYYMMDD, ë¯¸ì§€ì •ì‹œ 1ë…„ ì „)")
    parser.add_argument("--end", type=str, default=None, help="ì¢…ë£Œì¼ (YYYYMMDD, ë¯¸ì§€ì •ì‹œ ì˜¤ëŠ˜)")
    parser.add_argument("--train", action="store_true", help="ìŠ¤ì¼€ì¼ëŸ¬ ì‹ ê·œ í•™ìŠµ ì—¬ë¶€")
    
    args = parser.parse_args()
    
    # ë‚ ì§œ ê¸°ë³¸ê°’ ì„¤ì •
    if args.end is None:
        args.end = datetime.now().strftime("%Y%m%d")
    
    if args.start is None:
        end_date = datetime.strptime(args.end, "%Y%m%d")
        start_date = end_date - timedelta(days=365)  # 1ë…„ ì „
        args.start = start_date.strftime("%Y%m%d")
    
    batch_create_datasets(args.start, args.end, args.train)