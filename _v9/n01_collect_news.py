"""
30ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
í•œíˆ¬ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœê·¼ 1ë…„ì¹˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""
import pandas as pd
import requests
import json
import time
import os
import sys
import argparse
from datetime import datetime, timedelta
from dotenv import load_dotenv

# .env ë¡œë“œ
load_dotenv('D:/stock/.env')

# s00_get_token import
from s00_get_token import get_access_token

# ì„¤ì •
APP_KEY = os.getenv("REAL_APP_KEY")
APP_SECRET = os.getenv("REAL_APP_SECRET")
BASE_URL = "https://openapi.koreainvestment.com:9443"
TR_ID_NEWS_TITLE = "FHKST01011800"

# ì»¬ëŸ¼ ë§¤í•‘
COLUMN_MAPPING = {
    'cntt_usiq_srno': 'ë‚´ìš©_ì¡°íšŒìš©_ì¼ë ¨ë²ˆí˜¸',
    'news_ofer_entp_code': 'ë‰´ìŠ¤_ì œê³µ_ì—…ì²´_ì½”ë“œ',
    'data_dt': 'ì‘ì„±ì¼ì',
    'data_tm': 'ì‘ì„±ì‹œê°„',
    'hts_pbnt_titl_cntt': 'HTS_ê³µì‹œ_ì œëª©_ë‚´ìš©',
    'news_lrdv_code': 'ë‰´ìŠ¤_ëŒ€êµ¬ë¶„',
    'dorg': 'ìë£Œì›',
    'iscd1': 'ì¢…ëª©ì½”ë“œ1',
}


def get_news_by_date(token: str, stock_code: str, date: str, max_depth: int = 20, max_retries: int = 3) -> pd.DataFrame:
    """íŠ¹ì • ë‚ ì§œì˜ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    path = "/uapi/domestic-stock/v1/quotations/news-title"
    url = f"{BASE_URL}{path}"
    
    headers = {
        "Content-Type": "application/json",
        "authorization": f"Bearer {token}",
        "appKey": APP_KEY,
        "appSecret": APP_SECRET,
        "tr_id": TR_ID_NEWS_TITLE
    }
    
    all_data = []
    input_srno = ""
    
    for depth in range(max_depth):
        params = {
            "FID_NEWS_OFER_ENTP_CODE": "",
            "FID_COND_MRKT_CLS_CODE": "",
            "FID_INPUT_ISCD": stock_code,
            "FID_TITL_CNTT": "",
            "FID_INPUT_DATE_1": date,
            "FID_INPUT_HOUR_1": "",
            "FID_RANK_SORT_CLS_CODE": "",
            "FID_INPUT_SRNO": input_srno,
        }
        
        # ì¬ì‹œë„ ë¡œì§
        for retry in range(max_retries):
            try:
                res = requests.get(url, headers=headers, params=params, timeout=30)
                if res.status_code == 200:
                    data = res.json()
                    if data.get('rt_cd') == '0':
                        output = data.get('output', [])
                        if not output:
                            return pd.DataFrame(all_data) if all_data else pd.DataFrame()
                        all_data.extend(output)
                        
                        # ì—°ì† ì¡°íšŒ í™•ì¸
                        if data.get('tr_cd') == 'M':
                            input_srno = output[-1].get('cntt_usiq_srno', '')
                            time.sleep(1.0)  # í˜ì´ì§• ê°„ê²©
                        else:
                            return pd.DataFrame(all_data) if all_data else pd.DataFrame()
                        break  # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
                    else:
                        return pd.DataFrame(all_data) if all_data else pd.DataFrame()
                else:
                    if retry < max_retries - 1:
                        print(f"âš ï¸ HTTP {res.status_code}, {retry+1}ë²ˆì§¸ ì¬ì‹œë„...")
                        time.sleep(5)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                    continue
            except Exception as e:
                if retry < max_retries - 1:
                    print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ, {retry+1}ë²ˆì§¸ ì¬ì‹œë„... ({str(e)[:50]})")
                    time.sleep(10)  # ì—°ê²° ì˜¤ë¥˜ ì‹œ ë” ì˜¤ë˜ ëŒ€ê¸°
                else:
                    print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: {date}")
                    return pd.DataFrame(all_data) if all_data else pd.DataFrame()
    
    return pd.DataFrame(all_data) if all_data else pd.DataFrame()


def collect_stock_news(stock_code: str, stock_name: str, start_date: str, end_date: str, 
                       output_dir: str, token: str = None) -> pd.DataFrame:
    """ë‹¨ì¼ ì¢…ëª©ì˜ ê¸°ê°„ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    
    if token is None:
        token = get_access_token()
    
    start_dt = datetime.strptime(start_date, "%Y%m%d")
    end_dt = datetime.strptime(end_date, "%Y%m%d")
    total_days = (end_dt - start_dt).days + 1
    
    print(f"\nğŸ“° {stock_name}({stock_code}) ë‰´ìŠ¤ ìˆ˜ì§‘")
    print(f"   ê¸°ê°„: {start_date} ~ {end_date} ({total_days}ì¼)")
    
    all_news = []
    current_dt = end_dt  # ìµœì‹  ë‚ ì§œë¶€í„° ì—­ìˆœìœ¼ë¡œ
    
    while current_dt >= start_dt:
        date_str = current_dt.strftime("%Y%m%d")
        
        df_day = get_news_by_date(token, stock_code, date_str)
        
        if not df_day.empty:
            df_day['stock_code'] = stock_code
            df_day['stock_name'] = stock_name
            all_news.append(df_day)
        
        current_dt -= timedelta(days=1)
        time.sleep(1.0)  # API ì†ë„ ì œí•œ
    
    if all_news:
        df_news = pd.concat(all_news, ignore_index=True)
        df_news = df_news.rename(columns=COLUMN_MAPPING)
        
        # ì¤‘ë³µ ì œê±°
        if 'ë‚´ìš©_ì¡°íšŒìš©_ì¼ë ¨ë²ˆí˜¸' in df_news.columns:
            df_news = df_news.drop_duplicates(subset=['ë‚´ìš©_ì¡°íšŒìš©_ì¼ë ¨ë²ˆí˜¸'])
        
        # ì €ì¥
        output_path = f"{output_dir}/news_{stock_code}_{start_date}_{end_date}.csv"
        df_news.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"   âœ… {len(df_news)}ê±´ ì €ì¥: {output_path}")
        
        return df_news
    else:
        print(f"   âš ï¸ ë‰´ìŠ¤ ì—†ìŒ")
        return pd.DataFrame()


def collect_all_stocks_news(start_date: str, end_date: str, output_dir: str = "_data/news"):
    """30ê°œ ì¢…ëª© ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
    stocks_df = pd.read_csv("D:/stock/target_stocks.csv")
    
    print("=" * 60)
    print("ğŸš€ 30ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 60)
    print(f"ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"ì¢…ëª© ìˆ˜: {len(stocks_df)}ê°œ")
    print(f"ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print("=" * 60)
    
    # í† í° ë°œê¸‰
    print("\nğŸ”‘ í† í° ë°œê¸‰ ì¤‘...")
    token = get_access_token()
    if not token:
        print("âŒ í† í° ë°œê¸‰ ì‹¤íŒ¨")
        return
    print("âœ… í† í° ë°œê¸‰ ì™„ë£Œ")
    
    # ì¢…ëª©ë³„ ìˆ˜ì§‘
    all_results = []
    
    for idx, row in stocks_df.iterrows():
        code = str(row['Code']).zfill(6)
        name = row['Name']
        
        # ì´ë¯¸ ìˆ˜ì§‘ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        existing_file = f"{output_dir}/news_{code}_{start_date}_{end_date}.csv"
        if os.path.exists(existing_file):
            print(f"\n[{idx + 1}/{len(stocks_df)}] {name}({code}) - â­ï¸ ì´ë¯¸ ìˆ˜ì§‘ë¨, ê±´ë„ˆëœ€")
            try:
                df_existing = pd.read_csv(existing_file, encoding='utf-8-sig')
                if not df_existing.empty:
                    all_results.append(df_existing)
            except:
                pass
            continue
        
        print(f"\n[{idx + 1}/{len(stocks_df)}] ", end="")
        
        try:
            df_news = collect_stock_news(code, name, start_date, end_date, output_dir, token)
            if not df_news.empty:
                all_results.append(df_news)
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
        
        # ì¢…ëª© ê°„ ëŒ€ê¸°
        time.sleep(2.0)
    
    # ì „ì²´ ë³‘í•©
    if all_results:
        df_all = pd.concat(all_results, ignore_index=True)
        merged_path = f"{output_dir}/news_all_{start_date}_{end_date}.csv"
        df_all.to_csv(merged_path, index=False, encoding='utf-8-sig')
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ì´ ë‰´ìŠ¤: {len(df_all):,}ê±´")
        print(f"ì¢…ëª© ìˆ˜: {df_all['stock_code'].nunique()}ê°œ")
        print(f"ì €ì¥: {merged_path}")
        
        return df_all
    
    return pd.DataFrame()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="30ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘")
    parser.add_argument("--start", type=str, default=None, help="ì‹œì‘ì¼ (YYYYMMDD)")
    parser.add_argument("--end", type=str, default=None, help="ì¢…ë£Œì¼ (YYYYMMDD)")
    parser.add_argument("--days", type=int, default=365, help="ìµœê·¼ Nì¼ (ê¸°ë³¸: 365)")
    parser.add_argument("--output", type=str, default="_data/news", help="ì €ì¥ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    # ë‚ ì§œ ì„¤ì •
    if args.end:
        end_date = args.end
    else:
        end_date = datetime.now().strftime("%Y%m%d")
    
    if args.start:
        start_date = args.start
    else:
        start_date = (datetime.now() - timedelta(days=args.days)).strftime("%Y%m%d")
    
    # ìˆ˜ì§‘ ì‹¤í–‰
    collect_all_stocks_news(start_date, end_date, args.output)

