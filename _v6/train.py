import pandas as pd
import numpy as np
import argparse
import os
import joblib
import json
from pathlib import Path
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error
import lightgbm as lgb
import optuna
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'  # ì˜ì–´ í°íŠ¸ ì„¤ì •

class StockEnsembleTrainer:
    def __init__(self, data_path, model_dir="D:/stock/_v6/models", scaler_dir="D:/stock/_v6/scalers", n_splits=5, stock_code=None, use_optuna=True, n_trials=50):
        self.data_path = data_path
        self.base_model_dir = Path(model_dir)
        self.base_model_dir.mkdir(parents=True, exist_ok=True)
        self.scaler_dir = Path(scaler_dir)
        self.n_splits = n_splits
        self.kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)
        self.stock_code = stock_code
        self.use_optuna = use_optuna
        self.n_trials = n_trials
        
        # ì¢…ëª©ì½”ë“œë³„ ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        if stock_code:
            self.model_dir = self.base_model_dir / stock_code
            self.model_dir.mkdir(parents=True, exist_ok=True)
        else:
            self.model_dir = self.base_model_dir
        
        # Target scalerëŠ” ë‚˜ì¤‘ì— ë¡œë“œ (ì¢…ëª©ì½”ë“œê°€ í™•ì •ëœ í›„)
        self.target_scaler = None
        
        # ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥ ê²½ë¡œ (ì¢…ëª©ì½”ë“œë³„ í´ë” ë‚´ì— ì €ì¥)
        # ì¢…ëª©ì½”ë“œê°€ ìˆìœ¼ë©´ ì¢…ëª©ì½”ë“œ í´ë”ì—, ì—†ìœ¼ë©´ ê¸°ë³¸ í´ë”ì— ì €ì¥
        if stock_code and stock_code != "UNKNOWN":
            self.params_dir = self.model_dir  # ì¢…ëª©ì½”ë“œ í´ë”ì— ì§ì ‘ ì €ì¥
        else:
            self.params_dir = self.base_model_dir / "params"
            self.params_dir.mkdir(parents=True, exist_ok=True)
        
        # ìµœì  íŒŒë¼ë¯¸í„° (ë¡œë“œë˜ê±°ë‚˜ ìµœì í™” í›„ ì„¤ì •ë¨)
        self.best_lgbm_params = None
    
    def _load_target_scaler(self):
        """Target scaler ë¡œë“œ (ì¢…ëª©ë³„)"""
        if self.stock_code:
            target_scaler_path = self.scaler_dir / f"{self.stock_code}_target_scaler.bin"
            if target_scaler_path.exists():
                self.target_scaler = joblib.load(target_scaler_path)
                print(f"âœ… Target scaler loaded: {target_scaler_path}")
            else:
                # ì¢…ëª©ë³„ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìœ¼ë©´ DEFAULT ìŠ¤ì¼€ì¼ëŸ¬ ì‹œë„
                default_scaler_path = self.scaler_dir / "DEFAULT_target_scaler.bin"
                if default_scaler_path.exists():
                    self.target_scaler = joblib.load(default_scaler_path)
                    print(f"âš ï¸ Using DEFAULT scaler: {default_scaler_path}")
                else:
                    print(f"âš ï¸ Target scaler not found: {target_scaler_path}")
                    print(f"   ì¢…ëª©ë³„ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ì‹œ ìŠ¤ì¼€ì¼ë§ëœ ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    self.target_scaler = None
        else:
            # ì¢…ëª©ì½”ë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ìŠ¤ì¼€ì¼ëŸ¬ ì‹œë„
            target_scaler_path = self.scaler_dir / "target_scaler.bin"
            if target_scaler_path.exists():
                self.target_scaler = joblib.load(target_scaler_path)
                print(f"âœ… Target scaler loaded: {target_scaler_path}")
            else:
                print(f"âš ï¸ Target scaler not found: {target_scaler_path}")
                self.target_scaler = None
        
    def load_data(self, test_size=50):
        """ë°ì´í„° ë¡œë“œ ë° ë¶„ë¦¬ (ë§ˆì§€ë§‰ test_sizeí–‰ì„ test setìœ¼ë¡œ)"""
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ: {self.data_path}")
        df = pd.read_csv(self.data_path)
        
        # Targetê³¼ Feature ë¶„ë¦¬
        if 'target' not in df.columns:
            raise ValueError("'target' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë§ˆì§€ë§‰ test_sizeí–‰ì„ test setìœ¼ë¡œ ë¶„ë¦¬
        if len(df) <= test_size:
            raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ {test_size + 1}í–‰ í•„ìš”í•©ë‹ˆë‹¤.")
        
        df_train_val = df.iloc[:-test_size].copy()
        df_test = df.iloc[-test_size:].copy()
        
        X_train_val = df_train_val.drop(columns=['target']).values
        y_train_val = df_train_val['target'].values
        
        X_test = df_test.drop(columns=['target']).values
        y_test = df_test['target'].values
        
        print(f"   ì „ì²´ ë°ì´í„°: {len(df)}í–‰ Ã— {X_train_val.shape[1]}í”¼ì²˜")
        print(f"   Train+Val: {len(df_train_val)}í–‰")
        print(f"   Test: {len(df_test)}í–‰")
        print(f"   Target ë²”ìœ„: [{y_train_val.min():.4f}, {y_train_val.max():.4f}]")
        
        return X_train_val, y_train_val, X_test, y_test
    
    def _cleanup_old_models(self, stock_code, current_model_name):
        """í•´ë‹¹ ì¢…ëª©ì˜ ì´ì „ ëª¨ë¸ íŒŒì¼ë“¤ ì‚­ì œ (í˜„ì¬ ëª¨ë¸ ì œì™¸)"""
        try:
            # ì¢…ëª©ì½”ë“œ í´ë” ë‚´ì˜ ëª¨ë“  ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
            lgbm_files = list(self.model_dir.glob("*_lgbm.txt"))
            weights_files = list(self.model_dir.glob("*_weights.json"))
            graph_files = list(self.model_dir.glob("*_test_prediction*.png"))
            
            deleted_count = 0
            for file_path in lgbm_files + weights_files + graph_files:
                # í˜„ì¬ ëª¨ë¸ íŒŒì¼ëª…ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì‚­ì œ
                if current_model_name not in file_path.stem:
                    try:
                        file_path.unlink()
                        deleted_count += 1
                    except Exception as e:
                        print(f"   âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path.name} - {e}")
            
            if deleted_count > 0:
                print(f"   ğŸ—‘ï¸ ì´ì „ ëª¨ë¸ {deleted_count}ê°œ ì‚­ì œë¨")
        except Exception as e:
            print(f"   âš ï¸ ëª¨ë¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _load_best_params(self):
        """ì €ì¥ëœ ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ"""
        if not self.stock_code:
            return None
        
        # ì¢…ëª©ì½”ë“œ í´ë”ì— ìˆìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì½”ë“œ ì œê±°, ì•„ë‹ˆë©´ ì¢…ëª©ì½”ë“œ í¬í•¨
        if self.params_dir == self.model_dir and self.stock_code != "UNKNOWN":
            # ì¢…ëª©ì½”ë“œ í´ë”ì— ì§ì ‘ ì €ì¥ëœ ê²½ìš°
            lgbm_params_path = self.params_dir / "lgbm_params.json"
        else:
            # ê¸°ë³¸ params í´ë”ì— ì €ì¥ëœ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
            lgbm_params_path = self.params_dir / f"{self.stock_code}_lgbm_params.json"
        
        lgbm_params = None
        
        if lgbm_params_path.exists():
            try:
                with open(lgbm_params_path, 'r') as f:
                    lgbm_params = json.load(f)
                print(f"âœ… LGBM ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ: {lgbm_params_path}")
            except Exception as e:
                print(f"âš ï¸ LGBM íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return lgbm_params
    
    def _save_best_params(self, lgbm_params):
        """ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥"""
        if not self.stock_code:
            return
        
        # ì¢…ëª©ì½”ë“œ í´ë”ì— ìˆìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì½”ë“œ ì œê±°, ì•„ë‹ˆë©´ ì¢…ëª©ì½”ë“œ í¬í•¨
        if self.params_dir == self.model_dir and self.stock_code != "UNKNOWN":
            # ì¢…ëª©ì½”ë“œ í´ë”ì— ì§ì ‘ ì €ì¥
            lgbm_params_path = self.params_dir / "lgbm_params.json"
        else:
            # ê¸°ë³¸ params í´ë”ì— ì €ì¥ (í•˜ìœ„ í˜¸í™˜ì„±)
            lgbm_params_path = self.params_dir / f"{self.stock_code}_lgbm_params.json"
        
        try:
            with open(lgbm_params_path, 'w') as f:
                json.dump(lgbm_params, f, indent=2)
            print(f"ğŸ’¾ LGBM ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥: {lgbm_params_path}")
        except Exception as e:
            print(f"âš ï¸ LGBM íŒŒë¼ë¯¸í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _optimize_lgbm(self, X_train_val, y_train_val):
        """Optunaë¡œ LightGBM í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""
        print(f"\nğŸ” Optunaë¡œ LightGBM í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘ (n_trials={self.n_trials})...")
        
        def objective(trial):
            params = {
                'objective': 'regression',
                'metric': 'rmse',
                'boosting_type': 'gbdt',
                'num_leaves': trial.suggest_int('num_leaves', 20, 100),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),
                'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),
                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),
                'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),
                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
                'verbose': -1,
                'seed': 42
            }
            
            # KFoldë¡œ ê²€ì¦
            kf = KFold(n_splits=3, shuffle=True, random_state=42)
            scores = []
            
            for train_idx, val_idx in kf.split(X_train_val):
                X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]
                y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]
                
                train_data = lgb.Dataset(X_train, label=y_train)
                val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
                
                model = lgb.train(
                    params,
                    train_data,
                    num_boost_round=500,
                    valid_sets=[val_data],
                    callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)]
                )
                
                pred = model.predict(X_val, num_iteration=model.best_iteration)
                rmse = np.sqrt(mean_squared_error(y_val, pred))
                scores.append(rmse)
            
            return np.mean(scores)
        
        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=self.n_trials, show_progress_bar=True)
        
        best_params = study.best_params.copy()
        best_params['objective'] = 'regression'
        best_params['metric'] = 'rmse'
        best_params['boosting_type'] = 'gbdt'
        best_params['verbose'] = -1
        best_params['seed'] = 42
        
        print(f"âœ… LGBM ìµœì  íŒŒë¼ë¯¸í„° ì°¾ìŒ (RMSE: {study.best_value:.6f})")
        return best_params
    
    def train_lgbm(self, X_train, y_train, X_val, y_val, fold_idx):
        """LightGBM ëª¨ë¸ í•™ìŠµ"""
        print(f"\nğŸŒ² LightGBM í•™ìŠµ ì¤‘...")
        
        # íšŒê·€ ë¬¸ì œì´ë¯€ë¡œ objective='regression' ì‚¬ìš©
        train_data = lgb.Dataset(X_train, label=y_train)
        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
        
        # ìµœì  íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        if self.best_lgbm_params:
            params = self.best_lgbm_params.copy()
            print(f"   âœ… ìµœì  íŒŒë¼ë¯¸í„° ì‚¬ìš©")
        else:
            params = {
                'objective': 'regression',
                'metric': 'rmse',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'seed': 42
            }
            print(f"   âš ï¸ ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©")
        
        # ì–¼ë¦¬ìŠ¤íƒ€í•‘ ì½œë°±
        callbacks = [
            lgb.early_stopping(stopping_rounds=50, verbose=True),
            lgb.log_evaluation(period=100)
        ]
        
        model = lgb.train(
            params,
            train_data,
            num_boost_round=1000,
            valid_sets=[train_data, val_data],
            valid_names=['train', 'eval'],
            callbacks=callbacks
        )
        
        return model
    
    def evaluate_regression(self, y_true, y_pred):
        """íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ"""
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        
        # F1 ìŠ¤ì½”ì–´ë¥¼ ìœ„í•´ ì´ì§„ ë¶„ë¥˜ë¡œ ë³€í™˜ (ì–‘ìˆ˜=1, ìŒìˆ˜=0)
        y_true_binary = (y_true > 0).astype(int)
        y_pred_binary = (y_pred > 0).astype(int)
        f1 = f1_score(y_true_binary, y_pred_binary, average='binary')
        acc = accuracy_score(y_true_binary, y_pred_binary)
        
        return {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'f1': f1,
            'acc': acc
        }
    
    def plot_test_results(self, y_true, y_pred, metrics, save_path):
        """Test ì˜ˆì¸¡ ê²°ê³¼ ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        n = len(y_true)
        x = np.arange(n)
        
        # 1. Actual vs Predicted (Line plot)
        axes[0, 0].plot(x, y_true, 'o-', label='Actual', linewidth=2, markersize=6, color='blue')
        axes[0, 0].plot(x, y_pred, 's-', label='Predicted', linewidth=2, markersize=6, color='red', alpha=0.7)
        axes[0, 0].set_xlabel('Sample Index', fontsize=12)
        axes[0, 0].set_ylabel('Return Rate', fontsize=12)
        axes[0, 0].set_title('Actual vs Predicted Returns', fontsize=14, fontweight='bold')
        axes[0, 0].legend(fontsize=11)
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. Scatter plot
        axes[0, 1].scatter(y_true, y_pred, alpha=0.6, s=50)
        min_val = min(y_true.min(), y_pred.min())
        max_val = max(y_true.max(), y_pred.max())
        axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')
        axes[0, 1].set_xlabel('Actual Return Rate', fontsize=12)
        axes[0, 1].set_ylabel('Predicted Return Rate', fontsize=12)
        axes[0, 1].set_title('Prediction Scatter Plot', fontsize=14, fontweight='bold')
        axes[0, 1].legend(fontsize=11)
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. Residuals (Error)
        residuals = y_true - y_pred
        axes[1, 0].plot(x, residuals, 'o-', linewidth=2, markersize=6, color='green', alpha=0.7)
        axes[1, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)
        axes[1, 0].set_xlabel('Sample Index', fontsize=12)
        axes[1, 0].set_ylabel('Residual (Actual - Predicted)', fontsize=12)
        axes[1, 0].set_title('Prediction Residuals', fontsize=14, fontweight='bold')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. Metrics summary
        axes[1, 1].axis('off')
        metrics_text = f"""
Test Set Performance Metrics:

Regression Metrics:
  RMSE: {metrics['rmse']:.6f}
  MAE:  {metrics['mae']:.6f}
  MSE:  {metrics['mse']:.6f}

Classification Metrics (Binary):
  Accuracy: {metrics['acc']:.4f}
  F1 Score: {metrics['f1']:.4f}

Sample Size: {n}
        """
        axes[1, 1].text(0.1, 0.5, metrics_text, fontsize=12, verticalalignment='center',
                        family='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"\nğŸ“Š Test prediction graph saved: {save_path}")
        plt.close()
    
    def train_ensemble(self):
        """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ (KFold) ë° Test ì˜ˆì¸¡"""
        X_train_val, y_train_val, X_test, y_test = self.load_data()
        
        # ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ ë˜ëŠ” ìµœì í™”
        if self.use_optuna:
            # ì €ì¥ëœ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            lgbm_params = self._load_best_params()
            
            if lgbm_params is None:
                print(f"\n{'='*60}")
                print(f"ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
                print(f"{'='*60}")
                
                # Optunaë¡œ ìµœì í™”
                lgbm_params = self._optimize_lgbm(X_train_val, y_train_val)
                
                # ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥
                self._save_best_params(lgbm_params)
            else:
                print(f"\n{'='*60}")
                print(f"ğŸ“‚ ì €ì¥ëœ ìµœì  íŒŒë¼ë¯¸í„° ì‚¬ìš©")
                print(f"{'='*60}")
            
            self.best_lgbm_params = lgbm_params
        else:
            # Optuna ì‚¬ìš© ì•ˆ í•¨ - ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©
            print(f"\n{'='*60}")
            print(f"âš ï¸ Optuna ìµœì í™” ë¹„í™œì„±í™” - ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©")
            print(f"{'='*60}")
            self.best_lgbm_params = None
        
        fold_results = []
        best_f1 = -1
        best_fold = -1
        best_lgbm_model = None
        best_ensemble_weights = None  # ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì €ì¥
        
        print(f"\n{'='*60}")
        print(f"ğŸ¯ KFold êµì°¨ ê²€ì¦ ì‹œì‘ (n_splits={self.n_splits})")
        print(f"{'='*60}")
        
        # ì „ì²´ foldì—ì„œ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”ë¥¼ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
        all_lgbm_preds = []
        all_y_true = []
        
        for fold_idx, (train_idx, val_idx) in enumerate(self.kfold.split(X_train_val)):
            print(f"\nğŸ“Š Fold {fold_idx + 1}/{self.n_splits}")
            print(f"   Train: {len(train_idx)}ê°œ, Val: {len(val_idx)}ê°œ")
            
            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]
            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]
            
            # ëª¨ë¸ í•™ìŠµ
            lgbm_model = self.train_lgbm(X_train, y_train, X_val, y_val, fold_idx)
            
            # ì˜ˆì¸¡
            lgbm_pred = lgbm_model.predict(X_val, num_iteration=lgbm_model.best_iteration)
            
            # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
            lgbm_metrics = self.evaluate_regression(y_val, lgbm_pred)
            
            # LGBMë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ê°€ì¤‘ì¹˜ëŠ” 1.0
            lgbm_weight = 1.0
            
            print(f"\n   ëª¨ë¸ë³„ ì„±ëŠ¥:")
            print(f"   LGBM: F1={lgbm_metrics['f1']:.4f}, RMSE={lgbm_metrics['rmse']:.6f} â†’ ê°€ì¤‘ì¹˜: {lgbm_weight:.3f}")
            
            # ì•™ìƒë¸” ì˜ˆì¸¡ (LGBMë§Œ ì‚¬ìš©)
            ensemble_pred = lgbm_pred
            
            # ì „ì²´ fold ë°ì´í„° ìˆ˜ì§‘
            all_lgbm_preds.append(lgbm_pred)
            all_y_true.append(y_val)
            
            # í‰ê°€
            metrics = self.evaluate_regression(y_val, ensemble_pred)
            
            print(f"\nâœ… Fold {fold_idx + 1} ê²°ê³¼:")
            print(f"   RMSE: {metrics['rmse']:.6f}")
            print(f"   MAE:  {metrics['mae']:.6f}")
            print(f"   F1:   {metrics['f1']:.4f}")
            print(f"   Acc:  {metrics['acc']:.4f}")
            
            fold_results.append({
                'fold': fold_idx + 1,
                'metrics': metrics,
                'lgbm_model': lgbm_model,
                'lgbm_weight': lgbm_weight
            })
            
            # F1 ìŠ¤ì½”ì–´ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì €ì¥
            if metrics['f1'] > best_f1:
                best_f1 = metrics['f1']
                best_fold = fold_idx + 1
                best_lgbm_model = lgbm_model
                best_ensemble_weights = {
                    'lgbm': lgbm_weight
                }
                
                # ëª¨ë¸ ì €ì¥ (ì¢…ëª©ì½”ë“œ í¬í•¨)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                stock_code = getattr(self, 'stock_code', 'UNKNOWN')
                model_name = f"{stock_code}_fold{best_fold}_acc{metrics['acc']:.4f}_f1{metrics['f1']:.4f}_{timestamp}"
                
                lgbm_path = self.model_dir / f"{model_name}_lgbm.txt"
                
                # ì´ì „ ëª¨ë¸ ì‚­ì œ (í•´ë‹¹ ì¢…ëª©ì˜ ì´ì „ ëª¨ë¸ë“¤ë§Œ)
                if stock_code != 'UNKNOWN':
                    self._cleanup_old_models(stock_code, model_name)
                
                lgbm_model.save_model(str(lgbm_path))
                
                # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì €ì¥
                weights_path = self.model_dir / f"{model_name}_weights.json"
                with open(weights_path, 'w') as f:
                    json.dump(best_ensemble_weights, f, indent=2)
                
                print(f"\nğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥: {model_name}")
                print(f"   LGBM: {lgbm_path}")
                weight_str = f"LGBM={best_ensemble_weights['lgbm']:.3f}"
                print(f"   ê°€ì¤‘ì¹˜: {weight_str}")
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        print(f"\n{'='*60}")
        print(f"ğŸ“ˆ ì „ì²´ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*60}")
        
        avg_metrics = {
            'rmse': np.mean([r['metrics']['rmse'] for r in fold_results]),
            'mae': np.mean([r['metrics']['mae'] for r in fold_results]),
            'f1': np.mean([r['metrics']['f1'] for r in fold_results]),
            'acc': np.mean([r['metrics']['acc'] for r in fold_results])
        }
        
        std_metrics = {
            'rmse': np.std([r['metrics']['rmse'] for r in fold_results]),
            'mae': np.std([r['metrics']['mae'] for r in fold_results]),
            'f1': np.std([r['metrics']['f1'] for r in fold_results]),
            'acc': np.std([r['metrics']['acc'] for r in fold_results])
        }
        
        print(f"í‰ê·  Â± í‘œì¤€í¸ì°¨:")
        print(f"  RMSE: {avg_metrics['rmse']:.6f} Â± {std_metrics['rmse']:.6f}")
        print(f"  MAE:  {avg_metrics['mae']:.6f} Â± {std_metrics['mae']:.6f}")
        print(f"  F1:   {avg_metrics['f1']:.4f} Â± {std_metrics['f1']:.4f}")
        print(f"  Acc:  {avg_metrics['acc']:.4f} Â± {std_metrics['acc']:.4f}")
        print(f"\nìµœê³  F1 ìŠ¤ì½”ì–´: {best_f1:.4f} (Fold {best_fold})")
        
        # ì „ì²´ fold ë°ì´í„°ë¡œ ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì°¾ê¸° (LGBMë§Œ ì‚¬ìš©)
        if len(all_lgbm_preds) > 0:
            all_lgbm_pred = np.concatenate(all_lgbm_preds)
            all_y = np.concatenate(all_y_true)
            
            # LGBMë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ê°€ì¤‘ì¹˜ëŠ” 1.0
            optimal_lgbm_weight = 1.0
            
            ensemble_pred = optimal_lgbm_weight * all_lgbm_pred
            metrics = self.evaluate_regression(all_y, ensemble_pred)
            best_weight_f1 = metrics['f1']
            
            print(f"\nâœ… ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜:")
            print(f"   LGBM: {optimal_lgbm_weight:.3f} (F1={best_weight_f1:.4f})")
            
            # ìµœì  ê°€ì¤‘ì¹˜ë¥¼ best_ensemble_weightsë¡œ ì—…ë°ì´íŠ¸
            if best_ensemble_weights is None:
                best_ensemble_weights = {
                    'lgbm': optimal_lgbm_weight
                }
            else:
                current_ensemble = best_ensemble_weights['lgbm'] * all_lgbm_pred
                current_metrics = self.evaluate_regression(all_y, current_ensemble)
                if best_weight_f1 > current_metrics['f1']:
                    best_ensemble_weights = {
                        'lgbm': optimal_lgbm_weight
                    }
                    print(f"   âš¡ ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì—…ë°ì´íŠ¸ë¨ (F1: {current_metrics['f1']:.4f} â†’ {best_weight_f1:.4f})")
        
        # Test set ì˜ˆì¸¡
        if best_lgbm_model is not None:
            print(f"\n{'='*60}")
            print(f"ğŸ§ª Test Set Prediction (Last 50 samples)")
            print(f"{'='*60}")
            
            # ì „ì²´ train_val ë°ì´í„°ë¡œ ì¬í•™ìŠµ (ìµœê³  ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©)
            print("\nğŸ”„ Retraining on full train+val data for test prediction...")
            final_lgbm = self.train_lgbm(X_train_val, y_train_val, X_test, y_test, -1)
            
            # Test ì˜ˆì¸¡
            lgbm_test_pred = final_lgbm.predict(X_test, num_iteration=final_lgbm.best_iteration)
            
            # ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸” ì˜ˆì¸¡ (LGBMë§Œ ì‚¬ìš©)
            if best_ensemble_weights:
                ensemble_test_pred = best_ensemble_weights['lgbm'] * lgbm_test_pred
                weight_str = f"LGBM={best_ensemble_weights['lgbm']:.3f}"
                print(f"\n   ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì ìš©: {weight_str}")
            else:
                ensemble_test_pred = lgbm_test_pred
                print(f"\n   ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì‚¬ìš© (LGBMë§Œ)")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ì—­ë³€í™˜ (ì›ë³¸ ìˆ˜ìµë¥ ë¡œ ë³µì›)
            if self.target_scaler is not None:
                y_test_original = self.target_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
                ensemble_test_pred_original = self.target_scaler.inverse_transform(ensemble_test_pred.reshape(-1, 1)).flatten()
                print(f"\nğŸ”„ Scaler inverse transform applied")
                print(f"   Scaled range: [{y_test.min():.4f}, {y_test.max():.4f}]")
                print(f"   Original range: [{y_test_original.min():.4f}, {y_test_original.max():.4f}]")
            else:
                y_test_original = y_test
                ensemble_test_pred_original = ensemble_test_pred
                print(f"\nâš ï¸ Scaler not found, using scaled values")
            
            # Test í‰ê°€ (ì›ë³¸ ê°’ìœ¼ë¡œ)
            test_metrics = self.evaluate_regression(y_test_original, ensemble_test_pred_original)
            
            print(f"\nâœ… Test Set Results (Original Scale):")
            print(f"   RMSE: {test_metrics['rmse']:.6f}")
            print(f"   MAE:  {test_metrics['mae']:.6f}")
            print(f"   F1:   {test_metrics['f1']:.4f}")
            print(f"   Acc:  {test_metrics['acc']:.4f}")
            
            # ê·¸ë˜í”„ ì €ì¥ (ì›ë³¸ ê°’ìœ¼ë¡œ)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            stock_code = getattr(self, 'stock_code', 'UNKNOWN')
            graph_path = self.model_dir / f"{stock_code}_test_prediction_acc{test_metrics['acc']:.4f}_f1{test_metrics['f1']:.4f}_{timestamp}.png"
            self.plot_test_results(y_test_original, ensemble_test_pred_original, test_metrics, graph_path)
        
        return fold_results

def main():
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„° ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ")
    parser.add_argument("--data", type=str, required=True, help="ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²½ë¡œ")
    parser.add_argument("--code", type=str, default=None, help="ì¢…ëª©ì½”ë“œ (ì˜ˆ: 005930, íŒŒì¼ëª…ì—ì„œ ìë™ ì¶”ì¶œ ì‹œë„)")
    parser.add_argument("--model_dir", type=str, default="D:/stock/_v6/models", help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--scaler_dir", type=str, default="D:/stock/_v6/scalers", help="ìŠ¤ì¼€ì¼ëŸ¬ ë””ë ‰í† ë¦¬")
    parser.add_argument("--n_splits", type=int, default=5, help="KFold ë¶„í•  ìˆ˜")
    parser.add_argument("--use_optuna", action="store_true", default=True, help="Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‚¬ìš© (ê¸°ë³¸ê°’: True)")
    parser.add_argument("--no_optuna", dest="use_optuna", action="store_false", help="Optuna ìµœì í™” ë¹„í™œì„±í™”")
    parser.add_argument("--n_trials", type=int, default=50, help="Optuna ìµœì í™” ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 50)")
    
    args = parser.parse_args()
    
    # ì¢…ëª©ì½”ë“œ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ ë˜ëŠ” ì§ì ‘ ì…ë ¥)
    stock_code = args.code
    if stock_code is None:
        # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ ì‹œë„ (ì˜ˆ: preprocessed_005930_20260101_20260127.csv)
        import re
        filename = Path(args.data).stem
        match = re.search(r'(\d{6})', filename)
        if match:
            stock_code = match.group(1)
            print(f"ğŸ“Œ ì¢…ëª©ì½”ë“œ ìë™ ì¶”ì¶œ: {stock_code}")
        else:
            stock_code = "UNKNOWN"
            print(f"âš ï¸ ì¢…ëª©ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'UNKNOWN'ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.")
            print(f"   --code ì˜µì…˜ìœ¼ë¡œ ì§ì ‘ ì§€ì •í•˜ì„¸ìš”.")
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ Training Started")
    print(f"{'='*60}")
    print(f"Stock Code: {stock_code}")
    print(f"Data: {args.data}")
    print(f"Optuna: {args.use_optuna} (n_trials={args.n_trials})")
    print(f"{'='*60}\n")
    
    trainer = StockEnsembleTrainer(
        data_path=args.data,
        model_dir=args.model_dir,
        scaler_dir=args.scaler_dir,
        n_splits=args.n_splits,
        stock_code=stock_code,
        use_optuna=args.use_optuna,
        n_trials=args.n_trials
    )
    
    # ì¢…ëª©ì½”ë“œê°€ ì„¤ì •ëœ í›„ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì¬ì„¤ì •
    if stock_code and stock_code != "UNKNOWN":
        trainer.model_dir = trainer.base_model_dir / stock_code
        trainer.model_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {trainer.model_dir}")
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ë‹¤ì‹œ ë¡œë“œ (ì¢…ëª©ì½”ë“œê°€ ì„¤ì •ëœ í›„)
    trainer._load_target_scaler()
    
    trainer.train_ensemble()

if __name__ == "__main__":
    main()

