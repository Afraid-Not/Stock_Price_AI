"""
ëª¨ë¸ ë¶„ì„ ë° ìµœì í™”
- í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
- ìµœì  ì„ê³„ê°’ íƒìƒ‰
"""
import pandas as pd
import numpy as np
import joblib
import glob
import os

def load_latest_models(model_dir='models_9stocks'):
    """ìµœì‹  ëª¨ë¸ ë¡œë“œ"""
    models = {}
    
    # XGBoost
    xgb_files = sorted(glob.glob(f"{model_dir}/xgboost_*.pkl"))
    if xgb_files:
        models['xgboost'] = joblib.load(xgb_files[-1])
        print(f"âœ… XGBoost: {os.path.basename(xgb_files[-1])}")
    
    # CatBoost
    cat_files = sorted(glob.glob(f"{model_dir}/catboost_*.pkl"))
    if cat_files:
        models['catboost'] = joblib.load(cat_files[-1])
        print(f"âœ… CatBoost: {os.path.basename(cat_files[-1])}")
    
    # LabelEncoder
    le_files = sorted(glob.glob(f"{model_dir}/label_encoder_*.pkl"))
    if le_files:
        models['label_encoder'] = joblib.load(le_files[-1])
        print(f"âœ… LabelEncoder: {os.path.basename(le_files[-1])}")
    
    return models


def analyze_feature_importance(models, top_n=20):
    """í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("ğŸ“Š í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
    print("=" * 60)
    
    importance_df = pd.DataFrame()
    
    # XGBoost
    if 'xgboost' in models:
        xgb_model = models['xgboost']
        xgb_imp = pd.DataFrame({
            'feature': xgb_model.feature_names_in_ if hasattr(xgb_model, 'feature_names_in_') else [f'f{i}' for i in range(len(xgb_model.feature_importances_))],
            'xgb_importance': xgb_model.feature_importances_
        })
        importance_df = xgb_imp
    
    # CatBoost
    if 'catboost' in models:
        cat_model = models['catboost']
        cat_imp = cat_model.feature_importances_
        if importance_df.empty:
            importance_df = pd.DataFrame({
                'feature': [f'f{i}' for i in range(len(cat_imp))],
                'cat_importance': cat_imp
            })
        else:
            importance_df['cat_importance'] = cat_imp
    
    # í‰ê·  ì¤‘ìš”ë„
    if 'xgb_importance' in importance_df.columns and 'cat_importance' in importance_df.columns:
        importance_df['avg_importance'] = (importance_df['xgb_importance'] + importance_df['cat_importance']) / 2
    elif 'xgb_importance' in importance_df.columns:
        importance_df['avg_importance'] = importance_df['xgb_importance']
    else:
        importance_df['avg_importance'] = importance_df['cat_importance']
    
    # ì •ë ¬
    importance_df = importance_df.sort_values('avg_importance', ascending=False).reset_index(drop=True)
    
    # ìƒìœ„ í”¼ì²˜
    print(f"\nğŸ” ìƒìœ„ {top_n}ê°œ í”¼ì²˜:")
    print("-" * 50)
    for i, row in importance_df.head(top_n).iterrows():
        bar = "â–ˆ" * int(row['avg_importance'] / importance_df['avg_importance'].max() * 20)
        print(f"{i+1:2d}. {row['feature']:30s} {row['avg_importance']:.4f} {bar}")
    
    # í•˜ìœ„ í”¼ì²˜ (ì œê±° í›„ë³´)
    print(f"\nğŸ”» í•˜ìœ„ 10ê°œ í”¼ì²˜ (ì œê±° í›„ë³´):")
    print("-" * 50)
    for i, row in importance_df.tail(10).iterrows():
        print(f"    {row['feature']:30s} {row['avg_importance']:.4f}")
    
    # ì €ì¥
    importance_df.to_csv('models_9stocks/feature_importance.csv', index=False)
    print(f"\nğŸ’¾ ì €ì¥: models_9stocks/feature_importance.csv")
    
    return importance_df


def suggest_optimizations(importance_df):
    """ìµœì í™” ì œì•ˆ"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ ìµœì í™” ì œì•ˆ")
    print("=" * 60)
    
    # 1. ì œê±° ì¶”ì²œ í”¼ì²˜ (ì¤‘ìš”ë„ í•˜ìœ„ 20%)
    threshold = importance_df['avg_importance'].quantile(0.2)
    low_importance = importance_df[importance_df['avg_importance'] < threshold]['feature'].tolist()
    
    print(f"\n1ï¸âƒ£ ì œê±° ì¶”ì²œ í”¼ì²˜ (í•˜ìœ„ 20%, {len(low_importance)}ê°œ):")
    for f in low_importance:
        print(f"   - {f}")
    
    # 2. í•µì‹¬ í”¼ì²˜ (ìƒìœ„ 10ê°œ)
    top_features = importance_df.head(10)['feature'].tolist()
    print(f"\n2ï¸âƒ£ í•µì‹¬ í”¼ì²˜ (ìƒìœ„ 10ê°œ):")
    for f in top_features:
        print(f"   âœ… {f}")
    
    # 3. Lag í”¼ì²˜ ë¶„ì„
    lag_features = [f for f in importance_df['feature'] if '_lag' in f]
    lag_importance = importance_df[importance_df['feature'].isin(lag_features)]['avg_importance'].sum()
    total_importance = importance_df['avg_importance'].sum()
    
    print(f"\n3ï¸âƒ£ Lag í”¼ì²˜ ê¸°ì—¬ë„:")
    print(f"   Lag í”¼ì²˜ ìˆ˜: {len(lag_features)}ê°œ")
    print(f"   ì¤‘ìš”ë„ ë¹„ì¤‘: {lag_importance/total_importance*100:.1f}%")
    
    # 4. ë§¤í¬ë¡œ í”¼ì²˜ ë¶„ì„
    macro_features = ['kospi_return', 'kospi_gap_ma5', 'kospi_volatility', 
                      'usdkrw_return', 'usdkrw_gap_ma5']
    macro_in_data = [f for f in macro_features if f in importance_df['feature'].values]
    
    if macro_in_data:
        print(f"\n4ï¸âƒ£ ë§¤í¬ë¡œ í”¼ì²˜ ê¸°ì—¬ë„:")
        for f in macro_in_data:
            imp = importance_df[importance_df['feature'] == f]['avg_importance'].values[0]
            rank = importance_df[importance_df['feature'] == f].index[0] + 1
            print(f"   {f}: ì¤‘ìš”ë„ {imp:.4f} (ìˆœìœ„ {rank})")


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ” ëª¨ë¸ ë¶„ì„ ë° ìµœì í™”")
    print("=" * 60)
    
    # ëª¨ë¸ ë¡œë“œ
    models = load_latest_models()
    
    if models:
        # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
        importance_df = analyze_feature_importance(models)
        
        # ìµœì í™” ì œì•ˆ
        suggest_optimizations(importance_df)
    else:
        print("âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

