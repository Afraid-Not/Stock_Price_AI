import pandas as pd
import torch
import glob
import os
import warnings
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from tqdm import tqdm

# ìŠ¤íƒ€ì¼ ê´€ë ¨ ê²½ê³  ë¬´ì‹œ (ì½˜ì†”ì„ ê¹¨ë—í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤)
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")

# 1. ëª¨ë¸ ì¤€ë¹„
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_name = "clare25/krfinbert-jongtobang"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)
model.eval()

# 2. ì •ì œëœ 2,194ê°œ í‚¤ì›Œë“œ ë¡œë“œ
with open("d:/stock/news_refiner/refined_keywords.txt", "r", encoding="utf-8") as f:
    keywords = [line.strip() for line in f.readlines()]
keyword_pattern = "|".join(keywords)

def refine_news_to_csv(input_folder, output_csv):
    # .xlsx ë° .xls íŒŒì¼ë§Œ ê²€ìƒ‰
    all_files = glob.glob(os.path.join(input_folder, "*.xlsx")) + glob.glob(os.path.join(input_folder, "*.xls"))
    daily_results = []
    
    print(f"ğŸ“‚ ì´ {len(all_files)}ê°œì˜ íŒŒì¼ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.")

    for f in all_files:
        # ì—‘ì…€ ì„ì‹œ íŒŒì¼(~$ë¡œ ì‹œì‘)ì€ ê±´ë„ˆëœë‹ˆë‹¤
        if os.path.basename(f).startswith("~$"):
            continue
            
        try:
            # engine='openpyxl'ì„ ëª…ì‹œí•˜ì—¬ ì—ëŸ¬ ë°©ì§€
            df = pd.read_excel(f, engine='openpyxl')
            
            # ì‚¼ì„± ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§
            df = df[df['ì œëª©'].str.contains(keyword_pattern, na=False)].copy()
            if df.empty:
                continue

            # ë‚ ì§œ ì²˜ë¦¬ ë° ì£¼ë§ ë³´ì •
            df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], format='%Y%m%d', errors='coerce')
            df = df.dropna(subset=['ì¼ì'])
            df.loc[df['ì¼ì'].dt.dayofweek == 5, 'ì¼ì'] += pd.Timedelta(days=2)
            df.loc[df['ì¼ì'].dt.dayofweek == 6, 'ì¼ì'] += pd.Timedelta(days=1)

            # ë°°ì¹˜ ê°ì„± ë¶„ì„
            titles = df['ì œëª©'].tolist()
            scores = []
            batch_size = 32
            
            with torch.no_grad():
                for i in range(0, len(titles), batch_size):
                    batch = titles[i : i + batch_size]
                    inputs = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors="pt").to(device)
                    outputs = model(**inputs)
                    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
                    # ì¬í˜„ë‹˜ êµì • í¬ì¸íŠ¸: 0ë²ˆ(Pos) - 1ë²ˆ(Neg)
                    batch_scores = (probs[:, 0] - probs[:, 1]).cpu().numpy()
                    scores.extend(batch_scores)

            df['sentiment_score'] = scores
            daily_avg = df.groupby('ì¼ì')['sentiment_score'].mean().reset_index()
            daily_results.append(daily_avg)
            
            print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {os.path.basename(f)}")

        except Exception as e:
            print(f"âš ï¸ ê±´ë„ˆëœ€ ({os.path.basename(f)}): {e}")

    # ìµœì¢… ë³‘í•© ë° ì €ì¥
    if daily_results:
        final_df = pd.concat(daily_results, ignore_index=True)
        final_daily = final_df.groupby('ì¼ì')['sentiment_score'].mean().reset_index()
        final_daily.columns = ['ë‚ ì§œ', 'news_sentiment']
        final_daily.to_csv(output_csv, index=False, encoding='utf-8-sig')
        print(f"\nâœ¨ ë¦¬íŒŒì´ë‹ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_csv}")
    else:
        print("âŒ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì‹¤í–‰ ê²½ë¡œ í™•ì¸í•˜ì„¸ìš”
refine_news_to_csv("D:/stock/_data/news/", "D:/stock/_data/refined_news/daily_sentiment_score.csv")