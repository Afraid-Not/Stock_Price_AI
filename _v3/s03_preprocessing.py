import pandas as pd
import numpy as np
import os
import joblib
from sklearn.preprocessing import RobustScaler, StandardScaler

class StockPreprocessor:
    def __init__(self, scaler_dir="D:/stock/_v3/scalers"):
        self.scaler_dir = scaler_dir
        os.makedirs(self.scaler_dir, exist_ok=True)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        self.flow_scaler = RobustScaler()
        self.return_scaler = StandardScaler()
        
        # ì»¬ëŸ¼ ì •ì˜
        self.selected_columns = [
            'ë‚ ì§œ', 'ì¢…ê°€', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ê±°ë˜ëŸ‰', 
            'ê±°ë˜ëŒ€ê¸ˆ', 'ë“±ë½ë¥ ', 'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°ê´€ê³„_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 
            'ê°œì¸_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸ˆìœµíˆ¬ì_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'íˆ¬ì‹ _ìˆœë§¤ìˆ˜ê¸ˆì•¡', 
            'ì‚¬ëª¨í€ë“œ_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ì€í–‰_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ë³´í—˜_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 
            'ì—°ê¸°ê¸ˆ_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°íƒ€ê¸ˆìœµ_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°íƒ€ë²•ì¸_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 
            'ì™¸êµ­ì¸_ë§¤ìˆ˜ê¸ˆì•¡', 'ì™¸êµ­ì¸_ë§¤ë„ê¸ˆì•¡', 'ê¸°ê´€ê³„_ë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°ê´€ê³„_ë§¤ë„ê¸ˆì•¡', 
            'ê°œì¸_ë§¤ìˆ˜ê¸ˆì•¡', 'ê°œì¸_ë§¤ë„ê¸ˆì•¡', 'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ìˆ˜ëŸ‰', 'ê¸°ê´€ê³„_ìˆœë§¤ìˆ˜ìˆ˜ëŸ‰', 'ê°œì¸_ìˆœë§¤ìˆ˜ìˆ˜ëŸ‰'
        ]
        
        self.flow_cols = [
            'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°ê´€ê³„_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê°œì¸_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸ˆìœµíˆ¬ì_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 
            'íˆ¬ì‹ _ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ì‚¬ëª¨í€ë“œ_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ì€í–‰_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ë³´í—˜_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 
            'ì—°ê¸°ê¸ˆ_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°íƒ€ê¸ˆìœµ_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°íƒ€ë²•ì¸_ìˆœë§¤ìˆ˜ê¸ˆì•¡', 
            'ì™¸êµ­ì¸_ë§¤ìˆ˜ê¸ˆì•¡', 'ì™¸êµ­ì¸_ë§¤ë„ê¸ˆì•¡', 'ê¸°ê´€ê³„_ë§¤ìˆ˜ê¸ˆì•¡', 'ê¸°ê´€ê³„_ë§¤ë„ê¸ˆì•¡', 
            'ê°œì¸_ë§¤ìˆ˜ê¸ˆì•¡', 'ê°œì¸_ë§¤ë„ê¸ˆì•¡', 'ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜ìˆ˜ëŸ‰', 'ê¸°ê´€ê³„_ìˆœë§¤ìˆ˜ìˆ˜ëŸ‰', 'ê°œì¸_ìˆœë§¤ìˆ˜ìˆ˜ëŸ‰'
        ]

    def run_pipeline(self, input_path, output_path, is_train=True):
        """is_train=Trueë©´ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ìƒˆë¡œ í•™ìŠµì‹œì¼œ ì €ì¥í•˜ê³ , Falseë©´ ì €ì¥ëœ ê²ƒì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
        df = pd.read_csv(input_path)
        ss_df = df[self.selected_columns].copy()

        ss_df['ê±°ë˜ëŸ‰'] = ss_df['ê±°ë˜ëŸ‰'].replace(0, np.nan)
        ss_df = ss_df.dropna(axis=0)

        # 1. ê¸°ìˆ ì  ì§€í‘œ
        ss_df = self._add_technical_indicators(ss_df)
        
        # 2. ìŠ¤ì¼€ì¼ë§ (í•™ìŠµ/ë¡œë“œ ë¶„ê¸°)
        ss_df = self._apply_scaling(ss_df, is_train)
        
        # 3. ë‚˜ë¨¸ì§€ ì²˜ë¦¬
        ss_df = self._add_date_features(ss_df)
        ss_df = self._apply_clipping(ss_df)
        ss_df = self._prepare_final_dataset(ss_df)

        ss_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        return ss_df

    def _apply_scaling(self, df, is_train):
        df['ê±°ë˜ëŸ‰'] = np.log1p(df['ê±°ë˜ëŸ‰'])
        df['ê±°ë˜ëŒ€ê¸ˆ'] = np.log1p(df['ê±°ë˜ëŒ€ê¸ˆ'])

        flow_scaler_path = os.path.join(self.scaler_dir, "flow_scaler.bin")
        return_scaler_path = os.path.join(self.scaler_dir, "return_scaler.bin")

        if is_train:
            # í•™ìŠµ ëª¨ë“œ: fit_transform í›„ ì €ì¥
            df[self.flow_cols] = self.flow_scaler.fit_transform(df[self.flow_cols])
            df['ë“±ë½ë¥ '] = self.return_scaler.fit_transform(df[['ë“±ë½ë¥ ']])
            
            joblib.dump(self.flow_scaler, flow_scaler_path)
            joblib.dump(self.return_scaler, return_scaler_path)
            print(f"ğŸ’¾ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: {self.scaler_dir}")
        else:
            # ì¶”ë¡  ëª¨ë“œ: load í›„ transformë§Œ
            self.flow_scaler = joblib.load(flow_scaler_path)
            self.return_scaler = joblib.load(return_scaler_path)
            
            df[self.flow_cols] = self.flow_scaler.transform(df[self.flow_cols])
            df['ë“±ë½ë¥ '] = self.return_scaler.transform(df[['ë“±ë½ë¥ ']])
            print("ğŸ”Œ ê¸°ì¡´ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ë° ì ìš© ì™„ë£Œ")

        return df

    # (ì´í•˜ _add_technical_indicators, _add_date_features, _apply_clipping, _prepare_final_datasetëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
    def _add_technical_indicators(self, df):
        for col in ['ì¢…ê°€', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€']:
            df[f'{col}_log_ret'] = np.log(df[col] / df[col].shift(1))
        df['MA5'] = df['ì¢…ê°€'].rolling(window=5).mean()
        df['MA10'] = df['ì¢…ê°€'].rolling(window=10).mean()
        df['disparity_5'] = (df['ì¢…ê°€'] / df['MA5']) - 1
        df['disparity_10'] = (df['ì¢…ê°€'] / df['MA10']) - 1
        df['ma_gap'] = (df['MA5'] / df['MA10']) - 1
        df['ma5_gradient'] = np.log(df['MA5'] / df['MA5'].shift(1))
        return df.dropna().reset_index(drop=True)

    def _add_date_features(self, df):
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'].astype(str), format='%Y%m%d')
        dw, m, d = df['ë‚ ì§œ'].dt.dayofweek, df['ë‚ ì§œ'].dt.month, df['ë‚ ì§œ'].dt.day
        df['day_sin'] = np.sin(2 * np.pi * dw / 4)
        df['day_cos'] = np.cos(2 * np.pi * dw / 4)
        df['month_sin'] = np.sin(2 * np.pi * m / 12)
        df['month_cos'] = np.cos(2 * np.pi * m / 12)
        df['day_month_sin'] = np.sin(2 * np.pi * d / 31)
        df['day_month_cos'] = np.cos(2 * np.pi * d / 31)
        return df

    def _apply_clipping(self, df):
        for col in self.flow_cols:
            df[col] = df[col].clip(df[col].quantile(0.01), df[col].quantile(0.99))
        return df

    def _prepare_final_dataset(self, df):
        df['target'] = df['ì¢…ê°€_log_ret'].shift(-1)
        df = df.dropna().reset_index(drop=True)
        return df.drop(columns=['ì¢…ê°€', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì¢…ê°€_log_ret', 'MA5', 'MA10'])